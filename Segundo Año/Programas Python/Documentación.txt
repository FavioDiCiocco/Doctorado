Archivos:
---------

.) Crear_redes.py: Esto me construye redes estáticas conexas de un dado grado medio y 
con N agentes. Me las guarda en la carpeta de MARE. Cada vez que necesito nuevas redes
o renovar las existentes, uso esto.

.) funciones_generales.py: Acá voy a ir guardando las nuevas funciones que vaya implementando.
Así a partir de ahora esto tiene todas las funciones, pero el funciones de cada Python de cada
carpeta tiene sólo las funciones necesarias. Eso va a hacer que recorrer la lista de funciones
sea mucho más fácil cada vez que quiera buscar funciones.


Bifurcacion_logistica:
---------------------
En esta etapa estudio la transición del sistema de la región en la cual tiene tres puntos
fijos a la región en la cuál tiene uno solo. Lo primero que hago para esto es estudiar
analíticamente la ecuación dinámica y de ahí obtuve relaciones que cumplen el Kappa,
Alfa y Epsilon. Usando esas relaciones y la librería scipy para hallar soluciones numéricas
a las ecuaciones es que armé un gráfico 3D que me delimite la región en la cual el sistema
tiene tres puntos fijos. Esta fase del trabajo no requirió simulaciones, ya que sale de
resultados analíticos.
 A este gráfico 3D después le hice cortes según alfa para observar un poco mejor la forma
de las superficies 3D. Es decir, gráficos de Kappa en función de Epsilon para diferentes
Alfas.


Exploracion_Logistica:
----------------------
Armo archivos de Opiniones y unos pocos archivos de Testigos. Estos archivos de Testigos
guardan datos de 100 agentes con el objetivo de armar gráficos de Interes vs Tiempo
con las líneas grises finitas. El plan es a partir de estos datos armar gráficos de 
Promedio de Opiniones, Tiempo de convergencia e interés vs Tiempo.


Homofilia Estática:
-------------------
Este es el código que armé para estudiar el modelo que obtuvimos de la gente de España.
La idea del modelo es trabajar sobre redes estáticas pero asignar un peso a la interacción
de los agentes de forma tal que los agentes le den más importancia a quienes piensan como
ellos. La función del segundo término es de nuevo la tanh. Estos pesos tienen
la propiedad de que no son simétricos, por lo que el wij no es necesariamente igual al
wji, y además los wij sumados en j dan 1.
 Lo primero que estoy haciendo es generar datos de Opiniones y testigos, el clásico. Uso
redes de ER con grado medio 8 para 10000 agentes. Los archivos de Testigos sólo los armo
para las primeras dos iteraciones. Yo diría de realizar 50 iteraciones para empezar, cosa
de armar las simulaciones rápido.
 Deshice la carpeta de Datos y armé dos nuevas carpetas, 1D y 2D. En un principio tenían un
código "distinto", cuya única diferencia es que el 1D no hacía un esfuerzo real por calcular
la distancia entre las opiniones de los agentes, porque como es 1D no hay espacio no ortogonal
del cuál preocuparse. Actualmente eso está solucionado porque el código hace el producto escalar
para calcular la distancia usando la matriz de Superposición, por lo que está definido tanto
para 1D como para cualquier N dimensiones. Lo único extra a considerar es que según el número
de dimensiones, los datos se guardan en una carpeta distinta. Entonces si quisiera armar datos
5D, tendría que tener la carpeta 5D construída.
 Para esto terminé usando un K=3, barriendo beta [0,2] de a 0.1 y barriendo cos(delta) [0,1]
de a 0.1 también. Usé N=1000 al final, las primeras pruebas fueron con N=10000 pero para hacer
cuentas rápido y llegar con las presentaciones usé N=1000.

Tangente Diferenciada:
----------------------
Acá lo que estoy haciendo es correr un modelo idéntico al de arriba pero que quita el
término de cos(delta) de adentro de la tangente hiperbólica. Esto me deja la correlación
entre tópicos presente únicamente en los pesos de la red. La idea es observar si ese factor
adentro de la tangente hiperbólica simplemente es como un refuerzo sobre el factor de los
pesos. Como que ambos cumplen el mismo propósito y que si sacando uno puedo observar los mismos
resultados para valores de pesos más altos, o algo así. Para esto lo que hice es un barrido en
un espacio similar al caso 2D de la red anterior. Usé básicamente el mismo código que en el
caso anterior, con las mismas redes y con 1000 agentes. El caso anterior también lo hice con 1000
agentes al final. Los datos de esto están en Oporto.

Prueba Métrica:
----------------
Esta es una carpeta para trabajar más desde Python, no tiene un correspondiente en C. La idea
es construir sintéticamente distribuciones de datos similares a las que planeo medir. Con
eso el plan es ponerme a probar las métricas que charlamos con Pablo y con Hugo, la de la
distancia promedio de los puntos al centro del espacio de tópicos, la traza de la matriz
de Covarianza, las medidas de covarianza mutua (los elementos fuera de la diagonal) y
el determinante de la matriz de covarianza. El objetivo es ver cuántos estados puedo diferenciar
con esas métricas.
 Lo primero es usar el archivo de Generacion_datos.py para construir los datos sintéticos. Esos
archivos son datos con formas similares a los que tengo de otras simulaciones.

Medidas Polarización:
---------------------
Acá lo que voy a hacer son barridos más serios y usar las medidas de polarización que mencioné antes
para diferenciar los estados polarizados de los que no y los distintos tipos de polarización.
 Lo primero que voy a hacer es un barrido con cos(delta)= 0 en el espacio Beta-Kappa.
Voy a barrer Beta en [0,2] de a 0.1 y Kappa en [0,10] de a 0.5. Aunque en la región [0,1] voy
a barrer Kappa de a 0.2. Para este conjunto de parámetros además voy a tomar 40 simulaciones
cosa de tener una idea más o menos del comportamiento. Algo importante es que a partir de este
punto estoy usando dt=0.1 en vez de 0.01. Eso fue una propuesta de Hugo y ayuda a reducir los tiempos
de simulación. No fue tanto como hubiera deseado, pero fue bastante.

Prueba Tiempos:
---------------
Esta carpeta todavía no la use, la idea es hacer el testeo de cómo varía la fracción de estados
polarizados en función del tiempo de integración. El plan básico es revisar nuevamente cómo
hicieron ellos esto. Más que nada para ver cuántas simulaciones necesito. Además, necesito
una forma clara de diferenciar estados polarizados de los que no. Creo que la traza de la
covarianza igual demostró ser un buen medidor.
