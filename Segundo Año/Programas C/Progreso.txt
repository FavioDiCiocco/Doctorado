22/03/2023

Me olvidé de revisar el tema del formulario, mañana en casa lo miro.

Por otro lado hablé con Pablo sobre mi idea de mirar la derivada. Me parece que es un gráfico
interesante para hacer, pero es cierto que quizás no aporte tanto. Veamos de hacerlo
después, una vez que tenga hechos los gráficos de interés versus tiempo. Entonces la cosa
es mandar a hacer una nueva corrida de datos en Oporto. Para esta corrida la idea es guardar
datos de Opiniones y Testigos. Mi gran duda es cuántos datos de testigos guardar. Igual
creo que estoy haciendo mucho espamento, debería armar los datos y ya.
 Lo que siempre hago es guardar datos de 5 o 6 testigos para cada simulación, pero después
sólo grafico los datos de la primer o segunda simulación. Es decir que guardo datos que
después no uso, una gran boludez. Me parece más honesto guardar datos de 100 o 200 agentes
de las primeras simulaciones y para el resto de simulaciones no armar archivos de Testigos.
Es importante considerar que si guardo 100 agentes en dos simulaciones, eso son 200 agentes
que guardo de testigos. En comparación, si guardo 6 agentes de todas las simulaciones, en
el caso de 50 simulaciones para una dada configuración de parámetros, eso significan 300
agentes. Es decir, en el total estaré ahorrando espacio para el caso en que haga muchas
simulaciones. Además, la idea de guardar muchos agentes me permite armar los gráficos
de las líneas grises finitas que dan una idea del comportamiento dinámico del sistema
total. Me parece que va a ser mejor hacer esto, aunque para arrancar guardaré simplemente
50 agentes como testigos.

Esta nueva etapa entonces se llamará exploración_Logística, voy a barrer en Kappa y
Alfa. Epsilon lo fijo a 4, barro Alfa entre [5,8] y mirando los gráficos de Kappa
en función de Alfa para un Epsilon fijo, puedo ver que si barro Kappa entre [1,4]
en gran parte de la región barrida el sistema posee tres puntos fijos. Por lo que
esa región me parece razonable para estudiar. La idea sería que los parámetros
varíen de a 0,3, cosa de que son 11 puntos por parámetro. Ademaś tengo un sistema
de un único tópico, por lo que no necesito preocuparme por Cosdelta. Armaré unas
pocas simulaciones, por lo que esto no debería tardar tanto. Suponiendo que 
cada simulación tarde aproximadamente 40 segundos y dividiendo el laburo en
20 hilos, esto no va a tardar más de 3 horas. Es decir que si lo mando en un rato,
para hoy están los datos. Tengo entonces que modificar los archivos de main de C.

Ahí lo mandé a correr, parece funcionar sin problemas. Diría que para las cuatro
esto va a estar terminado.

Miré el resumen del poster de TREFEMAC, me parece que está bastante bien, sólo
me queda preguntarle a Pablo cómo pondría la referencia al paper de Baumann en
el resumen. Me parece que deberíamos aunque sea mencionar que esto no surgió
de la nada.

Dicho eso, encontré el paper este que había pasado antes Sebas, voy a leerlo a ver
qué hacen ya que trabajan con el modelo de Baumann y ver si hay algo interesante
que sacar de ahí. Ya leí las primeras dos secciones, debería después continuar con
la sección 3 de resultados.

------------------------------------------------------------------------------------------

23/03/2023

Revisé pero no encuentro en casa el Formulario de Autorización. Igual dice que las firmas
tienen que ser manuscritas, así que después veré de imprimirlo el lunes, se lo llevo a Pablo
y de ahí a la Biblioteca Central. También envío mi Tesis por mail el lunes y listo.

Entonces debería ponerme con lo que son los datos que armé ayer. Ahora que lo pienso, estaría
bueno tener algunos datos armados para hacer pruebas con las funciones. Hagamos eso, recorramos
una región similar y usemos eso para armar unos datos en la pc.

Me estoy dando cuenta de que nunca hice ningún if para que el programa arme testigos sólo
si el número de iteración es 1 o 2. Hagamos estas dos cosas.

Agregué al main los if que me escriben el archivo de Testigos sólo para las primeras dos simulaciones.
Hecho eso, armé algunos datos en la pc de casa y rearmé los datos en la pc de Oporto. Los tuve
que rearmar porque me di cuenta que había escrito archivos de Testigos para todas las simulaciones.
También armé una carpeta de datos para contener los archivos. Para lograr deshacerme de los
archivos que no me interesaban tuve que usar una función llamada remove, borra un archivo
según el path que recibe.

Lo siguiente que tengo que hacer es modificar las funciones de gráfico y armarme los siguientes gráficos:
.) Mapa de colores de Opiniones (Fácil, ese lo tengo ya hecho)
.) Mapa de tiempo de Convergencia (Creo que puedo tomar el de Varianza y modificarlo un poco)
.) Interés en función del tiempo, pero tengo que hacer eso con las líneas grises y finas.
Tengo que modificar la función existente y armar una nueva para eso.
.) Después puedo ver de armar una función que grafique la derivada del interés en función del tiempo.

En los gráficos de mapas de colores tengo además que agregar las curvas de Kappa Máximo y Kappa Mínimo

Ahí le hice la modificación al Mapa de Colores. Veamos que todo funca bien, el lunes seguiremos con
esto. El tema del alfa me produjo errores de nuevo. Voy a ver si lo puedo solucionar de alguna otra
manera. Solucionado

------------------------------------------------------------------------------------------

27/03/2023

Hoy llegué y me puse a resolver algunas cosas extra. Volví a conectar el Slack a mi celular.
Después mandé el mail a la biblioteca central con mi tesis. Aunque al parecer hubo problemas
con el envío a la dirección tesis_lic@df.uba.ar por el tamaño del archivo. Mandé dos veces
el mail, esperaré a ver si me responden algo y de ahí veré qué hago. Tengo el formulario
de autorización firmado por mi, después se lo daré a Pablo para que lo firme. Quizás tenga
que imprimir otro después.

Voy a necesitar unos datos para hacer unas pruebas, así que ahí mandé a correr el Instanciar
en la pc de la facultad. Lo siguiente es ponerme con el mapa de tiempo de convergencia.

Visto el mapa de tiempo de convergencia, la verdad no se ve mucho. La línea de Kappa_min
parece tener dificultades en la convergencia en comparación al resto. ¿Por qué el comportamiento
no es simétrico en ambas regiones de transición? Quizás los gráficos de Testigos me den una
respuesta al respecto.

Mirando el gráfico de interés en función del tiempo logré observar que para el caso de alfa
alto y Kappa bajo, el sistema efectivamente tiene un estado metaestable, se observa
claro como el agua. Quizás esté interesante revisar esa región. Ahora mismo tengo las
funciones que arman los tres gráficos que me resultaban interesantes hacer. Ahora debería
pasar el código a Oporto y ver los gráficos que me genera.

Me respondieron de biblioteca digital, parece que les llegó la tesis perfecto. Si me responden
que sólo falta el Formulario, le pido a Pablo que me lo firme y de ahí completo lo que falta.

Antes de ponerme a ver si están los gráficos de Exploracion_Logistica, lo primero que voy a hacer
es intentar armar la función que grafica la derivada del interés. Y después podría ponerme
con la parte de la burocracia infinita.

Los gráficos de Derivadas no son realmente informativos, al final podría prescindir de eso.
Revisando los gráficos que hice con los datos de Oporto, pareciera que la curva de Kappa_min
es la que tiene una región de un mayor tiempo de convergencia al punto final. Viendo los gráficos
de Interes en función del tiempo, no logré encontrar un gráfico en el cual las opiniones de los
agentes se mantenga constante por un tiempo prolongado antes de decaer. Aunque si hay varios
gráficos en los cuales las opiniones primero caen y luego suben o al revés, variando muy lentamente
antes de llegar a un resultado final.

Para revisar esto mejor es que mandé a hacer gráficos para un grupo específico de Kappas pero para
todos los Alfas. Eso quizás me muestre las curvas en las cuales los agentes tardan en converger.

------------------------------------------------------------------------------------------

28/03/2023

Hoy a la mañana fui a cursar la materia de Piegaia, después di clases en la materia de F1 y llevé
el formulario de Autorización a la biblioteca del pabellón 2. Estuve revisando lo que hice ayer,
estoy dudando de si no debería hacer un barrido más fino de los datos.

Entre organizar el partido y cosas, se me está yendo toda la tarde. Mañana entonces tendría que
rever el resumen de TREFEMAC así como ver qué más puedo hacer con el modelo. Creo que compensa
hacer un barrido más fino. La duda es cómo hacerlo correctamente sin hacer cuentas innecesarias.
Es decir, sin volver a calcular cosas que ya calculé antes.

Y por otro lado, se me ocurre que estaría bueno ver de modificar la función que grafica el interés
vs tiempo de forma que haga los gráficos para la región de Kappas en los cuales hay puntos con
alto tiempo de convergencia.

También haré mañana la burocracia infinita.

------------------------------------------------------------------------------------------

29/03/2023

Estoy viendo para mandar a correr nuevos datos que complementen los que ya tengo. Para eso
necesito primero barrer completamente el alfa entre 5 y 8 de a 0,1. Eso significa que para
los Kappas existentes tengo que armar datos nuevos. Por otro lado, como mi paso anterior
fue 0,3 también en Kappa, querría armar los datos para los Kappa menores a 1,8 sin repetir
los datos ya armados. En ese caso, se me ocurre armar simulaciones diferentes moviéndome
de a 0,3 pero arrancando desplazado, cosa de tomar todos los valroes intermedios. Yo diría
de arrancar primero con los Kappas faltantes y después completamos a los Kappas existentes.
Primero mandé a correr datos para Kappa={1.1,1.4,1.7,2} con alfa entre 5 y 8 de a 0,1.

Cuando eso termine, hago lo mismo pero arranco con Kappa = 0.9 así corto en 1.8.
Ya hice la burocracia infinita y mandé la corrida usando el Kappa inicial de 0.9. Hecho
esto, lo siguiente sería poner Kappa en 1 y completar los alfas que le faltan a esos Kappas.
Lo que estoy pensando es qué pasará con los Kappas por encima de 2, los que no tienen
un barrido tan fino en alfa. El uso del Dataframe creo que permitirá que esa región quede
en blanco ya que el array ZZ estará compuesto de ceros que se sobreescriben en base
a los datos obtenidos de los archivos. Igual estoy viendo que el programa no está planeado
para considerar que no haya archivos que levantar. Le va a intentar tomar un log a 0 o a
la nada misma, el programa no va a saber qué hacer. Podría asegurarme de graficar los
datos con Kappa por debajo de 2, eso es una opción. Creo que en principio es lo más razonable,
para no estar corriendo un barrido fino innecesario en esa región. 
 El mesh se ajusta a un barrido diferenciado en un eje, pero no a dos barridos diferenciados
en dos ejes. No, creo que en ese caso tendría que hacer los ploteos por separado. Pero hecho
de esa manera, quizás debería asegurarme que los límites de lo plotteado sea tal que los
colores no se mezclen. Plottear regiones con diferentes granularidades no es tan sencillo
como uno quiere imaginar.

Luego de varias simulaciones, logré armar un barrido más fino de la región de Kappa=[1,2]
y Alfa=[5,8]. Aunque para mantener esto correcto, tuve que retocar las funciones de
graficación de forma que sólo consideren el Kappa (Parámetro 1) en los casos en que vale
menos que 2. Porque creo que graficar casos de diferentes granularidades no es algo
tan simple. Hecho esto, mandé a armar los gráficos, quiero ver si se observa mejor una
región de convergencia. Para esto estaré armando muchos gráficos, espero que no sea
una locura revisarlos. Podría ponerme pronto a armar un barrido fino para el resto de la
región de estudio.

Por otro lado leí el paper que había pasado Sebas en el cual hacían un estudio sobre modelos
de opinión, especialmente sobre un modelo basado en el de Baumman pero con algunas modificaciones.
Hay una idea interesante que sacar sobre un tipo de gráfico que se puede armar para diferenciar
los estados de polarización. Para el resto del análisis de esto, está lo que subí al drive
en Bibliografías.

------------------------------------------------------------------------------------------

30/03/2023

Hoy vine a la facultad en auto. Espero que sea la última vez, es un bardo. Más allá de que
hoy en particular hubo algún motivo para la congestión, sigue siendo un bardo y muy aburrido.
Después estuve un buen rato mirando el resumen y viendo cómo contar lo que hicimos de una
forma un poco más específica.

Ahora a la tarde voy a cursar la materia de Sociología para gente de Exactas.

------------------------------------------------------------------------------------------

31/03/2023

A la mañana cursé la materia de Piegaia, después fui a dar clases y por último me volví a
la oficina para inscribirme a la TREFEMAC. Hecho esto, creo que el lunes tengo varias
cosas para hacer de las cursadas. Por un lado, hacer los ejercicios de física, me vengo
haciendo el vivo, hoy me agarraron con un ejercicio y estuve un rato en duda. Necesito
contestar más claramente a los estudiantes lo que está pasando, así que tener lo ejercicios
ya preparados es primordial. Por otro lado, tengo que ponerme a resolver ejercicios de la
materia de Piegaia, o sino nunca voy a entrar en ritmo. Por último, tengo que leer los 
textos de la materia de Sociología. Así que tengo que ver de trabajar en casa algunas
de estas cosas porque sino no voy a llegar jamás. Y otras trabajarlas acá.

También, tengo que pagar la cuota anual de la AFA y revisar el tema de las afiliaciones.
Marcos dijo que iban de cierta forma, pero no están para nada anotadas de esa forma.
También tengo que incluir a Pablo y Sebas a la afiliación.

------------------------------------------------------------------------------------------

03/04/2023

El lunes fui después del mediodía a la facultad. A la mañana estuve en casa haciendo ejercicios
de F1 para ir teniendo las guías hechas. Después del mediodía fui a la facultad, me imprimí las
guías y estuve mandando varios mensajes organizando cosas de varios grupos. Un bardo, pero
fue necesario.

------------------------------------------------------------------------------------------

04/04/2023

Cursé y di clases. Y después hice algunos ejercicios más de F1. Los martes y viernes van
a ser bastante escuetos. Vamos a aprovechar el finde largo para ponerme al día con las guías.

------------------------------------------------------------------------------------------

05/04/2023

En la mañana corregí el tema de las afiliaciones del trabajo enviado a la TREFEMAC y completé
el formulario del pedido de ayuda económica. Después pagué la cuota anual de la AFA, y
aproveché para pagarle a mamá y a Azu. Hecho eso estuve revisando algunas cosas y organizando
varios pequeños detalles. A la tarde tengo turno.

------------------------------------------------------------------------------------------

10/04/2023

Estuve haciendo ejercicios de F1 en la mañana y de MEFE en la tarde. Hoy fue un día de ejercicios
nomás. También movimos el escritorio grande de la oficina.

------------------------------------------------------------------------------------------

11/04/2023

Cursé MEFE y hablé con el JTP. Me dijo que la idea es que a partir de ahora primero tengamos
la práctica y después la teórica. Me dijo que la materia de MEFE no tiene final, me conviene
más cursar la práctica y las teóricas las miro online más tarde. Eso supongo será lo que haré
los martes y viernes después de cursar. Lo que sí, tengo que hablar porque me quise inscribir
como doctorando a la materia y no pude, así que estoy cursando sin estar inscripto.

Después fui a dar clases. Esta vez estuve mucho mejor preparado para las consultas. Una chica
consultó sobre que tiene ciertas dificultades para resolver los ejercicios. Intenté darle
consejo, pero me da un poco la sensación de que quizás deje la materia. Después intentar darle
una mano.

A la tarde resolví un ejercicio más de F1.

------------------------------------------------------------------------------------------

12/04/2023

A la mañana llevé la bici a la bicicletería. No vinieron estudiantes a las clases de consulta
de contraturno. Revisé un poco lo que tengo hecho y completé el archivo de Progreso.

Ahí estuve leyendo y repasando los últimos gráficos que había armado. Lo último que hice
fue armar gráficos de Interés en función del tiempo, Opiniones promedio y Promedio de
tiempo de convergencia. Podría aprovechar y también armar gráficos de la varianza de los
tiempos de convergencia.

Por otro lado, mirando los gráficos de Promedio de opiniones y de Promedio de tiempos de
Convergencia, se nota que la franja de transición entre que el sistema converge al punto
fijo mínimo y que converge al punto fijo máximo está corrida respecto de la línea de Kappa
mínimo que está graficada. Creo que estaría bueno agregar la línea de Kappa máximo y ver
si realmente la franja de transición está en el medio de ambas curvas. Lo que sí es que
parece seguir una forma similar. Al parecer nunca retiré la línea del Kappa Máximo del
gráfico. Si no se grafica es porque no entra en la región graficada. Creo que si bien 
va a ser mucha simulación medio al pedo, vale la pena agregar los datos necesarios para
agregar la región de Kappas que falta. Kappa se mueve de [1,4] y Alfa de [5,8]. Originalmente
ambos tenían un paso de 0,3. Luego, para Kappa entre [1,2] hice un barrido más fino en
ambos parámetros, barriendo de a 0,1. Si no me equivoco, no habría problema en que Kappa
tenga pasos diferentes, pero sólo si corrijo para que todo tenga un barrido igual en Alfa.

Así que debería mandar a correr datos para rellenar los datos de forma que Alfa recorra
el [5,8] de a 0,1. Ya mandé a correr los datos arrancando con Alfa=5,1. Después tengo
que mandarlo con Alfa=5,2 y listo. En 21 minutos debería terminar de correr.

Debería primero que nada pensar en qué voy a poner en el poster. Para eso arranquemos del
poster que usé para la TREFEMAC pasada y del resumen, eso me va a dar una idea de qué quiero
mostrar y cómo.

Ya mandé la otra parte de los datos. Mañana puedo mandar a correr el programa de Python y
revisar los gráficos hechos.

Estoy queriendo armar el poster. Para arrancar, el texto del resumen no entra bien en el
lugar que tenía antes, el resumen actual es muy grande. Podría ir probando entonces de
ponerlo y después lo ajusto.

Cosas que poner en el poster:
------------------------------
.) Ecuación dinámica, describiendo los términos de la ecuación. Al ser en 1D, no necesito
hablar de tópicos no ortogonales. Quizás podría mencionar que todas las interacciones
entre agentes refuerzan las opiniones.
.) Función logística. Tengo que mostrar qué es y que forma tiene y cómo varía esa forma
con los parámetros.

Mañana sigo anotando esto.

------------------------------------------------------------------------------------------

13/04/2023

En la mañana estuve leyendo la bibliografía de la materia de Sociología. Esto me tomó
todo el tiempo hasta ir a cursar. De ahí me volví temprano sin pasar por la práctica
porque esperaba ir a buscar mi bici, que no estaba lista.

------------------------------------------------------------------------------------------

14/04/2023

Fui a MEFE, di clases, intenté buscar un reemplazo y cosas.

------------------------------------------------------------------------------------------

17/04/2023

Estuve coordinando cosas para buscar un reemplazante, Mauro y un conocido de Constanza
me dijeron que podrían si no consigo a nadie más. Debería charlar con Nahuel y Julian sobre
si es necesario que estén presentes el día del parcial

------------------------------------------------------------------------------------------

18/04/2023

Cursé las primeras dos horas en MEFE, fui a dar la clase de rozamiento en F1, preparé los
papeles para hacer el pedido de licencia con goce de sueldo y hablé con Nahuel por Slack.


------------------------------------------------------------------------------------------

19/04/2023

Estoy pensando la charla para dar mañana a la mañana. La idea es contar mi línea de trabajo.
Debería contar que trabajo un modelo de dinámica de opiniones, actualmente transformado en
un modelo de dinámica de interés respecto tópicos de debate. Arrancaría mostrando las
ecuaciones dinámicas, que son el centro de mi trabajo. Mostraría el caso de muchos tópicos,
diría que es a lo que queremos llegar y hablaría de la idea de tópicos no ortogonales.
Luego presentaría el modelo unidimensional y diría que ahí es dónde estamos parados ahora.
Lo siguiente sería unos gráficos del interés en función del tiempo para mostrar el
comportamiento del sistema. Después unos gráficos de mapas de colores mostrando algunos
análisis hechos con el objetivo de explicar que mi interés es estudiar el proceso para
comprender el sistema. Entendiendo como funciona, el plan es pasarlo a un modelo multidimensional
y luego comparar el modelo con datos para ver si se observa lo simulado.
 También me parece interesante mostrar las herramientas que uso (C, Python, Bash, Github)
y un poco de mi proceso de trabajo. (Armo código en C, simulo en los clusters, grafico,
descargo las imágenes y luego analizo los resultados).

Después modificar las líneas grises para que sean un poco más grandes, así se ven un poco mejor
esos gráficos.

------------------------------------------------------------------------------------------

20/04/2023

En la mañana terminé la presentación. Espero que quede bien. Después vamos a la reunión de
Sophy, más tarde resuelvo el tema del reemplazo. Y después iré a cursar, quizás lea un poco
de la bibliografía de la materia de Sociología.

------------------------------------------------------------------------------------------

21/04/2023

Cursé, di clases, me comí una hamburguesa completa y mandé la documentación para el pedido
de licencia con goce de haberes. También hice la burocracia infinita. Por último voy a anotar
algunas cosas de la materia de MEFE y terminar por hoy.

------------------------------------------------------------------------------------------

24/04/2023

Estuve en la mañana haciendo ejercicios de F1 y a la tarde ejercicios de MEFE. Eso fue todo
mi día. 

------------------------------------------------------------------------------------------

25/04/2023

Cursé y di clases. Hablando con Constanza, me recordó que hay un TP computacional para hacer
para MEFE. Al parecer corrieron la fecha de entrega para el martes que viene.

Considerando que la semana que viene tengo parcial de MEFE, voy a empezar a hacer ejercicios en
casa en el horario de conectarme con los pibes al Discord. Así voy a llegar un poco mejor
a las materias. Haré tanto cosas de F1 como de MEFE.

Hablando con Pablo estamos en la idea de empezar a avanzar a la implementación de un campo
externo. Para esto tengo que explorar por en lado el uso de la función que propuso Pablo
para que el interés se mantenga entre [0,1] y por otro lado tengo que pensar distintas formas
de introducir el campo externo a la función. Pablo me habló de pensar formas de que un agente
gane interés y después lo pierda en un tópico.

Voy a traer de hace unos días que había copiado sobre cosas que poner en el poster.
Cosas que poner en el poster:
------------------------------
.) Ecuación dinámica, describiendo los términos de la ecuación. Al ser en 1D, no necesito
hablar de tópicos no ortogonales. Quizás podría mencionar que todas las interacciones
entre agentes refuerzan las opiniones.
.) Función logística. Tengo que mostrar qué es y que forma tiene y cómo varía esa forma
con los parámetros.

Mañana tengo que ir a la consulta de contra turno, pero eso es aparte. 
Me voy a imprimir las guías de F1 y de MEFE.

------------------------------------------------------------------------------------------

26/04/2023

Vamos a anotar entonces las cosas que creo necesarias para el poster. Anotar la ecuación
dinámica claramente va, es el corazón del modelo. Y por tanto describir los términos de
la ecuación 1D es igual de importante. También mencionar que debido a que los intereses
son todos positivos entonces el interés sólamente puede contagiarse.
 ¿Debería hablar de la función logística? Me suena como el paso razonable considerando
que esto está en el segundo término y no parece obvio el por qué.
 Después tengo que mostrar algunos resultados del modelo. Es decir, que el sistema
admite estados en los cuales todos los agentes alcanzan el máximo interés o decaen
al cero de interés. Mostrar que existen simulaciones de transición sin caracterizar la
región de transición me parece una pésima idea.
 Viendo lo que el modelo permite hacer, podemos hablar de la exploración del espacio de
parámetros. Podría hacer gráficos para mostrar cómo cambia el gráfico de promedio
de intereses para la combinación de parámetros Kappa-Alfa, Kappa-Epsilon y Alfa-Epsilon.
Eso estaría bueno para mostrar que en el caso Alfa-Epsilon el sistema produce una recta
que diferencia la región que converge al punto de máximo interés versus la región que
converge al mínimo interés.
 
 Estoy mirando el gráfico de interés promedio que armé en la carpeta de Exploración_Logística.
Tengo mis dudas respecto al hecho de que la transición de un punto fijo mínimo al punto fijo
máximo no está sobre la curva de Kappa_mínimo sino un poquito por arriba, pero con una forma
similar. Se me ocurre que si en vez de distribuir las opiniones iniciales entre [0,Kappa], las
distribuyo en intervalos con el valor máximo cada vez más chico, la curva esa debería subir
para acercarse y finalmente superponerse con la curva del kappa máximo. Me parece que eso
es algo interesante para observar. Comparé la simulación con los gráficos de Geogebra, lo que
veo es que fijando alfa y epsilon, a medida que Kappa aumenta, el punto fijo del medio va
bajando. Pero no sólo eso, sino que al aumentar Kappa el valor medio del interés inicial también
aumenta, ya que el interés inicial en promedio vale Kappa/2. Luego, razonablemente al aumentar
Kappa resulta que para algún valor Kappa/2 es mayor al punto fijo del medio, y por tanto el
sistema empieza a converger al punto fijo máximo.

############################################################################################
 Me parece que sería interesante ver cómo la curva de transición de convergencia del punto 
de mínimo interés al de máximo interés varía al cambiar el espacio de interés inicial. Serían
una serie de gráficos interesantes. Y además, podría armar un gráfico de diferencia de punto de
convergencia entre el punto de convergencia de una fila y la fila siguiente. Eso ilustraría la
curva en la que se da el salto. Luego podría superponer los gráficos y eso debería iluminar la
zona entre las curvas de Kappa máximo y mínimo. Me gusta esta idea.
############################################################################################

Volviendo al poster, me parece que por una cuestión de seguir un hilo conductor, es más razonable
que al empezar a contar cosas sobre la ecuación dinámica, hable de ciertos resultados, como el
hecho de cuáles son los puntos fijos que el sistema alcanza o que se necesita un mínimo valor
de Epsilon para que el sistema tenga tres puntos fijos. Creo que eso se puede mostrar, no con
un gráfico de Geogebra, sino con un gráfico de Python que tenga marcado con puntos grandes
los puntos fijos y luego tenga escrito en el eje X cosas como: "Punto fijo estable mínimo"
o algo más corto. Yo haría toda una sección del poster que sea el ANÁLISIS DINÁMICO.
En esta región definitivamente se puede agregar el gráfico 3D de la región de tres puntos fijos
con los gráficos de corte.

Habiendo planteado que el sistema tiene una región en la cual tiene más de un punto fijo,
me parece razonable mostrar el gráfico de la varianza en el espacio de parámetros. Para eso
usaría el gráfico que ya tengo con cos(delta) = 0, así no tengo que rehacer esos datos.
Me parece que es más interesante el gráfico en el caso de Kappa en función de Epsilon, porque
así se ve que esa región tiene una parte que se cierra. Si hago el Kappa-Alfa lo que
tengo es una parte en el medio coloreada que como gráfico me parece poco interesante.
Después, para agrandar la región marcada lo que puedo hacer es restringir la zona graficada,
eso lo puedo hacer fácil y va a quedar mejor, así no es un gráfico con tanta zona azul que
no dice mucho.

Habiendo visto la región en la cuál el sistema tiene tres puntos fijos, lo siguiente es mostrar
el gráfico de promedios. Acá si resulta una buena idea armar gráficos de promedios de cada
parámetro en función del resto. Hablamos de cómo podemos observar que el parámetro alfa y el
parámetro Epsilon da lo mismo variarlos y que estudiamos el comportamiento de Kappa con
Alfa y con Epsilon. Eso serían tres gráficos, donde mostraríamos que la transición entre
una región y la otra se da dentro de la región de tres puntos fijos.

Si me queda lugar, creo que podría intentar incorporar los gráficos de interés final promedio
en función de Kappa o Epsilon. Creo que esos aportan, pero tendría que armarlos considerando
puntos con un tamaño proporcional a la cantidad de simulaciones que caen en cada lugar.
Igual esto creo que da para charlarlo con Pablo, si tengo que hacer todo lo que puse y encima
armar el poster, no creo que llegue con todo.

------------------------------------------------------------------------------------------

27/04/2023

Aún si hoy no empiezo a armar el poster, es importante que hoy defina los datos que voy a
necesitar y los mande a correr, así ya eso lo tengo para la semana que viene.

Estoy medio armando una primera idea del poster. Mejor hacer eso mañana. Ahora voy a mandar
a correr los datos que necesito y ya me pongo a hacer ejercicios de F1. Y que la materia
de Sociología se resuelva sola.

Yo quiero armar gráficos de promedio de Kappa-Epsilon y Kappa-Alfa. Para eso necesito variar
los tres parámetros, Kappa, Epsilon y Alfa. ¿Dónde los varío y cómo los varío? ¿Y en qué
carpeta los guardo? ¿Y cómo inicializo las condiciones?

Se me ocurre inicializar usando que las opiniones vayan entre [0,Kappa], es para ser consecuente
con los otros gráficos. Epsilon va entre [1.5,3]. Kappa va entre [1,3] y Alfa entre [1,3].
Suponiendo que cada simulación tarda seis segundos, con un barrido más o menos fino de
0.1 tengo 16 valores para Epsilon, 21 para Kappa y 21 para Alfa. Luego armando 40 o
60 simulaciones para cada configuración eso implica un total de 2.540.160 segundos.
Que dividido en 20 hilos me da 127008 segundos. En total eso son 35 horas. Si lo mando hoy,
lo tengo para el finde. Perfecto.
 Pero pará, no necesito Kappa tan grande, Kappa debería ir entre [1,2], y lo mismo Alfa.
Con lo visto, no me compensa gráficos tan grandes, mejor revisar esas regiones un poco más
en detalle. Si en vez de un paso de 0.1 tengo uno de 0.05 pero con la región reducida eso me
da 68 horas. Eso es menos de tres días. Tengo que estar seguro de lo que mando a correr, pero si
lo hago hoy o mañana, ya el martes lo tengo hecho. Voy a armar las carpetas, preparar el código
y asegurarme que sólo tengo que apretar unos botones cuando hable con Pablo.

Ya tengo hecho todo, creo que tengo que mandarlo y listo. Si puedo, discuto un poco con Pablo
la idea, sino lo mando en casa y listo. En el peor caso, lo charlo mañana un momento con Pablo.

------------------------------------------------------------------------------------------

28/04/2023

Fui a cursar y di clases. Después de eso me puse a revisar el programa que subí a Oporto y a
revisar el armado de datos. Pero me mandé una cagada, porque al principio el programa se mandó
a correr y estaba mal el path de los archivos, así que tiraba error y no corría. Corregí ese
error, pero me olvidé de frenar los programas. Eso llevó a que tengo los 20 hilos en uso. Eso
estaría dando errores, si no fuera porque volví a compilar el archivo Opiniones.e. Gracias
a eso, ahora los archivos están correctamente corriendo y armando los datos que corresponden.
Por un momento pensé que iba a tener que esperar al martes de la semana que viene para recién
ahí mandar a correr todo. Lo que sí voy a tener que hacer, pero no va a ser tanto problema, 
es mandar a correr todo desde el principio pero tengo que ajustar Instanciar para que sólo
rearme los archivos de los primeros Kappa. Por lo que veo, ya los datos de Kappa=1.05 los
está armando. Por si estoy viendo algo mal, después rearmo los datos de Kappa = {1,1.05,1.1}.
Bueno, menos mal, esto hubiera sido un problema a considerar sino.

------------------------------------------------------------------------------------------

02/05/2023

A la mañana no cursé, sólo hice ejercicios de MEFE y después me fui a dar clases. Le debo a
uno de los chicos la resolución del ejercicio 6 de la guía de SNI.
 Por otro lado, yo pensé que la simulación iba a estar terminada para ayer, y sin embargo está
todavía corriendo. Parece que completó una simulación y media en este tiempo, estamos cerca de
completar la segunda. Con algo de suerte ya mañana lo mando a correr lo que falta y después
armo los gráficos. Tengo que tener el código para armar los gráficos listo. Igual no creo que
sea difícil, tuve en la sección de Cambio_parámetros 2D que armar gráficos con archivos que tenían
tres parámetros, así que es cosa de tomar eso y reajustar las funciones.
 Sigamos preparando el poster, anotando cosas y ya mañana nos ponemos seriamente con eso.
 
------------------------------------------------------------------------------------------

03/05/2023

Charlé con Pablo sobre ideas para el poster, ideas para el trabajo a futuro y después me puse
a armar gráficos para el poster. A la tarde di clases de consultas.

------------------------------------------------------------------------------------------

04/05/2023

A la mañana armé el croquis del canasto metálico para la bici, tuvimos una reunión de grupo
donde Franco Eskinazi nos dió una charla sobre un paper de identificación de ideología de 
usuarios y de ideología latente.
 Después trabajé en el poster, fui a la charla sobre el conocimiento científico estudiando el
caso de la convención de armas químicas y después seguí con el poster. Al parecer hubo unas
simulaciones raras en el cluster, no entiendo por qué. Así que lo mandé de nuevo, y si no
se arregla, mañana tendré que ver mejor qué pasa con eso.

Viendo el poster, en la parte de análisis dinámico ordené todo sacando lo de que el interés
tiene que ser positivo y que los agentes tienen que reforzar su interés al interactuar.
Me parece que de todo lo que hay para mostrar, eso es lo menos importante y se puede describir
o ver de los gráficos.

------------------------------------------------------------------------------------------

05/05/2023

En la mañana resolví el ejercicio que me había preguntado uno de los estudiantes. Después
fui a dar clases. No fui al parcial de MEFE.

Después mirando con Seba descubrimos que al final sí estaba comiéndome todo el espacio de
Oporto. Tengo que ser más consciente con eso. Por ahora mandé a hacerse unos gráficos
y cuando venga Pablo decidiré los gráficos que faltan agregar. Mientras lo que haré es
armar unos datos que sirvan para armar los gráficos que necesito. Podría armar tres
carpetas, una con alfa fijo, otra con Kappa fijo y otra con epsilon fijo. Esto va a
tardar mucho menos que lo anterior en correr.
K = [1,2], Alfa=[1,2], Epsilon=[1.5,3]. Variando los tres de a 0.05. Haré 30 simulaciones.
Sabiendo que cada una tardaba unos 10 segundos, supongamos 15 para el peor caso.
Las 30 simulaciones las distribuiré entre seis hilos.
Epsilon fijo = 3: 21*21*31*15 (9 horas y media)
Kappa fijo = 1.5: 21*31*31*15 (14 horas)
Alfa fijo = 1.5: 21*31*31*15 (14 horas)

Listo, puedo mandar esto y mañana a la madrugada está terminado. Cierto que no puedo simplemente
mandarlo, los .e se van a pisar y eso va a ser un bardo. Podría simplemente mandarlo de a
1 a la vez. Hagamos eso. Usemos 20 hilos y hagamos 40 simulaciones

Ahora a las 16 mandé a armar los datos de Epsilon fijo. Eso va a tardar unas 3 horas.
Quizás la mitad considerando que yo calculé que cada simulación tarde 15 segundos y en
realidad es más bien 8.

Bueno, la idea está más o menos clara, puedo hacer esto en el finde. El plan es:
x) Modificar los gráficos de Opinión en función del tiempo para que se vean mejor
desde la distancia. Quizás agregarles los parámetros asociados en el título del plot.
Eso lo voy a lograr corriendo el Graficar de la carpeta de Exploración Logística en Oporto.
x) Ubicar estos gráficos en el espacio de parámetros graficado a la derecha. O quizás sea
mejor tenerlos ubicados en el gráfico 3D, quizás con unas cruces para que se vean.
x) En la región abajo a la izquierda agregar un gráfico de Promedio de Opiniones. Ese
gráfico lo voy a conseguir mandando a correr el Graficar de la carpeta de Cambios_Parametros
que tengo en Oporto.
x) Junto con esos gráficos poner gráficos de interés final en función de Kappa.
x) Pasar el último párrafo a Conclusiones. Y hacer que la intros se vea más linda.
x) No es necesario hacer los datos de Alfa_fijo o Kappa_fijo. Necesito sólo los de Epsilon fijo,
A cambio tengo que agregar Kappa entre [0.5,1], y repetir la simulación para Epsilon=1.5.
Podría hacer eso más corto si fijo Alfa ahora que lo pienso, total no necesito todos los alfas.
Bien, la idea cierra.


------------------------------------------------------------------------------------------

07/05/2023

Al final había hablado con Pablo el 05/05 y definimos que los únicos datos que necesitaba son
los de alfa_fijo. Lo que hice fue armar datos variando Kappa entre [0.5,2] con un paso de 0.01.
Estos datos tenían Alfa = 3 y Epsilon tomó sólo dos valores, 1.5 y 3. Esos datos los armé junto
con datos de Testigos. Voy a usar estos datos para armar gráficos de Interés final en función de
Kappa.

Antes que nada, ahora voy a mandar a armar el gráfico de Promedio de Opiniones que necesito. No creo
que tarde mucho, pero por si acaso. Ahí mandé a prepararse el gráfico de Promedios. Lo que queda
es armar los gráficos de Evolución temporal y los de Interés final en función de Kappa.

Ahí cargué el archivo de Python y mandé a armar el gráfico de interés final. Estoy pensando en
que quizás no pueda correctamente llenar el espacio de abajo a la izquierda del poster.

Bueno, lo que me queda hacer entonces es descargar los gráficos de Promedio, los de Opinión
vs Tiempo y el de Opinión final vs Kappa, agregar los detalles en el gráfico de Varianzas
(Quizás explicarlo un poco mejor), quizás pueda usar el espacio extra para agregar la expresión de
campo medio y retocar los títulos de las secciones y las conclusiones. Suena a algo que puedo hacer
en la mañana tranca.

Para que sea más fácil de encontrar mañana, fijate los gráficos de evolución temporal en
Complemento_Poster con Kappa = 1.5.

------------------------------------------------------------------------------------------

08/05/2023

Ya descargué los gráficos y organicé el poster. El poster quedó bastante bien, agregué
los gráficos de Promedio de interés, el de interés final en función de Kappa y los de interés
en función del tiempo. Voy a corregir unos títulos, unos colores, agregar unos detalles 
a los gráficos en el google y listo, poster terminado. Mientras se grafican las cosas faltantes
en Oporto, iré agregando música a la playlist de TREFEMAC 2023.

Me confundí el Parámetro 1 y el 2 al graficar los OpivsTiempo, así que lo tengo que hacer de nuevo
eso. Ahora mismo se está armando el gráfico de Varianzas primero. Después correré los de OpivsTiempo.
Por último el de Promedios.

Al final terminé el poster sin hacer los gráficos esos, no iba a llegar. Las conclusiones quedaron
un poco flojas, pero cosas que pasan.

------------------------------------------------------------------------------------------

19/05/2023

Del 09 al 12 del 05 fui a la TREFEMAC. El lunes 13 vine a la facultad y me puse a hacer cosas
de F1, si no me equivoco. Creo que estuve todo el día haciendo ejercicios. El martes
fui a cursar y después a dar clase de F1. Nahuel me dió los parciales y me puse a resolver el
punto 3. El miércoles empecé a corregir parciales. El jueves a la mañana fui a la defensa de
tesis de Ignacio Sticco. A la tarde seguí corregiendo parciales.
 Hoy a la mañana fue a hacerme el estudio preocupacional, después di clases de F1 y a la
tarde fui a la reunión sobre el nuevo plan de la carrera. Por último tomé estas notas. El
lunes me queda tomar notas en el cuaderno, así como ver de llamar a un cardiólogo y a Personal
para hacer el cambio de plan.

Ya me acordé, el lunes me volví temprano para cambiar los libros y comprar el canasto. No pude
cambiar los libros, pero conseguí mi canasto.

------------------------------------------------------------------------------------------

02/06/2023

Los días que pasaron del 19 a hoy los estuve anotando en el cuaderno. El 22 y 23 estuve
principalmente corrigiendo parciales. El 23 volví tarde a casa, tipo 21:30 salí de
la facultad. El miércoles 24 laburé desde casa. El 25 y 26 fueron feriados, pero igual
laburé porque estoy con mucho con las materias de F1 y MEFE.

Esta semana fue bien estándar. Laburé en F1 y MEFE el 29, el 30 cursé y di clases. También
arranqué con el tema de los papeles para entregar a RR.HH. Es un bardo impresionante eso.
El jueves a la mañana Seba dió una charla sobre LLM (Chat-GPT, Bard, cosas así). Me parece
que es una buena señal de que debería empezar a usar estas cosas. 

Hoy fui a la mañana a conseguir el informe del electrocardiograma. Lo que no estoy consiguiendo
es turno médico para terminar los estudios clínicos de rutina. Lo que sí podría hacer es
intentar ver lo que me dijeron del UMA, hacer una consulta clínica por Zoom. Quizás
eso me sirva.

Después di clases de F1. Ahora estoy terminando la Burocracia infinita. Lo que voy a hacer ahora
es empezar a revisar lo que hice y prepararme una idea de cómo encarar mi laburo a partir
de la semana que viene. 

Ahí armé una lista con todos los temas que tengo pensado, me parece que es una buena charla para
tener con Pablo para arrancar y fijar el trabajo. El lunes seguiré con MEFE y veré si puedo enviar
los papeles importantes para RR.HH. También debería ver de conseguir mi tarjeta de crédito del
Nación.

------------------------------------------------------------------------------------------

05/06/2023

Estuve todo el día copiando la carpeta de MEFE de las notas que tenía de Constanza. No llegué
a terminar de copiarlo todo.

------------------------------------------------------------------------------------------

06/06/2023

A la mañana fui a cursar MEFE. Vimos el tema de asignar intervalos de confianza a los parámetros.
Después fui a dar clases de F1. A la tarde copié un poco más de la carpeta de MEFE y me junté
con Pablo para charlar sobre el TP. Estamos de acuerdo en que el modelo parece estar bien
caracterizado. Lo siguiente sería quizás empezar a pensar seriamente en el interés del
modelo. ¿Qué pregunta quiero responder? ¿Qué cosa espero ver con el modelo?
 Una idea para trabajar esto es leer unos papers, ver de sacar unas ideas de qué hacen los otros
trabajos relacionados con sus modelos.

También Pablo me dijo que prepare la idea del Republia.

------------------------------------------------------------------------------------------

07/06/2023

Hoy no estoy tan muerto de sueño como ayer, pero la mañana se me hizo lenta, fue complicado
salir de casa. Estuve toda la mañana terminando de firmar los papeles para RR.HH. Al final
los envié. No hice lo del Siradig. Ni idea de cómo completar eso, no pude conseguir clave fiscal
en la app de MiAfip. No me tomó el DNI.

A la tarde copié cosas de MEFE y me fui a dar consultas. Creo.

------------------------------------------------------------------------------------------

08/06/2023

A la mañana me puse a ver el TP Computacional de MEFE. A la tarde fui al principio de la jura
de Constanza, Walter, Rodri y Julián. Después di la clase de consultas contra turno más poblada
de esta cursada. Eran 10 contra mi. Me defendí bastante bien. Después fuimos con Constanza,
Walter y Rodri a morfar algo.

------------------------------------------------------------------------------------------

09/06/2023

Día clásico. Cursé, después fui a responder consultas. Por último trabajé un poco en el TP
computacional de MEFE.

------------------------------------------------------------------------------------------

12/06/2023

Hoy estuve trabajando en el TP Computacional 2 de MEFE. Resolví lo necesario para el punto
2 y un poco del 3. A la tarde me junté con Constanza y resolvimos hasta el 5 más o menos.
No está para entregar, pero aprendimos bastante del tema.

------------------------------------------------------------------------------------------

13/06/2023

A la mañana cursé MEFE un rato, después fui a F1 porque estuvieron rápido con consultas.
Después fui a la reunión de los voluntarios para la organización de las olimpíadas
metropolitanas de Física. Ahora estoy haciendo la burocracia infinita y ya después me
pongo con el copiar la carpeta de MEFE. Después tengo que estudiar parciales.

------------------------------------------------------------------------------------------

23/06/2023

Pasaron varios días desde la última vez que escribí acá. El 13 fue martes, el miércoles 14,
jueves 15 y viernes 16 no sé qué hice. Habré estado copiando la carpeta de MEFE y haciendo
algunos ejercicios de F1. No estuve avanzando en nada en el tema de Tesis. Después 19 y 20
fueron feriados, aunque yo estudié MEFE. El miércoles arrancó la cosa heavy con semana de la
física y cosas. Jueves más semana de la física y consultas contra turno. Hoy rendí el parcial
de MEFE. Más tarde di clases de F1 y después me puse a hacer ejercicios de F1. A lo último
fui a la reunión de doctorandos.

------------------------------------------------------------------------------------------

06/09/2023

Existe una posibilidad de realizar un trabajo en colaboración con una gente de España que 
publicó un paper utilizando un modelo similar al de Baumann. Pablo me dijo de ir armando
una simulación multidimensional de un modelo similar al de ellos. Para eso tengo que tomar
mi código de la tesis y a partir de ahí ver de hacer unas simulaciones para mostrar la 
aplicación del modelo al caso multidimensional. Tengo que ver de revisar el código
que cargué al Github y ver de actualizarlo con el nuevo formato más legible del código actual.
Esto va a ser un poco un bardo, pero quizás logre tener algo armado para el miércoles.

------------------------------------------------------------------------------------------

07/09/2023

Acabo de tener una revelación horrorosa. Descubrí que llevo bastante más laburo del que
recordaba sin registrar en la documentación. Todas las documentaciones están desactualizadas.

.) La documentación en la carpeta Programas C/Programas está desactualizada.
.) La documentación en la carpeta Programas Python está desactualizada.
.) La documentación en la carpeta de Imágenes está desactualizada. Encima el cruce de carpetas
de cosas que hice en el primer año con las del segundo año me está confundiendo.

La semana que viene voy a ver si puedo ponerme a organizar esto. Primero tendría que agarrar
la documentación en Imagenes y separar lo que es del año pasado con lo que es de este año.
Y marcar la transición supongo. Luego podría ir leyendo el archivo de Progreso para ir viendo
cómo avanzaron los programas. Con eso tendré una buena idea de qué hice en cada carpeta. Tengo
que aceptar de que posiblemente la carpeta de Programas no estará correctamente actualizada. Pero
asumo que lo que hice en las distintas etapas razonablemente es muy similar y por eso nunca terminé
de cambiar los archivos del src.

Ahora lo que voy a hacer es separar el archivo actual y lo pondré en una carpeta llamada Exploración
Logística. Por lo que estoy viendo de mis notas, eso es lo último que hice. Queda entonces descubrir
qué son las carpetas de imágenes que sobran en mis archivos, pero creo que podré tener más respuestas
cuando mire lo que tengo en la facultad. Vale aclarar, no vas a encontrar nada en el archivo de Progreso,
recién lo repasé, no anoté nada importante. Putos microcambios. El tema de esto es que realmente no
pudieron haber muchos cambios. De haberlos, el Git debería haber notado la diferencia en los códigos.
Qué raro. Va a ser un tema deshacer la trama de archivos superpuestos y mezclados.

La nueva etapa se va a llamar Homofilia Estática, ya que vamos a tratar de implementar homofilia en redes
estáticas. Después tengo que armar redes de Erdos-Renyi para mis simulaciones, así lo que hago matchea
mejor con lo que hizo esta gente. Aprenderme sus nombres estaría bueno.

------------------------------------------------------------------------------------------

12/09/2023

No tengas miedo. El 08/09 fue viernes, diste clases, revisaste alguna cosa y te fuiste.
El 11/09 fue lunes y te dedicaste a la entrega del TP de la guía 1. Hoy a la mañana
estuve preparando la clase de F2. Queda entonces hacer un poco de lo del código y mañana
a la mañana, antes de las 11:30, voy a releer el paper de la gente esta de España.

Miré más documentación de más carpetas. Está todo mal. La semana que viene arranco a organizar
esto. Lunes y miércoles a la mañana le damos a esto de lleno. Lo importante es que ya tengo
un código que creo que funcionaría. Mañana veré de mandar a correr el armado de las redes
y ya después me pongo a leer el paper.

------------------------------------------------------------------------------------------

13/09/2023

A la mañana leí el paper de la gente de España para prepararme para la reunión. Tomé algunas
notas y me marqué unas ideas. Igual la charla fue más que anda dada entre Pablo y los muchachos.
Quedamos en que voy a arrancar con las simulaciones y dentro de dos semanas nos juntamos.
Lo que charlamos es más o menos lo que veníamos charlando de hacer en conjunto, el plan
sería extender el modelo, revisar cuál es el comportamiento en el espacio de Beta-Cos(delta),
ver si podemos proponer el delta como algo variable y que depende de las opiniones de los
agentes.

Yo ahora voy a ir a cursar. Mañana mi plan es hacer bastantes cosas de F2 y ya el viernes
después de F2 podría ponerme a hacer cosas de la tesis. La semana que viene lunes y miércoles
a la mañana me pongo a organizar cosas, fuerte. Martes, jueves y viernes me pongo con el
armado del modelo y cosas. Quizás este finde también haga un poco. Por lo menos revisar
el VPN para ver que todo funca y después mandar a correr aunque sea una prueba con N=1000.
Revisar los grados medios de esas redes. También podría el finde ponerme a organizar las
documentaciones, aunque creo que en la facultad tengo más info para revisar eso.

------------------------------------------------------------------------------------------

15/09/2023

En la mañana estuve preparando el código de Homofilia Estática. Después fui a responder consultas en F2.
Un alumno me consultó por un ejercicio de dos cuerdas unidas, revisar de hacerlo para
la clase que viene. O consultarlo con Gabriel o alguien. Zoe dijo que lo tenía hecho.

Después de eso comi, fui al CASI, intenté integrarme a un grupo pero no funcionó. La próxima
será. Mandé a correr el código con 10000 agentes, por lo que ví tarda 20 minutos resolver
una simulación, así que hay que planear bien esto. Espero poder hacer funcionar todo en casa
durante el finde. Ahora voy a subir todo a Github, ya el finde lo que tengo que hacer es:

.) Borrar el código viejo en src, o por lo menos mandarlo a una nueva carpeta para después
mirarlo e intentar descubrir lo que estuve haciendo.
.) Armar redes de 10000 agentes y grado medio 8 en Oporto.
.) Corregir la distribución de los datos iniciales, porque se están haciendo sólo en valores positivos
y debería ser uniforme entre [-kappa, kappa]. Considerar si hay algo que pueda hacer para más o menos
definir la región si Kappa es chico, pero creo que no es tanto problema eso.
.) Preparar las carpetas para recibir los datos nuevos.
.) Cambiar los Instanciar y Metainstanciación.
.) Mandar a correr las simulaciones. La idea sería barrer Beta [0.5, 1.5] y CosDelta [0,1]. Aunque estaría
bueno revisar cómo lograr armar las simulaciones que les dan a ellos. Supongo que podría armar
esas tres simulaciones aparte.
.) Revisar las funciones de Python para ver que los códigos que levantan y arman los gráficos funcan
todo bien.

------------------------------------------------------------------------------------------

17/09/2023

Es domingo, son las siete de la tarde. Mandé a correr el código. Hasta donde sé, funca bien. Lo probé
en la pc de la facultad y funcionó sin problemas. Ojalá funque bien. Aproximadamente va a tardar
40 horas. Estoy usando los 20 hilos de Oporto, estoy corriendo el programa de forma de armar simplemente
20 simulaciones. Mis simulaciones no tienen guardados datos de testigos más allá de las primeras dos
o tres simulaciones, me sigue pareciendo una buena idea. Si bien son 40 horas, asumí que va a terminar
el martes a las 19. Puedo ver de intentar mandarlo a correr de nuevo el martes a la tarde cosa de
armar otras 20 simulaciones, total hasta el jueves tengo tiempo de armar las funciones de Python.

Es importante que pruebe las funciones de Python que grafican, ver que hacen lo que quiero. Eso lo
puedo probar el jueves en la facultad.

Importante recordar, la función de crear redes arma redes de Erdos-Renyi con grado medio 10.

------------------------------------------------------------------------------------------

20/09/2023

El lunes 18 y el martes 19 no avancé con el código, estuve dando clases de C, cursé Caos,
Fractales y Solitones, di clases en F2 y después tuve que buscar unos papeles. Días complicados.

Vamos a ver si puedo encontrar el motivo de por qué el código funca mal en Oporto. O si puedo hallar
una solución al tema de armar datos.

Por lo que veo, el problema no parece ser que el programa no corre. El problema es que los valores
están continuamente oscilando y mi programa no corta. ¿Y si lo hago cortar en un tiempo dado?
Eso podría ser una solución mañana. También estoy viendo que mi cálculo de distancias es una
cosa rara muy mal definida. Voy a usar la definición que hace Baumann del cálculo del producto
escalar de dos vectores, aprovechando la matriz de superposición.

Parece que el error estaba efectivamente en el hecho de que se calculaba mal la distancia entre
agentes. Mañana tengo que armar ese producto de forma que sea adaptable al cambio del número de
tópicos. Y recalcular el tiempo que tarda en armarse los datos.

------------------------------------------------------------------------------------------

21/09/2023

Siguiendo con la idea que me tiró Sofi, voy a mandar a correr datos en la pc de Oporto cosa de ver
primero que mi código replique lo que ven la gente de España en los tres casos que marcaron en su
paper. Voy a construir 40 simulaciones en los puntos con (Kappa=0.5,Beta=1), (Kappa=10,Beta=0.1) 
y (Kappa=10,Beta=1.5). También voy a separar el código en dos carpetas, una para datos 1D y otra 
para datos 2D. La idea es que el código 1D directamente toma la norma entre vectores como si fueran
vectores ortogonales. Eso no es un problema porque en 1D no hay un espacio multidimensional que pueda
ser no ortogonal. Mientras esto corre, yo me encargaré de ir armando una función que calcule la norma
no ortogonal. Con esa función implementada, creo que no voy a necesitar separar en casos 1D y 2D.
Aunque tener carpetas separadas será útil para diferenciar los datos.

Por otro lado, debería borrar los datos viejos de Oporto para poder armar nuevos datos. Ver cuánto
van a pesar, eso es importante.

Luego de hacer eso, armaré la función que calcula la norma para vectores de dimensión N en un espacio
no ortogonal. Esa función necesita que le pase la matriz de superposición.

Ya borré los archivos en Cambios_parametros y en CI_variables. Dios quiera que no vuelva a necesitar
esos datos en el futuro. Rearmé las carpetas, cosa de poder usar eso para construir la Documentación
en el futuro.

Armé la función que calcula la norma de un vector en un espacio no ortogonal. La probé y funciona bien.
Ahora queda ver si con esto el sistema correctamente converge a donde tiene que ir. Lo bueno
es que esta implementación del código es robusto ante un caso de dimensión N, por lo que no tengo
que separar si el código trabaja un caso unidimensional o bidimensional o incluso si quisiera de más
dimensiones.

Mandé a armar una simulación de 10000 agentes que finalice si realiza 20000 pasos temporales o más.
La idea es ver si el código corre, si finaliza o si sigue dándole eternamente. El código 1D tarda
unos 30 minutos aprox. El 2D debería tardar 40 minutos como máximo, no crece tanto el orden de cuentas,
se duplica con suerte.

Estoy viendo de subir el archivo que grafica opiniones vs tiempo a Oporto. Estoy notando que ese archivo
está hardcodeado porque proviene del código de Complemento_Poster, así que voy a tener que deshardcodearlo.

Creo que resolví eso bien. Confío en que la forma robusta del código con el Pandas va a resolver
correctamente el conflicto cuando intente graficar Betas y Kappas que no están asociados.
Quiero decir, por como está hecho el código, va a querer graficar los datos de Beta=1.5 y Kappa=0.5,
pero no simulé eso. Igual, el intento de graficar eso surge sólo si hay archivos en la lista, porque
eso depende de un for que recorre una lista. Si la lista es vacía, no hace nada.

Subí la carpeta con el nuevo src a Oporto y el viejo código lo dejé en HE_v0. Mañana lo pensaré con
un poco más de calma y veré de borrar esa carpeta. O la puedo dejar ahí hasta el próximo miércoles.
Eso suena mejor. También subí el código de Python, ya si todo está bien, puedo armar los gráficos
de Opinión en función del tiempo. Qué buen código que armé, me quiero mucho.

Ya armé los gráficos del caso unidimensional, se ve tal cual ve la gente de España. Éxito.

------------------------------------------------------------------------------------------

22/09/2023

En la mañana mandé a correr una simulación del caso multidimensional. Aproveché para corregir 
el tema de que inicializar sólo creaba opiniones positivas. Eso estaba mal en el código del
modelo multidimensional, pero no en el código unidimensional. Por eso se ven bien los datos
armados. Y corregí el detalle de que no estaba liberando el puntero de Intermedios.

Pasé todos los archivos necesarios para poder correr en Algarve cosas, así que ahora tengo
40 hilos para hacer funcionar todo. Vamos a ver qué tal. Queremos tener unas simulaciones
armadas y revisar el comportamiento del sistema. Ponele que cada simulación tarda 20 minutos
para 1000 agentes en 2D. 

Primero que nada, Pablo me dijo que mande cinco simulaciones para K menor a 1. Hagamos eso
directamente con el Metainstanciación, usemos 10 hilos para armar 10 simulaciones y fue.
Esto lo voy a mandar a OPORTO. Lo que mandé es a armar 10 simulaciones para N=1000, 
Beta[0.5, 1, 1.5], Cdelta = 0 y Kappa = 0.1. Armo unas cosas más, me voy a casa y después
desde casa mando en Oporto también a correr. Visto que esto corrió en un pedo, puedo mandar
a correr otras cosas más ya.
 La segunda tanda de simulaciones, de las "cinco" que me dijo Pablo, tienen Kappa = 3 y
Cdelta = [0, 0.25, 0.5, 0.75, 1].

Tengo que cambiar los nombres de los archivos, porque los estoy guardando con Beta y Delta,
pero si también barro en Kappa, entonces esto va a estar mal siempre, se van a ir reescribiendo
los datos.

Mientras mandaré a correr datos en ALGARVE. Voy a fijar Kappa a 3, barrer beta entre 0 y 2
y Cos(delta) entre 0 y 1. Si Beta va de a 0.2, entonces son 11 valores, mientras que si
Cos(delta) va de a 0,2 son 6 valores. A 10 minutos cada simulación, eso son 660 minutos
una tanda de esto. Eso multiplicado por 10 simulaciones me da 6600 minutos, o lo que es
lo mismo, 110 horas. Esas 110 horas repartidas en 15 hilos son 7.3333 horas. Hagamos 30
simulaciones y me da 22 horas. Todo bien.
 Repito para que quede claro, en ALGARVE están los datos con los que voy a armar el diagrama
de fases. En OPORTO están los datos para hacer una exploración rápida.

Finalmente, mandé a correr datos en Oporto y Algarve. Me faltan en Oporto la tanda de simulaciones
con K mayor a 1.

------------------------------------------------------------------------------------------

23/09/2023

Hoy en la tarde revisé los datos. Por un lado, se terminaron las simulaciones de K chico en
Oporto, así que mandé a armar las simulaciones en K grande. Esas deberían estar terminadas
para mañana. Con eso voy a poder armar unos gráficos de opiniones en el espacio de fases.
Ahí voy a ver rápidamente el comportamiento del sistema en esas regiones.

Por otro lado, en Algarve se terminaron las simulaciones para armar el espacio de fases barriendo
Beta [0,2] de a 0.2 y Cosdelta [0,1] de a 0.2. Como terminaron todas las simulaciones,
aproveché para mandar a correr una nueva tanda de simulaciones que completen los valores
de Cosdelta intermedios en la región [0,1] que no se completaron antes. Eso tardó un día.
Se me ocurre mandar a correr datos para completar los otros datos que faltaron del Beta entre
0 y 2, pero ya veré mañana para eso.

------------------------------------------------------------------------------------------

24/09/2023

Los datos que mandé se terminaron, tanto los de Algarve como los de Oporto.
En Algarve quiero mandar a correr datos, pero también quiero ver si lo que ya tengo
produjo resultados. Voy a hacer una carpeta de copia, "2D_copia", en la que tenga los
datos que armé hasta ahora. Mientras el programa se pone a armar datos y los guarda
en la carpeta de 2D, yo trabajaré con lo que está en 2D_copia. En Oporto en cambio
creo que no tengo que simular nada más, así que queda revisar los datos. Con los
datos de Oporto me voy a poner a armar gráficos. Con los de Algarve armaré los mapas
de colores del espacio de fases.

Ahí miré mi código de Python, no es robusto ante la existencia de varios N que graficar.
Siempre lo armé pensando en un sólo valor de N. Tengo que considerar cómo implementar la
posibilidad de que mi conjunto de datos tenga varios N y grafique según el N. Eso queda
como tarea para después.

------------------------------------------------------------------------------------------

25/09/2023

Lo primero que voy a hacer en la mañana es armar un archivo que haga los gráficos de 
trayectorias de opiniones en el espacio de fases. Cuando lo pase a Oporto y Algarve no me
tengo que olvidar que los archivos de ahí tienen tres parámetros en el nombre. Es decir que
tengo que rearmar la formulación de lo los archivos. Voy a revisar después si los archivos
1D también tienen tres parámetros, creo que no.

Tengo que corregir además el main que tengo en la pc de la facultad, que es distinto al main
que armé en las pcs del cluster. En las pcs del cluster cambié la forma en que el código se
dirige a la carpeta adecuada y los nombres de mis archivos. Ese cambio surgió en cuanto agregué
la forma correcta de calcular distancias no ortogonales. Creo que tengo que tener en cuenta
en el futuro de rearmar datos 1D que los nombres de archivos viejos son distintos a los nombres
de archivos nuevos.

Armé un archivo nuevo para probar que se grafique todo bien. Si se grafica bien, lo mando a
Oporto y Algarve.

Después de comer mando a hacer los gráficos en el espacio de fases de los datos de Algarve. Tengo
que rearmar los códigos de funciones y de Graficar para que tomen tres parámetros del nombre de
los archivos.

------------------------------------------------------------------------------------------

26/09/2023

Hoy a la mañana me desperté y recordé el espíritu del código original que tomaba los dos parámetros
que iba a graficar y de ahí corría todo asegurándose que en el eje X esté lo que tenga que estar, en
el eje Y lo mismo. Yo ayer en la noche, flasheando que tenía que extender la función a tres variables
corregí eso posiblemente cagando el código. Ahora lo que voy a hacer es mandar a correr esto para
armar los gráficos en el espacio de fase que tengo que armar, y mientras eso corre, voy a mirar desde
Github cómo estaba el código antes, dejarlo como estaba y corregir en graficar cuál es el parámetro
1 y cuál el 2, para que el código que inteligentemente armé hace unos meses siga funcionando lo más
bien.

Voy a rearmar mi código, con algo más razonable, que es llamar parámetro x al que grafico en el eje x
y parámetro y al que va en el eje y. El resto de los parámetros les pondré el nombre que les corresponde.

------------------------------------------------------------------------------------------

27/09/2023

Armé mis funciones para graficar el mapa de colores de Promedio de Opiniones
y Varianza de Opiniones. Las hice rápido las funciones, así que tienen un
vector de más, podría resolver lo mismo gastando menos espacio de memoria.
Básicamente, puedo deshacerme del Opifinales. Eso queda para el futuro.

Notas de la charla con Hugo, David, Mario y Jesús:
--------------------------------------------------

El tema de la distancia no es menor.

Propusieron tres formas de entender el tema de los pesos.

.) La primera es considerar que calculo la distancia como una norma en el espacio.
Esa distancia puede ser considerando el espacio ortogonal o el no ortogonal.

.) La segunda es considerar que se calculan pesos distintos por cada tópico.
Esos pesos se calcularán viendo las distancias entre las opiniones en cada tópico
por separado. Entonces el peso en el tópico 1 se calcula con las distancias
en el tópico 1.

La idea sería armar histogramas de agentes en el espacio de tópicos. Para armar
los histogramas me recomendaron que guarde mejor los datos, intentando obtener el
histograma directamente de la simulación. Eso va a ayudar a que los archivos no pesen
cerca de 200 megas cada uno, haciendo imposible el guardar datos.

El plan sería que yo arme simulaciones diferenciando si uso un tipo de distancias
o el otro.

----------------------------------------------------------------

Voy a ver de resolver para mañana el hacer la burocracia infinita y quizás el viernes
arrancar a reorganizar la documentación. Y la semana que viene resuelvo lo de los gráficos
de histogramas que me dijeron e implemento el tema de las distancias. Tengo que tener
cuidado con lo que es el armado de las carpetas y diferenciar correctamente las
etapas del trabajo.

------------------------------------------------------------------------------------------

28/09/2023

En la mañana llevé a ver el tema de las gomas del auto, llegué tarde a la facultad y
después me puse a ver lo de inscribirme en la escuela de Brasil. También vi que salió
la prueba de oposición para el cargo de laboratorio superior. Honestamente, ni idea 
de qué presentar, así que me voy a mantener afuera de eso.

Después en la tarde finalmente me puse con los temas de F2, siendo que primero repasé
contenidos de fórmula de D'Alambert y después empecé con los ejercicios.

------------------------------------------------------------------------------------------

29/09/2023

En la mañana seguí con ejercicios de F2. Después fuimos a responder consultas y a la tarde
me puse a completar mis notas y la burocracia infinita.

------------------------------------------------------------------------------------------

02/10/2023

Hoy a la mañana mandé a correr los datos para complementar el barrido que hice antes. No
implementé todavía la función que arma los histogramas en los datos que salen de C. Tengo
bastantes cosas por hacer y no es algo tan importante todavía. Total, todos los archivos que
tengo, que son 45 simulaciones en el espacio que quiero barrer, me ocupan 13G. Mi plan es
tener 5 veces eso, así que sólo me va a ocupar 65 G. Menos en realidad considerando que los
Testigos están contabilizados en esos 13, pero no voy a generar más.

Entonces, tengo que barrer, modificando para que el Metainstanciación arranque desde la iteración
46 y de ahí corra hasta 200. Y que además el Beta ahora corra en todos los valores desde
0 hasta 2 de a 0.1, no de a 0.2. Bueno, antes de sumar hasta 200 simulaciones, voy a sumar
hasta 105. Es decir, 60 iteraciones más. Quizás estoy haciendo mal el cálculo, pero como
las simulaciones pueden tardar cualquier cosa entre 60 segundos y 1120, no sé cuánto considerar
en promedio para hacer las simulaciones. Lo que hice fue considerar un promedio de 400 segundos.
En ese contexto, me da que sumar esas 60 iteraciones implica 4 días de laburo. Arranco con eso,
después quizás sumo más.

Ya lo mandé a correr. Espero que salga todo bien. Ahora me voy a poner a revisar lo de la clase
de F2. Así ya mañana llego preparado. Después el resto de la semana será Sistemas Complejos y
laburo de tesis.

------------------------------------------------------------------------------------------

06/10/2023

Efectivamente la semana fue lo que anoté. El martes y miércoles me dediqué a cosas de Sistemas
Complejos. El jueves preparé cosas en distintos grupos y preparé la clase de F2. El viernes
a la mañana di clases y después me puse con el tema del doctorado.

Me armé una función que arma los histogramas 2D. Tengo que ponerla a prueba. Para eso voy a armar
unos datos en la pc de la facultad, y luego sobre eso lo mando a correr. Si los gráficos salen bien,
ya puedo mandar eso a Algarve y armar todos mis nuevos gráficos.

Ahora que tengo esto podría ponerme a preparar el código para el caso de distancias distintas que
me pidieron o podría ponerme a actualizar la documentación. Me tienta más lo segundo.

Se armaron los datos, pero no tengo más tiempo. Probaré la función en casa. Después en la semana
seguiré con la actualización de la documentación. Actualicé la de los programas en C. Ya es algo.
Yo continuaría con la Documentación de las imágenes.

------------------------------------------------------------------------------------------

10/10/2023

El 9 estuve todo el día con el tp de Sistemas Complejos. Al final no resolví el último punto,
pero logré hacer la mayor parte. Walter me pasó su TP para tener una idea, pero veré qué
tal puedo resolverlo por mi cuenta.

Volviendo al trabajo de hoy, lo primero importante es mandar a hacer algunas simulaciones
en las que veo tres o cuatro puntos relevantes como para hacerme una idea del comportamiento
del sistema en esas regiones. Lo siguiente es reacomodar los gráficos de Histogramas obtenidos
cosa de que coincidan con lo visto en las trayectorias de opiniones.

Podría hacer simulaciones para Beta= 0.1, 1, 1.5 y eso combinarlo con Cos(delta)= 0, 0.5, 1.
Ahora, el tema es que tengo que armar métricas distintas. Podría armar dos métricas de
acá a mañana. En principio se me ocurre que podría con dos. La primera sería sacando el
cos(delta) de la tanh, y que sólo exista en los pesos w_ij. La segunda sería que la
distancia entre las opiniones sea con independencia total en las opiniones, generando
pesos diferenciados según el tópico.

Es importante entonces diferenciar esto en tres etapas, más que nada para no confundir
los datos. Y bueno, también para no confundir los códigos. Así que guardo el código
que tengo actualmente y me armo dos nuevas carpetas con códigos. Mañana o 
pasado me pondré con la documentación.

Acabo de notar que el laburo que hice el finde no lo comitee. Por tanto, el laburo que estoy
haciendo ahora va a entrar en conflicto con eso. Lo que me importa preservar de ese finde es
más que nada lo que hice en el archivo de funciones. Podría simplemente ignorar en este commit
el "laburo" que hice en el archivo y después committear lo de hoy. Creo que suena como un plan.
En ese caso mejor ir yendo así ya voy resolviendo esa diferencia.

------------------------------------------------------------------------------------------

11/10/2023

Evité el conflicto de los merges. O la mayor parte por lo menos. Ahora tengo que ponerme
a hacer dos cosas. La primera es mandar a correr datos con la métrica que no tiene el cos(delta)
en la tanh. La segunda es rearmar los gráficos de histogramas para que me coincidan con los de
trayectorias.

Ya hice lo primero. Ahí mandé a hacer los histogramas. Si esto está bien, entonces lo que me queda
es ponerme a armar una presentación.

Notas de la charla:
-------------------

.) Revisar medidas de Kurtosis o cosas para ver si las distribuciones se asemejan a uno,
dos o cuatro picos. También podría estar bueno ver la covarianza como medida para
diferenciar los picos. El coeficiente de correlación es otra cosa que se puede utilizar.

.) Ver si para betas apenas por encima de 1, se requiere cosdelta más grande para romper la
polarización. Repasar este concepto.

.) Buscar la cruz que se forma para betas menores a 1 y cosenos delta bajos.

.) Estaría bueno hacer un análisis similar al que hacen ellos para redes con beta=0. En ese caso
surgen estados polarizados si modifican las condiciones iniciales y la red. Lo interesante es
ver que para redes de ER con grado medio bajo se forman estados polarizados cuando no
debería pasar. Entonces podríamos hacer algo similar con el estudio con el parámetro
superposición de tópicos.

.) Armar un barrido fino del espacio Beta-Delta guardando los histogramas. Aunque ese barrido que me
está pidiendo es algo que ya tengo.

.) Revisar cómo da lo de la entropía para distinguir los estados.

.) Y también considerar qué está pasando con las simulaciones que saturan. ¿Esas están bien, o deberían seguir
oscilando?

------------------------------------------------------------------------------------------

19/10/2023

Superada la reunión del 11/10, el jueves 12 no trabajé mucho en esto, estuve con cosas
de F2 o de Sistemas Complejos. Honestamente no recuerdo qué pasó ese jueves. Di consultas
y hablé con Guille y Gabriel sobre el problema 1 del parcial.

De viernes a lunes no laburé en esto, cosas del parcial y de Sistemas Complejos. Además fue
finde largo todo eso. El martes tomamos el parcial de F2 y después a la tarde cargué los
archivos de PDF a la carpeta de Parciales. El miércoles estuve laburando lo que pude
en Sistemas Complejos.

Hoy a la mañana resolví el tema de cargar mi CBU a AFIP para el reintegro del IVA. Después
organicé partidas y me puse por último a revisar Documentación.

Armé la documentación sobre las carpetas de imágenes. Me queda actualizar la documentación en
la carpeta de Python. Estuve pensando en mandar a correr simulaciones. Podría por un lado
aprovechar y aumentar las simulaciones de Homofilia_estática en Algarve cosa de tener
200 simulaciones. Y mientras tanto, armar otras 200 simulaciones en Oporto del modelo de
Tangente_diferenciada. La paja de eso es que voy a tener que recordar dónde están los
datos de qué, pero supongo que no es tanto bardo por ahora. En el peor de los casos,
podría pasar los datos de una pc a la otra y listo. Yo creo que es posible eso y que
vale la pena. Hagamos esto de las dos simulaciones. Es más, armemos una prueba y veamos
si puedo copiar datos de una pc a otra. Parece que Algarve no está encendida.

------------------------------------------------------------------------------------------

24/10/2023

El viernes 20 arranqué a leer el paper, tuve clases de F2 y después vino el DF Abierto.
El sábado y domingo 21 y 22 seguí laburando, tanto en el TP de CFS como en el paper
para la reunión de grupo.
El lunes 23 en la mañana terminé de leer el paper y a la tarde fui a cursar CFS. Corrieron
la fecha de entrega del TP al miércoles 25.

Hoy a la mañana terminé la presentación para la reunión de grupo. Ya la cargué al Drive
que pasó Ale. Fui a responder consultas de F2. Tengo que ponerme al día con las guías.

Di la charla de grupo. Salió bastante bien, me la elogiaron bastante. Me alegra.
Se resolvió correctamente esto.

Ahora voy a mandar a correr datos en Oporto y Coimbra. En Oporto voy a mandar a correr
los datos de Tangente_Diferenciada que barran en el espacio Beta=[0,2] de a 0.1 y 
Cos(delta)=[0,1] de a 0.1. Serán 200 simulaciones por punto del espacio de parámetros.
Corro esto en Oporto porque tengo todo básicamente armado para eso. Después copiaré
los archivos para mandar a correr eso en Coimbra.

Al final no mandé a correr cosas en Coimbra. Me tomó un montón de tiempo simplemente descargar
los datos. Voy a ver de borrar las cosas innecesarias como los archivos de datos. Esos
no los necesito porque los tengo en Oporto.

------------------------------------------------------------------------------------------

31/10/2023

El miércoles 25 terminé el TP 3 de CFS. Desde entonces hasta hoy básicamente estuve laburando
en cosas de F2. Ahora voy a ver de mandar a reproducirse los gráficos de histogramas 2D
a ver si encuentro los gráficos de cruz que hablamos la otra vez. Voy a ver si puedo más o
menos mandar a correr datos en Oporto.

Mandé a continuar las simulaciones del caso de tangente diferenciada. Revisando los archivos de 
salida, me parece que razonablemente todos los hilos habían completado 4 simulaciones de las
11. Ahora queda que oporto siga laburando.

------------------------------------------------------------------------------------------

03/11/2023

El 01 y 02 de Noviembre estuve corrigiendo parciales y me mudé de vuelta a San Fernando.
Hoy arranqué mirando los archivos de los histogramas. Son muchos gráficos, pero más o menos
va yendo la cosa. Encontré dos gráficos interesantes. Uno con la cruz que dijeron que tenía
que aparecer, otra con tres puntas.

Estos gráficos aparecen para valores de Beta cercanos a 1 y con cos(delta) = 0.
La primer cruz la vi en Beta = 0.8, Cos(delta) = 0 y sim=58. Hay varias cruces más en
Beta =0.9. Quizás un barrido más fino cerca de 1 genera otras cruces.

Lo que debería hacer ahora es tomar los datos que tengo en la pc, armar una función que 
calcule la traza de la matriz de covarianza y comparar eso con algunos gráficos cuya forma
conozco.

Estoy recordando que por ahora mis funciones son vulnerables a que si tuviera varios N o varios
Kappa, entonces eventualmente lo voy a tener que corregir eso.

Estoy mirando las covarianzas. No puedo diferenciar correctamente un estado de cuatro puntas de uno
de dos puntas. Ahí le mandé unos mensajes a pablo con lo que fue una primer observación de esto.
Se me ocurre que vale la pena armar un mapa de colores utilizando la traza de la matriz de Covarianza
y ver qué se observa. Qué detecta la matriz de Covarianza y qué no.

------------------------------------------------------------------------------------------

06/11/2023

Hoy estuve con bastantes cosas así que avancé poco con el tema del doctorado, pero mandé a armar
un mapa de colores para el espacio de parámetros usando la traza de la covarianza como métrica para
diferenciar estados. Faltaría sumarle algo más.

Ahora voy a ir a cursar CFS.

------------------------------------------------------------------------------------------

08/11/2023

Una buena idea sería modificar el K=10 para poder observar mejor las cruces que me mencionan.
En esa región la tanh se puede aproximar más por uno. También podría ser posible que en una
de esas la cruz nunca se forme. Quizás se forma una nube.

Enfocarme en las simulaciones más en la región entre 0.5 y 1.5, el resto se resuelve con menos
estadística porque no es tan importante. Eso va a ayudar a hacer más rápido las simulaciones.

Revisar el tiempo que duran los estados metaestables. Me propusieron que debería mirar el cómo
evoluciona la polarización de los estados en función del tiempo. Debería usar una métrica para definir
si está o no polarizado, luego de eso ver la fracción de polarización en función del tiempo y con eso
determinar un tiempo de corte razonable.

Ellos proponen dos medidas para definir la diferencia entre estados polarizados y no polarizados.
La primer medida es una distancia de las distribuciones al centro para definir si el estado es
polarizado o no, y luego el uso de la covarianza para diferenciar los tipos de polarización.
Se podría considerar una entropía de Leibler creo, o información mutua. Esto me parece 
que en principio es mucho, vamos a arrancar con la covarianza.

Una tercera propuesta es usar la Kurtosis para diferenciar qué tan bimodal es una distribución.
Hugo propone que no es necesario encontrar una respuesta a eso, pero la curtosis podría darnos una
medida de eso.

Pablo dijo que hay un test para determinar si una distribución es unimodal o bimodal.

Dijo Hugo que lo primordial es revisar el espacio de parámetros y definir la fracción de estados
polarizados.

##########################################
Lo primero y lo último son lo más urgente.
##########################################


------------------------------------------------------------------------------------------

15/11/2023

Voy a armar una etapa nueva para probar las métricas que nos propusieron la otra vez.
Específicamente la métrica de distancia de las opiniones al centro y la de la covarianza.
Esta etapa razonablemente será Prueba_metricas. La idea es armar un código de Python que genere
datos sintéticos. Estos datos sintéticos voy a usarlos como forma de medir que tan bien las
métricas diferencian estos estados.

¿Qué estados necesito generar?
-------------------------------

1) Consenso neutral: Todos al centro. (Una configuración posible)

2) Polarización en un extremo: Todos a una esquina. (Cuatro configuraciones posibles)
3) Polarización a un extremo con anchura: Que haya una distribución desde el centro hasta ese
extremo. Podría además hacer que esa distribución sea homogénea, bimodal, más grande en un 
extremo o en el otro. (Cuatro por cuatro configuraciones posibles)

4) Polarización a dos extremos: Todos a dos esquinas. (Seis configuraciones posibles)
5) Polarización a dos extremos con anchura: Al igual que en el anterior, anchura entre los extremos.
Me parece que justamente, si tengo dos extremos, los agentes se ubican en las rectas que unen esos extremos,
no en rectas en otras direcciones. Si armo todas las combinaciones posibles, esto va a cubrir los casos en
que las opiniones se distribuyan de forma horizontal o vertical. (Seis por cuatro configuraciones posibles)

6) Polarización a tres extremos: Todos a tres esquinas. (Cuatro configuraciones posibles)
7) Polarización a tres extremos con anchura: Al igual que en el anterior, anchura entre los extremos.
Acá no me parece tan obvio entender cómo va la anchura, pero diría que entre las tres puntas se puede
dar, es decir que repartiría agentes de forma que haya anchura formada por "dentro" de las tres esquinas
y por los "bordes". (Cuatro por cuatro por dos configuraciones posibles) No creo que use todas las configuraciones
posibles en este caso.

8) Polarización a cuatro extremos: Todos a cuatro esquinas (Una configuración posible)
9) Polarización a cuatro extremos con anchura: En este caso me parece que sólo conviene considerar la
anchura por "dentro". (Uno por cuatro configuraciones posibles).

Antes de hacer esto, me junté con Pablo y charlamos de cuál es el plan de cosas a hacer. Para eso me
parece clave entonces primero probar lo que charlábamos de ver si cambiando el dt puedo trabajar el sistema
con un dt=0.1. Eso haría que todo vaya 10 veces más rápido. O más incluso. Probemos entonces con
hacer unas simulaciones de prueba y enviarlas a Homofilia_estatica. Usaré simulaciones con K=10.
Esas no se van a mezclar con las que ya tengo. Voy a mandar una simulación con dt=0.01 y otra con dt=0.1.
Ambas con el mismo número random, 1511. Probaré esto para algún valor lejos de la interfaz,
con beta=2 por ejemplo, y otro sobre la interfaz, con beta=1. Si todo va bien, genial. Ir bien sería
que me dan los mismos valores de opiniones finales para ambos casos. Esto va a tomar un rato en correr
igual, mientras esto se resuelve, pasaré a otra cosa. TENGO QUE DOCUMENTAR LAS NUEVAS ETAPAS.
Para diferenciar las simulaciones, la de dt=0.01 tiene número de iteración 10. La de dt=0.1
tiene número de iteración 100.

El sistema tarda claramente menos, casi 10 veces menos. Pero no parece llegar a los mismos estados.
Parece que los saltos bruscos lo pueden hacer llevar a estados distintos, eso lo veo en que las opiniones
finales de bastantes agentes no coinciden en signo. Voy a armar los histogramas y ver qué observo.

Comparando los histogramas, los estados finales son prácticamente iguales. Puedo hacer las cuentas con
el dt=0.1 sin miedo. Ale y Ale están usando Oporto y Coimbra. No tengo mucho lugar para laburar eso.
Mañana, o quizás cuando llegue a casa, mandaré a correr nuevos datos.

Hoy antes de irme voy a ver de mandar a correr los datos para barrer la región con kappa y
cos(delta). Eso voy a mandarlo a correr en Coimbra, supongo.

------------------------------------------------------------------------------------------

16/11/2023

Hoy todo lo que estaba corriendo Ale Mildiner en Oporto se fue. No hay nada corriendo ahí. Es
mi oportunidad de ocupar todos los hilos. Voy a mandar a hacer un barrido de datos en el espacio
de Beta_Kappa con un dt de 0.1. Creo que es oportuno cambiar la etapa. Esta será Medidas_polarizacion.
Tendrá dos carpetas, una para ver la región de Beta_Kappa con cos(delta)=0, y otra para ver la región
una vez que tengo Kappa en 10.

Lo importante por lo que voy a separar esto de la carpeta de Homofilia_estatica es que en esa
yo estaba trabajando con dt=0.01, como hace Baumann. Sin embargo, hablando con Hugo y David
nos dijeron que podemos usar dt=0.1. Yo probé dos puntos para ver cómo da el sistema, y es muy
similar lo que da en ambos casos.
 Necesito barrer Beta entre 0 y 2, hagámoslo de a 0.1. Por otro lado tengo que barrer Kappa entre
0 y 20. Hagámoslo de a 0.5, aunque veamos si puedo hacer el [0,1] de a 0.2.
 Por lo que vi ayer, esto haría que las simulaciones que tardaban 200 segundos tarden 7, y la
de 520 segundos tardó 250. Entonces supongo que puedo más o menos promediar 100 segundos por simu-
lación. No necesito mucha estadística, con 40 iteraciones me sobra.
 Así que tengo 21*48*40*100 = 4032000 segundos = 1120 horas. Esto dividido en 10 hilos serían 112 horas,
o lo que es lo mismo, 4 días y medio. Estaría más o menos para las elecciones. Intentemos que esto
se termine antes. Aprovecho para reducir la cantidad de pasos máximos del sistema, porque al cambiar
el dt, cambio el tiempo máximo al cual el sistema llegaría. Ahora llega 10 veces más lejos. Puedo
entonces reducir a la mitad la cantidad de pasos máximos, creo que no estaría mal.

Ahí mandé las simulaciones. Me apropié de Oporto. Espero que sean sólo dos días como mucho.
No parece que vaya a ser sólo eso nomás. Ojalá el sistema converja rápido.

Mientras eso corre hay dos cosas que tengo que hacer. La primera es armar datos sintéticos y poner
a prueba las métricas que charlamos con Pablo. La segunda es documentar las etapas que estoy
armando.

Luego está la tercera, que es intentar armar algo para medir la fracción de polarización de
estados. Para eso voy a necesitar mandar a correr datos en Coimbra.

Aproveché y armé una carpeta que sea de Medidas_polarizacion en mi carpeta, le puse los archivos
de Python de Prueba_metrica y después subí eso a Oporto.

