------------------------------------------------------------------------------------------

22/03/2024

Al final terminé de revisar los archivos del barrido Beta-Kappa, sólo había problemas en la iteración
90 a 99. Así que tendré que en Oporto mandar a correr dos conjuntos de datos separados. Uno que recorra
todo el espacio para iteraciones entre 90 y 99 y otro que recorra el espacio para Beta mayor a 1
para iteraciones entre 50 y 69.

Voy a aprovechar la mañana para preparar el main cosa de que cuando se termine la corrida de Oporto,
que va a terminar en uno o dos días, ya lo pueda mandar a correr rápido. Después de comer me pondré
con el análisis de la ecuación dinámica del modelo. Bien, ya modifiqué el Instanciar. Lo que tengo
que hacer es mandar las simulaciones de 50 a 69 en Oporto mañana a la tarde.

------------------------------------------------------------------------------------------

26/03/2024

En la mañana fui a llevar el documento de matrimonio de mamá al estudio, pero al final el documento
no estaba actualizado. Tendré que conseguir la actualización del registro civil y de ahí
volver a intentar.

Las simulaciones en Algarve terminaron, así que podría mandar a resolver las simulaciones entre
80 a 99.

Hoy la verdad me agaró un sueño imposible, no avancé mucho. Pero estuve mirando lo que me pasó Hugo
y lo que tengo yo de la cuenta, logré armar la misma expresión para la derivada de la perturbación.
Queda entonces ver dónde queda efectivamente el valor de Beta de transición. Lo interesante es que
aparece un factor 2 que antes no estaba. Vamos a ver cómopuedo hallar entonces el valor de Beta de
equilibrio.

------------------------------------------------------------------------------------------

27/03/2024

Lo primero que hice en la mañana fue revisar mails, después mandé a correr las simulaciones entre
90 y 99 en el barrido beta-kappa en Oporto. Con eso voy a tener todas las simulaciones en ese espacio
y voy a poder armar los gráficos con la estadística de 100 simulaciones. Eso debería durar de acá a
la semana que viene. Quizás.

Mientras estoy haciendo el análisis de la ecuación dinámica para definir el Beta tal que el estado de
polarización ideológica transiciona de ser inestable a estable.

------------------------------------------------------------------------------------------

04/04/2024

En la mañana revisé las carpetas de Oporto y demás para ver que todo estuviera corriendo bien, mandé
a armar gráficos en Oporto ahora que tengo las 100 simulaciones por punto y estuve intentando pensar
cómo armar el gráfico que Pablo me pide que haga sobre el espacio Beta-Kappa.

Mientras tanto, se siguen resolviendo las simulaciones que faltan del espacio reducido Beta-Cos(delta).
Esas simulaciones van a terminar cerca de tres o cuatro días.

Lo que tengo que hacer ahora primero es ver cómo armar un gráfico que muestre clarametne la composición
de estados en el espacio Beta-Kappa. A partir de eso, podría pensar un mapa para el espacio de
Beta-Cos(delta).

Hoy apenas miré las cosas, no hice mucho más. La verdad, siento que perdí buena parte del tiempo. Dios,
como odio estos días. Y eso que vine temprano y todo.

------------------------------------------------------------------------------------------

05/04/2024

Hoy estuve todo el día armando los gráficos de distribución de estados en el espacio de parámetros.
Logré hacer los gráficos tanto para el espacio Beta-Kappa como para el espacio Beta-Cosd.
Siento que no son la gran cosa, pero Pablo me dijo que haga algo así, o mejor. Yo saqué esto.
Tengo que ser mejor que esto, espero estar mejorando con el tiempo, no estar estancándome.

Bueno, no nos matemos, mañana partida, el domingo tarea de Alemán y del curso de aplicaciones
a becas. Lunes retomamos con ganas y fuerzas.

------------------------------------------------------------------------------------------

08/04/2024

Hoy llegué más o menos temprano, los trenes están tardando mucho ahora, temas de despidos.
VLLC. A la mañana voy al curso de inglés. Revisé las simulaciones en el espacio reducido.
Ya casi están todas terminadas, queda una sola en la carpeta de algarve. Así que después de
comer, junto todas las simulaciones de Algarve en Coimbra y desde ahí armo los gráficos del
parámetro de espacios.

Veamos qué simulaciones tengo en cada pc. En Coimbra tengo dos carpetas.
) Datos: 0-9.
) Zoom_beta-Cosd: 30-39, 50-79.

Algarve.
) Zoom_beta-Cosd: 10-29, 80-99

Oporto.
) Zoom_Beta-Cosd: 40-49

Ahora lo junto todo. Ahí mandé a correr para que se armen todos los gráficos del espacio reducido.
La pregunta es qué hago ahora. Para mi tiene interés revisar qué es lo que pasa con el sistema
para el punto fijo de cuatro extremos, ese análisis de la ecuación dinámica, que creo que
razonablemente dará que Beta crítico es 1, yo creo que será una investigación interesante.

Otra cosa que puedo hacer esperando a la reunión con Pablo, es armar la presentación para el
miércoles. Aunque eso lo puedo hacer mañana. Lo tercero sería ponerme a leer algún paper en
el tiempo hasta juntarme hoy con Pablo.

Hablé con Pablo, la idea es armar los gráficos indicando las regiones no con colores, sino delineando
los contornos, usando números romanos para indicar las regiones, luego colocar cerca gráficos que
indiquen estados finales característicos y explicar cómo es que terminé definiendo esas regiones.
En particular, si habría alguna forma de identificar mejor la curva que surge en el espacio Beta-Kappa,
la cuál yo definí puramente a ojo.

Ahí armé los gráficos que me dijo Pablo, me falta colocarle los números romanos al segundo. Mientras
se están terminando los gráficos en la región reducida. Tengo mala espina.

------------------------------------------------------------------------------------------

09/04/2024

Revisé Coimbra, se hicieron los gráficos del espacio reducido. Se ve algo interesante respecto
de los estados con anchura, y se ve que coinciden los resultados con lo observado en el espacio
total Beta-Cos(delta).

Sigamos con el trabajo de Pablo hasta eso de las 11 y algo. Después a las 12 voy a comer, a las
13 voy al abrazo en el 0+inf y después a cursar.

Terminé de cursar, trabajé un poco en la presentación y después me fui a casa temprano para que
no me agarre la lluvia.

------------------------------------------------------------------------------------------

10/04/2024

A la mañana llegué y mandé a armar gráficos de Histogramas 2D. Después tuvimos la reunión de grupo.
Comí en la oficina y rápido terminé de armar lo que pude de la presentación para la
gente de GOTHAM. Pablo hoy no pudo venir, lo mismo Jesús. La charla la tuve yo con Hugo
y Mario.

De la charla saqué los siguientes puntos:
1) En el espacio de parámetros Beta-kappa, la curva que diferencia estados de Consenso Radicalizado
respecto de los estados Polarizados, en principio Hugo la estudió bastante desde varias perspectivas.
Su conclusión es que es un resultado de la saturación de la función de tanh. Una propuesta que
me hizo es intentar ver si reemplazando la función tanh por una función signo, entonces
debería ver si esa curva desaparece y sólo veo una línea constante en Beta aprox. 0.2.
2) Hugo me dice que esos estados de polarización descorrelacionada que estoy observando
si los dejara correr más tiempo, posiblemente vería que convergen a otro tipo de estados,
quizás Pol 1D con anchura o Pol 1D nomás, yo no creo que sea el caso. Vamos viendo.
3) Algo interesante sería intentar ver si el modelo 2D para el caso de Cos(delta) = 0 se puede interpretar
como dos modelos unidimensionales independientes. Una forma de comprobar eso sería tomar un
punto del espacio de parámetros en el cuál surjan estados de polarización descorrelacionada
y comparar esos estados con estados polarizados en el caso unidimensional. Si el caso 2D con
Cos(delta)=0 se pudiera interpretar como dos simulaciones independientes, una para cada tópico,
entonces lo que debería poder observar es que la polarización simultánea de ambos tópicos debería
ocurrir con una probabilidad que es la probabilidad al cuadrado de que cada tópico polarice. Y
eso se debería obtener a partir de realizar simulaciones 1D. Para ellos esto es una pregunta
interesante respecto de cómo el modelo 2D no es sólo el modelo 1D 2 veces, sino que trae algo
propio a la formación de opiniones por la distancia entre opiniones. (Creo)
4) Cuando vaya a hacer los cálculos analíticos, probar hacer unas simulaciones primero, para
ver que efectivamente lo que quiero ver se da como yo planteo y no perder un montón de tiempo
en cuentas que no llevan a nada.
5) Al hacer las simulaciones con las que vamos a trabajar, no guardar todos los datos, sino guardar
sólamente el histograma de datos. Y considerar que ese histograma de datos tiene que tener
una cantidad de cajas que coincidan con la cantidad de cajas de las preguntas que voy a mirar,
porque algunas preguntas tienen 6 cajas y otras 7.

------------------------------------------------------------------------------------------

11/04/2024

A la mañana hablé con Pablo sobre lo que fue la charla con la gente de GOTHAM. El plan ahora
es armar una lista de cosas para hacer en estas tres semanas hasta la próxima reunión. Ahora
mismo no estoy realizando simulaciones. Debería considerar arrancar con eso, para que ya
esté funcionando antes de hacer el resto de cosas.

En la mañana estuve organizando cosas, mandando mensajes, imprimiendo comprobantes y así.
Mañana voy a ir a buscar las fotos de mi recibida. Para eso, tengo que llamar antes. Entonces,
a eso de las 14 llamo y después a las 17 salgo para allá, total es tomarme el tren hasta Retiro,
pedalear 10 minutos desde ahí y después volverme.

Hagamos la lista de orden de cosas por hacer esta semana y la que viene:
(Una idea que propusimos es ya fijar Kappa=10 y dejar de preocuparnos)
-----------------------------------------------------------------------

Es importante arrancar con esto porque requiere simulaciones, así que eso puede ir corriendo
mientras hago otras cosas.
########################################################################################################
1) Podría arrancar con las simulaciones del sistema usando la función signo en vez de la función
tanh. Eso me parece importante para arrancar porque va a requerir varias simulaciones. Digamos
que lo armo con 30 iteraciones, eso debería alcanzar para ver algo. Y el espacio que voy
a barrer debería ser de Kappa [1,10], con Beta de [0,1]. Después puedo ver de agregar
más Kappa, pero lo importante es hacer un barrido bien rápido de la cosa, variar grueso,
con Kappa variando de a 1 y Beta variando de a 0.1. Esto ya lo podría mandar hoy.
2) Empezar a descargar los datos de la ANES, ir construyendo un conjunto de datos con 10000
agentes cosa de tener para ir comparando nuestras simulaciones con los datos extraídos de las
encuestas. La idea sería armar datos en la región reducida de Beta-Cos(delta). Además, tengo
que asegurarme de guardar los datos, no guardando las opiniones de TODOS los agentes finales,
sino guardar el histograma final de los agentes. Hugo me dió un consejo de cómo guardar los
datos de forma de poder comparar mis resultados en el caso de que la opinión tenga 6 respuestas
o de que tenga 7.
3) Hugo me dijo de hacer simulaciones en un punto del espacio de Parámetros donde observe
varios casos de simulación y que por un lado corra simulaciones en el modelo 1D y por el otro
corra simulaciones en el modelo 2D. La idea es ver si la probabilidad de observar estados polarizados
2D es igual al cuadrado de la posibilidad de que polarice un estado 1D. Esto tendría alguna comparación
en el caso en que Cos(Delta)=0, siendo que en ese caso la ecuación del tópico 1 queda casi
completamente desacoplada de la ecuación del tópico 2. Hay todavía un pequeño acople en lo que
a los pesos refiere, así que no debería ser lo mismo. Digo yo. Esto puedo mandarlo por un lado
en Algarve y por el otro en Coimbra, con 10000 agentes. Creo que habíamos discutido que era
una buena idea usar esa cantidad de agentes.
########################################################################################################

4) Antes de continuar las cuentas analíticas sobre el valor de Beta que cambia la estabilidad de las soluciones,
conviene intentar primero hacer simulaciones con redes completas y con la pequeña perturbación
propuestas, para ver si el resultado corrobora lo esperado. Así nos damos una idea del resultado
final. Después de esto puedo retomar mis cuentas. Eso significa, PRIMERO, revisar que me quedó
una cuenta pendiente del caso en el que considero la solución ideológica. LUEGO, continuo la cuenta
del caso de polarización descorrelacionada.

Cosas más opcionales:
---------------------
5) Hugo me había dicho la otra semana que revise si pasaba que partiendo de un estado que yo
sé que finaliza en un estado de polarización radicalizada, al ir aumentando el cos(delta) el
estado se transforma en un estado de polarización ideológica. La idea está buena y no requiere
mucho esfuerzo. Creo.
6) Me dijeron de revisar si encuentro encuestas en Argentina que nos permitan observar
polarización, porque en las encuestas que buscaron en España, la mayoría no tiene casos de polarización.
7) Podría ver de continuar con el clasificador neuronal, aunque en principio no es ni de
cerca necesario ahora.

Después de haberme distraído un poco, resolví el punto 1. Cambié la función en el archivo de avanzar,
armé una nueva etapa llamada Func_sign y mandé en Oporto a correr este barrido en la región que 
determiné antes.

------------------------------------------------------------------------------------------

12/04/2024

A la mañana fui a realizar el trámite del Banco Provincia. Llegué a la facultad a las 13.

Ahora estoy revisando la lista de cosas por hacer. Entre lo que tengo que hacer, me parece que
es mejor empezar por el punto 3 y no por el 2. Más que nada porque el punto 2 va a tardar tanto
que empezarlo ahora o el lunes da lo mismo, el otro punto en cambio me parece que me va
a dar resultados más rápido.

Estuve muy distraído hoy, pero armé el programa que simula en 1D. Más tardé con el armar una función
que en C me construya mi histograma. No era tan difícil, sólo soy un boludo que está desatento.
Ahora tengo que subir esto a Algarve o Coimbra y mandarlo a correr. Fijate que esto no contempla
estar en una carpeta de src. Pero creo que no es problema, simplemente tengo que compilarlo y
mandarlo. Voy a tener que modificar el archivo de Instanciar quizás, pero nada grave. O el
de Metainstanciacion. Espero que cuando arme la función para el caso 2D esto sea más fácil.
Vamos para casa. No es temprano en realidad.

------------------------------------------------------------------------------------------

15/04/2024

Al final el finde no hice la tarea que planeaba hacer, pero no fue tan terrible, la semana
arrancó igual y estamos todos bien. A veces no tiene tanto sentido hacerse la cabeza con
eso.

Hoy lo que tengo que tener terminado es el armado de las opiniones en cajas al final de la simulación,
cosa de ya mandar eso y entonces de los siete puntos que marqué para hacer, tener ya dos
resueltos.
 Repasé la función para el caso 1D, ahí logré hacer que funcione. El caso 1D está planteado
para redes con N=1000, Beta=0.7, Kappa=10 y Cosd=0. Cada simulación tarda 215 segundos.
Así que si corro 30 simulaciones en ese punto, no debería costarme más de 20 minutos,
siendo que esas simulaciones las voy a repartir en 10 hilos. Después tengo que subir
el archivo de opinion.e a Algarve y desde ahí modificar el Instanciar para mandar a correr
la simulaciones 1D.

Ahora me pongo con las simulaciones 2D. Logré que compile. Mañana lo mando a correr en las
pc's de la facultad. O quizá hoy en casa si llego temprano y no estoy para jugar ranked.
Perdí un poco de tiempo en esto, pero al final del el armar estas funciones que me construyan
los histogramas en el código en C es importante para el siguiente punto a trabajar.
Es cierto que faltan dos cosas importantes:
1) Probar que la función esa esté laburando bien. MUCHO MUY IMPORTANTE.
2) Organizar correctamente el cómo interpreto los números que la cosa esta
me tira. Así identifico correctamente qué va dónde. Armar las cajitas de 6*6 o las de 7*7
va a ser un bardo. Bah no, mentira, va a ser una boludez.

------------------------------------------------------------------------------------------

16/04/2024

No puedo mandar a correr las simulaciones en la pc de Algarve, ya fue, lo corro en la pc
de la facultad. Mientras eso corre, mandé las simulaciones en Coimbra, eso no fue tan simple.
Había un error medio boludo en la función de clasificación. Ahora me voy a poner a estudiar
alemán. Tengo que después hacer caso a mis notas sobre revisar que todo funcione bien,
no puedo moverme a ciegas como estoy haciendo ahora. Si bien la función está copiada
de algo que funciona, tengo dudas.

Fui a cursar Alemán.

Mandé en la pc de Coimbra para realizar 1000 simulaciones. Eso debería tardar unos días.
Mientras, voy a necesitar simulaciones en la pc de la facultad que lleguen hasta 1000 también
de 1D.

Repito para que no se olvide, es mucho muy importante que pruebe que las funciones de Clasificación
están funcionando bien. Para eso voy a tomar algunas simulaciones, usar sus semillas y simular en
la pc de la facultad. A esas simulaciones les voy a guardar las opiniones finales, y las distribuciones.
Voy a comparar que las distribuciones me den lo mismo que las opiniones finales.

------------------------------------------------------------------------------------------

17/04/2024

Mandé en la pc de la facultad cuatro procesos para resolver 250 simulaciones en cada terminal.
En la pc de Coimbra ya está casi terminada la tanda de simulaciones para el punto del espacio
Kappa=10, Beta=0.7 y Cosd=0. En la carpeta de Oporto está terminado el barrido en el espacio
Beta-Kappa para la función signo. Así que ya podría trabajar en ver que efectivamente se arma
el gráfico que esperamos.

Yo creo que hoy tendría que hacer dos cosas. La primera es ver de descargar datos de la ANES,
así ya puedo mandar a correr datos. Lo segundo es ver que efectivamente la función Clasificación
funciona bien. Para eso voy a descargar algunas simulaciones, rearmar esas simulaciones en esta
pc usando las semillas, guardar las opiniones finales y comprobar que los gráficos que puedo
recrear usando las distribuciones que surgen de la función Clasificación son iguales a las
distribuciones que surgen de las opiniones finales.

Tengo unas dudas sobre qué hacer con el tema de los datos de la ANES. Vengo revisando mis archivos,
no encuentro algo de lo que me decía Hugo de tener cuidado al revisar los datos de la ANES.
Lo que voy a hacer, luego de debatirme y pensar qué corno quiero, es hacer gráficos de distribución
de opiniones confrontando todas las preguntas entre ellas. 

Estoy revisando las etiquetas. Labels_pre tiene 20 etiquetas mientras que labels_post tiene 9 etiquetas.
Juntos suman 29 etiquetas. Pero dict_labels tiene apenas 23 etiquetas. Es decir que de las 29 etiquetas
que mira, sólo 23 están identificadas. Debería esforzarme por identificar las otras 6.
Ahí vi, las seis que están removidas en labels_pre y labels_post son 6 preguntas en labels_pre
que tienen 4 respuestas, en vez de seis o siete. En labels_post sacaron la pregunta sobre si Obama es
musulman, pero no la de ubicación propia a lo largo del eje conservador/liberal. Supongo que para arrancar,
por hoy, puedo dejarla.

Observando los gráficos, encontré claros casos de: Consenso Radicalizado, Polarización Ideológica, Polarización
1D con anchura, Polarización descorrelacionada, y quedaría definir qué cuenta como casos con anchura
o algunas cosas más. Creo que lo que estaría bueno es poder definir qué pares de preguntas vamos a
revisar y con qué vamos a comparar esos casos. También vale notar que algunos casos resulta que tienen
algunas casillas vacías. Quizás para no hacer un barrido demasiado grande y poder observar estos
resultados, estaría bueno moverse con Beta entre [0.6,1.2] y Cos(delta) entre [0.05,0.15]. Y para
eso hacer un barrido BIEN grueso, total no busco con eso caracterizar alguna curva, sólo quiero tener
gráficos para comparar con lo observado en la ANES.

Voy a descargar entonces cinco archivos de Probas_Pol en 2D así ya mañana arranco con los gráficos
para revisar que la Clasificacion está funcionando bien. Descargué cinco simulaciones al azar, las
cinco pareciera que convergen a estados de Consenso Radicalizado. Voy a tener que armar las simulaciones
mañana usando esas semillas y ya después veo qué pasó.

------------------------------------------------------------------------------------------

18/04/2024

A la mañana fui a llevar el acta de matrimonio al estudio de traducción, y volví al mediodía. Después
me puse a ver los datos del barrido en el espacio Beta-Kappa. El gráfico pareciera dar lo que yo busco,
pero no se ve muy claro. Debería probar extender un poco la región y hacer un poco más fino el barrido.
Mañana lo hablo con Pablo cualquier cosa.

Ahora me voy a poner a estudiar Alemán. Después me pondré con lo de escribir la carta de motivación y el 
CV. Por último, con algo de tiempo, quizás lea un paper. Mañana repasaré el tema de las simulaciones
en el espacio Beta-Kappa, y de las simulaciones en un punto del espacio de parámetros.c

------------------------------------------------------------------------------------------

19/04/2024

Lo primero que voy a hacer es comparar el gráfico de Func_sign en el espacio Beta-Kappa
con el gráfico que tengo de esa misma región hecho en la etapa de opinión actualizada.
Para eso voy a tomar la función que arma el gráfico del espacio de parámetros de Entropía
y reducir la región de los ejes X e Y.

Mientras se resuelve eso, voy a probar lo de revisar que las funciones de Clasificacion
estén laburando bien. Aunque me descargué sólo gráficos con estados finales de Consenso.
Busquemos primero dos o tres gráficos en estados de polarización. No encontré estados de
polarización, pero encontré estados que tardaron mucho en resolver. ¿Estará funcionando
mal la función de Clasificación?

Voy a identificar los estados según su número de iteración.
.) Iter=100: Los agentes convergen a un estado de Consenso radicalizado, en el punto [10,-10].
Pero la función de clasificación dice que están todos en el lugar final. Lo cuál no tiene
sentido, porque si el valor de Y es -10, en la asignación el valor de "fila" debería ser 0
y por tanto la casilla marcada debería ser una de las primeras 42, no la última.
.) Iter=110: Convergen al punto [10,-10]. Van al mismo lugar que los anteriores
.) Iter=120: Convergen al punto [10,10]. Este sí le corresponde marcar en la última casilla
del vector de Distribución. Pero claramente parece que la función está funcionando mal.
.) Iter=130: Convergen al punto [10,10].

Es al pedo seguir con esto, efectivamente la función de Clasificación está mal, pero lo está
por un error muy boludo, y es que el ancho que usaba para ver si un número iba a una fila u otra
era 0, entonces al dividir por cero daba infinito y todos los agentes iban a parar al mismo
lugar. Así que eso está mal y tengo que rehacer todas las simulaciones corrigiendo simplemente
ese detalle.
 De paso, increíblemente, para el caso 1D sí hice bien el cálculo del ancho. Genial, eso significa
que eso está bien hecho y no necesito rehacerlo. Lo cuál es genial, porque estas simulaciones
eran más complejas de hacer porque no podía hacerlas en las pc's del cluster.

Voy a cerrar el día de hoy con tres cosas.
1) Mando a correr en Coimbra las simulaciones de un punto del espacio de nuevo. Esta vez corrijo
la función de Clasificacion para que funcione correctamente.
2) Mando en Oporto unas simulaciones extras de la región Beta-Kappa para intentar delinear mejor
lo que observo. La idea es expandir la región, no la cantidad de simulaciones.
3) Armo una carpetita con algunas simulaciones separadas del tema de datos de la ANES, así me queda
más sencillo para mostrarle a Pablo después lo de algunas distribuciones razonables.

Para el punto 2 hago un barrido extra, agregando valores de Kappa en los puntos intermedio.
1.5, 2.5 y así.

------------------------------------------------------------------------------------------

22/04/2024

A la mañana fui a la última clase del curso de "Becas:Help!". Tomé algunas notas sobre cómo
mejorar el CV y discutimos con los demás consejos para buen CV.

Lo que voy a hacer ahora es armar el gráfico del mapa de entropía para la función signo,
y después ver cuál es la proba de que un estado esté polarizado para el caso 1D y para el
caso 2D.
 Miré los archivos armados. Por motivos que no comprendo, faltan archivos, otros están armados
a la mitad. Hubo un corte, es imposible que no haya habido un corte.

Tengo descargados los archivos de agentes en un punto del espacio de parámetros, en los cuales
me guardé la distribución de opiniones finales, no las opiniones finales. Lo que tengo que hacer
ahora es con Python, levantar los datos, reordenarlo en el formato de una matriz y desde ahí
construir los gráficos de histogramas. Además de eso, lo otro que tengo que hacer es calcular
la proba de que un estado sea polarizado en el caso 1D y de que polarice en ambos tópicos
en el caso 2D.

1) Armo histogramas a partir de la distribución de opiniones.
2) Clasifico esos estados según los criterios definidos previamente.
3) Calculo la proba de tener estados polarizados en 1D y la proba de tener estados con
polarización descorrelacionada en 2D. (¿Debería comparar con polarización descorrelacionada?
¿Cómo es la proba si considero polarización 1D?)

De estas tres cosas que quería hacer, no hice ninguna. Siento que hoy podría haber hecho
más, pero estuve trabado toda la tarde. También hice muchas pequeñas cosas. Voy
a ponerme a pensar mejor cómo trabajar esto y ya el miércoles veré de resolverlo más claro.
Mañana voy a estudiar para el final de Mininni y después marcha.

Hablando con Pablo, él me dijo de que descargue yo los datos de la ANES para revisarlos,
así voy trabajando eso por mi cuenta. Debería separar preguntas políticas y no políticas,
así como separarlas según sus distribuciones. Después con eso ver qué tipo de gráficos
me quedan así tengo una buena idea de qué cosas espero observar. Mirar el paper de Baumann
y el de Hugo vendría bien para repasar qué es lo que estoy queriendo buscar.

Hoy y mañana me voy a poner a pensar cómo construir mis nuevas funciones en Python, cosa
de ya cuando em vuelva a sentar, ponerme a escribirlo de una y no volver a trabarme con
el cómo armar las funciones en el caso de Probas_Pol.

Por último, Pablo me propuso que arme más estadística a las simulaciones de Func_Sign,
no que barra más fino. Debería cancelar lo que mandé a correr y mandar de nuevo
con más estadística. Más que nada porque sino voy a tener un problema al querer armar
el gráfico porque algunos puntos van a tener más estadística y otros menos.
Lo que voy a hacer es mañana borrar las simulaciones con valores de Kappa fraccionarios.

------------------------------------------------------------------------------------------

23/04/2024

Ya borré esos archivos con valores de Kappa fraccionarios, mientras en Oporto se completan
simulaciones para llegar a tener 100 en ese barrido.

Ayer me quedé pensando en lo que dijo Sebas. Quizás es mejor seguir guardando las opiniones
finales de los agentes. Y además, me hice un quilombo queriendo usar la función de Hugo para
las simulaciones 1D. ¿Por qué no usar mis simulaciones? Si dan similares los resultados,
no tiene sentido diferenciar unas de otras. Podría usar mis simulaciones y con eso armarme
en Coimbra las 1000 simulaciones para el caso 1D y para el caso 2D. Mandemos hoy las 2D 
guardando las opiniones finales y después veo qué hago mañana.

Hablando con Pablo, los dos pilares para la próxima charla es trabajar con los datos y poner
en orden el análisis teórico. Así que por lo visto, no es central esto que estoy haciendo.
Pero como ya empecé, tengo que aprovechar y presentarlo.

------------------------------------------------------------------------------------------

24/04/2024

A la mañana lo primero que hice fue mandar a correr la tanda de simulaciones 1D de Probas_Pol
en la pc de Coimbra. Lo siguiente que voy a hacer es repasar las ecuaciones dinámicas cosa de tener
algo que presentarle a Pablo mañana y organizar los datos para la presentación.

Estuve avanzando con esto, aunque en eso vamos. Mañana me voy a poner en la mañana a estudiar
un poco de lo de Mininni y después seguiré con esto un poco más.

------------------------------------------------------------------------------------------

26/04/2024

En el día de ayer estuve trabajando en el análisis de la ecuación dinámica básicamente todo
el día. Fui a una reunión de grupo y llegué tarde por el tema de estar esperando el link para
la charla por el Repositorio de Investigación.

Hoy llegué, revisé el tema del análisis dinámico, charlé con Sebas y me propuso considerar un
análisis matricial similar a lo que veíamos en Mate 3. Igual creo que lo mejor sería probar
hacer lo que dijo Hugo, de hacer simulaciones sobre el análisis perturbativo y ver qué da eso.

Las simulaciones en Coimbra están terminadas. Las de Oporto todavía no. Debería por un lado
armar lo de Coimbra, cosa de tener por lo menos ese resultado. Pero creo que puedo dejar
eso para el próximo lunes sin dramas. Yo hoy me pondría a ver el tema de descargar datos de la
ANES. Voy a revisar la ANES, ver qué se puede descargar, qué preguntas hay y hacer esa separación
que me dijo Pablo de preguntas políticas y preguntas apolíticas, cosa de tener un conjunto
saludable de preguntas a revisar.

Ahí estuve viendo un poco de alemán, ahora sigamos con lo del modelo de opiniones. Descargué
los datos de la ANES, habrá que ver de armar el conjunto de preguntas que querramos observar.
Eso tomará un tiempo. 

------------------------------------------------------------------------------------------

29/04/2024

Llegué al horario usual. Me puse a revisar mails y cosas que quedaron pendientes. Ahora que
resolví eso, me pongo con las cosas que dejé corriendo.

1) Ver lo de la entropía en el espacio Beta-Kappa para la función Signo.
2) Determinar la fracción de estados polarizados en el caso 1D y en el caso 2D.
Usaré el algoritmo que tengo para eso y compararé con tomar 200 gráficos de histogramas
3) Leer un paper
4) Seguir laburando los datos de la ANES.

El punto 1 ahora no voy a poder, no terminó de correr eso.
Para el punto 2 necesito armar funciones que trabajen con un sistema 2D y un sistema 1D.

Logré armar uno de los gráficos de torta que quería, pero claramente esto no es lo más
interesante para charlar en la próxima reunión. Lo que deberíamos charlar en la próxima
reunión es el trabajo con los datos, de los cuales apenas armé unos gráficos nuevos
y después descargué los datos de la ANES de 2020. Así que la cosa viene lento en
ese tramo. Habrá que hacer nuevas cosas si quiero avanzar. Ahora voy a leer rápido
el paper de Sebas respecto a lo de Granovetter, al final no recuerdo si ese fue el
paper que leí o no. O si leí un paper en algún momento. Dicho eso, lo que sigue es
ponerme a revisar las preguntas y cosas del modelo. Así que hagamos esto y preparemos
para ir a casa temprano hoy. Iré a buscar el documento que necesitaba la semana que viene.

La idea sería primero que nada tomar las preguntas que tenemos y separarlas en función de
si son políticas o no. ¿Qué definimos como preguntas políticas? La respuesta es que las
preguntas políticas son aquellas que los demócratas o republicanos responderían distinto,
mientras que las apolíticas son aquellas que no apelan a esa identidad partidaria.

Anotemos esto en el código. Ahí hice la separación, básicamente todas las preguntas
son políticas. Razonable. Veré mañana si puedo encontrar unas ocho o diez no
políticas y de ahí veré cómo resuelvo esto. Pero el armado de los gráficos de histogramas
funciona de una.

------------------------------------------------------------------------------------------

30/04/2024

No llegué más temprano que lo usual, pero casi. Armé los gráficos de las distribuciones
de las opiniones diferenciando preguntas políticas y no políticas. Habiendo charlado con
Pablo, la pregunta sería ver si estas preguntas políticas cruzadas con ellas mismas me
generan gráficos distintos a cruzarlas con las preguntas no políticas. Aunque siento
que las preguntas no políticas apenas tengo casos que mirar, quizás valga la pena revisar
la ANES nueva y de ahí ver qué puedo extraer. Al final del día, la forma de levantar
datos que usa Hugo me podría servir para la nueva ANES creo yo, simplemente tengo que levantar
el csv y convertirlo en un pandas.

Lo siguiente que puedo hacer entonces son los gráficos de la distribución en el espacio de
opiniones y de ahí ver qué puedo rescatar. Comparemos preguntas políticas con otras políticas
y apolíticas con apolíticas. De ahí vamos armando los gráficos. Una vez que tenga los gráficos,
ampliar el conjunto de preguntas, porque no me satisface lo que tengo. No creo que tenga
suficientes apolíticas.

Antes que esto, Pablo me dijo de aplicar la medida de la distancia Jensen Shannon. Olvidemos
lo anterior, hagamos esto YA. No tengo una distribución para comparar, pero podría aprovechar
dos distribuciones que tengo acá y medirles su distancia Jensen-Shannon, ver que la idea se
puede y que da razonable. Bien, ya vi que calcula y cómo hacer la cuenta. En su momento será
un bardo ver cómo clasificar los gráficos según si son preguntas de 6 casilleros o 7.

Hice la cuenta sobre los datos de la ANES 2020, aprox. tiene 1200 preguntas. Veamos de levantar
los datos de la ANES 2020. Bien, los datos parece que se levantan sin problemas.

Preguntas Políticas 2020:
-------------------------
1) V201200: SCALE LIBERAL-CONSERVATIVE SELF-PLACEMENT (7 Opciones)
2) V201225x: VOTING AS DUTY OR CHOICE (7 Opciones)
3) V201231x: PARTY IDENTITY (7 Opciones)
4) V201246: SPENDING & SERVICES: SELF-PLACEMENT (7 Opciones)
5) V201249: DEFENSE SPENDING: SELF-PLACEMENT (7 Opciones)
6) V201252: GOV-PRIVATE MEDICAL INSURANCE SCALE: SELF-PLACEMENT (7 Opciones)
7) V201255: GUARANTEED JOB-INCOME SCALE: SELF-PLACEMENT (7 Opciones)
8) V201258: GOV ASSISTANCE TO BLACKS SCALE: SELF-PLACEMENT (7 Opciones)
9) V201262: ENVIRONMENT-BUSINESS TRADEOFF: SELF-PLACEMENT (7 Opciones)
10) V201342x: ABORTION RIGHTS SUPREME COURT (7 Opciones)
11) V201345x: FAVOR/OPPOSE DEATH PENALTY (4 Opciones)
12) V201356x: FAVOR/OPPOSE VOTE BY MAIL (7 Opciones)
13) V201362x: FAVOR/OPPOSE ALLOWING FELONS TO VOTE (7 Opciones)
14) V201372x: HELPFUL/HARMFUL IF PRES DIDN’T HAVE TO WORRY ABOUT CONGRESS/COURTS (7 Opciones)
15) V201375x: RESTRICTING JOURNALIST ACCESS (7 Opciones)
16) V201382x: CORRUPTION INCREASED OR DECREASED SINCE TRUMP (7 Opciones)
17) V201386x: HOUSE IMPEACHMENT DECISION (7 Opciones)
18) V201405x: REQUIRE EMPLOYERS TO OFFER PAID LEAVE TO PARENTS OF NEW CHILDREN (7 Opciones)
19) V201408x: SERVICES TO SAME SEX COUPLES (6 Opciones)
20) V201411x: TRANSGENDER POLICY (6 Opciones)
21) V201420x: BIRTHRIGHT CITIZENSHIP (7 Opciones)
22) V201423x: SHOULD CHILDREN BROUGHT ILLEGALLY BE SENT BACK OR ALLOWED TO STAY (7 Opciones)
23) V201426x: WALL ON BORDER WITH MEXICO (7 Opciones)
24) V201429: BEST WAY TO DEAL WITH URBAN UNREST (7 Opciones)



Preguntas Apolíticas 2020:
--------------------------


------------------------------------------------------------------------------------------

01/05/2024

Volví del cumpleaños de Estaban. Ahora queda ponerme a hacer algunas cosas, empezar a preparar
la presentación de mañana. Se me hace importante primero revisar que las preguntas que
arme tengan gráficos útiles. Si eso es así, lo siguiente será ir viendo quizás de empezar
la presentación. Si no es así, me pongo a buscar algunas preguntas más.

Por algún motivo que no comprendo, mi función me está tirando errores, a pesar de que no
tiene nada distinto a lo que tenía ayer. Resolveré esto mañana en la facultad.

Hagamos un esquema de la charla:
--------------------------------

1) Les comento que estuve mirando las preguntas que estaban en el archivo que me pasó Hugo
y revisando esos gráficos que producen para ver cuáles gráficos podríamos querer comparar
con nuestros datos, en caso de querer observar tal o cual estado.
 Muestro varios gráficos y coloco al lado las distribuciones con las que digo que se podrían
comparar.
2) No creo que de ninguna forma me dé el tiempo, pero podría intentar medir la distancia
Jensen-Shannon de algún gráfico en particular con la de una de las distribuciones obtenidas
de la ANES.
3) Les cuento que bajé los datos de la ANES 2020, logré leer los datos, los cuáles tienen un
formato muy similar, y construir gráficos parecidos. Para eso estuve revisando la guía de
datos y de ahí seleccionando preguntas que podrían ser relevantes o útiles.
¿Por qué queremos la encuesta más nueva?
4) Debería definir una región en la cuál realizar las simulaciones de 10000 agentes.
Eso debería poder hacerlo posiblemente si tengo una idea de qué gráficos quiero buscar.
En Beta razonablemente tenga que ir entre [0,1] y Cos(delta) entre [0,0.15]. Un barrido
medio crudo sería de a 0.05 para Beta y 0.01 para Cos(delta). Necesito saber cuánto va
a tardar esto.
5) Si queda lugar, mostrar alguno de los otros resultados.

------------------------------------------------------------------------------------------

02/05/2024

A la mañana preparé la presentación para la gente de GOTHAM. Armé los gráficos de las
distribuciones 2D y de ahí fui armando alguna idea de las cosas importantes.

Después de la reunión, fui al coloquio de Darío, aunque no pude ver mucho, volví para
anotar algunas cosas y después me fui a casa. Estuve como cuatro horas viajando para 
ir a buscar el documento que faltaba por el tema de la nacionalidad italiana. Todavía
sin suerte.

No pude mandar a correr el barrido en el espacio de parámetros para el caso de 10000
agentes. Mañana es lo primero que mando a hacer en la mañana.

------------------------------------------------------------------------------------------

03/05/2024

No estoy pudiendo mandar a correr simulaciones en la pc de Coimbra, no sé qué error está
encontrando el código. Voy a rehacer un código único desde la pc de la facultad y subir
eso a las tres pc's y de ahí mando a correr todo. A este código le falta las funciones
de Clasificación y los vectores asociados.

Mandé a correr en mi pc un archivo de 10000 agentes, veamos cuánto tarda en resolverse.
Es un estado con Beta 0, debería converger a un estado de Consenso Radicalizado. Está
tardando más de una hora esto. Es un muy mal presagio esto.

Mientras termina de correr el programa con 10000 agentes, voy a descargar los datos de
la ANES de años anteriores. Descargué las encuestas de 2012, 2008 y 2004.
La de 2012 parece que tiene un formato muy similar a las últimas 2, esa creo que se
podría agregar a lo visto sin mucho problema. Pero la de 2008 y la de 2004 tienen un
formato muy distinto y no estoy seguro de tener los archivos correctos para observar
las preguntas consideradas.

La de 2008 tiene un codebook separado para la encuesta pre y otro para la encuesta 
post. Habría que repasar el codebook para separar las preguntas. Lo bueno es que
parece que también usan números negativos para respuestas fuera de formato, pero
algunas preguntas tienen MUCHÍSIMAS respuestas con números por fuera de los primeros
10, habrá que revisar si son un problema o si se pueden ignorar.

NO TERMINÉ DE VER CÓMO ES EL FORMATO DE LA ANES 2004. TAMBIÉN TENGO QUE VER DE LEVANTAR
LOS DATOS, VER SI ME TIRA ALGÚN ERROR.

Justo terminó el código en la pc de la facultad. Por lo visto corre y llega a un resultado
razonable. El problema es la cantidad de tiempo que tarda. Tardó 11813 segundos en resolver
7000 pasos. Una locura es eso. Para 1000 agentes tardó simplemente 40 segundos. Las escalas
son completamente distintas. Veamos si funciona con los datos de clasificación. De paso,
el archivo apenas ocupa 900 kb. Casi un mega. Si tengo 100 simulaciones, para 36 puntos,
eso es aprox. 3 GB. Puedo simplemente guardarme las opiniones finales por ahora.

El código con la clasificación funca perfecto en la pc. Igual, quedémonos sólo con lo
importante, que serían las opiniones finales y la semilla. Comitteo esto y ya mañana
mando a correr todo. ACORDATE DE USAR UNA SOLA CARPETA DE REDES DE ADYACENCIA.

------------------------------------------------------------------------------------------

04/05/2024

Hoy a la tarde mandé a correr las simulaciones en las tres pc's, pero esto va a tomar
una eternidad. Hablar con Pablo y contarle que voy a meterme un momento en el código a ver
si hay algo que pueda hacer para hacerlo correr más rápido.

------------------------------------------------------------------------------------------

05/05/2024

Mirando el código, encontré algo que claramente está gastando mucho tiempo. Estoy calculando
varias veces el mismo peso. Tengo que hacerlo de forma tal de calcularlo una sola vez. Eso
va a reducir en mucho el tiempo de simulación. Ese error está en la función de GENERAR_SEPARACIÓN.

Otra cosa que no tiene que ver con tiempos de simulación pero que estaría bueno cambiar
es el hecho de que la matriz que guarda las tanh se llama Exp. Habrá quedado de otro código,
cambiar eso.

Lo tercero que se me ocurre que puede servir para achicar los tiempos es reducir primero
el ancho de la ventana de promedio, de 1000 a 500, y después cambiar el número de iteraciones
extras que el sistema necesita para cortar a 1500. En especial porque muchas simulaciones que
cortan rápido hacen 7000 pasos totalmente al pedo, cuando con 4000 o 3000 habrían terminado.

Estoy pensando en quizás cambiar la cantidad de pasos_maximos, pero Hugo y demás usaban esa
misma cantidad de pasos máximos, me parece que cambiar sería una mala idea.

------------------------------------------------------------------------------------------

06/05/2024

Ahí hice el cambio sobre el cálculo de los pesos. Veamos en comparación con el cálculo que se hizo
el otro día. La otra vez tardó 11813 segundos. Voy a usar la misma semilla y correr el mismo
programa, a ver cuánto menos tarda ahora. No voy a cambiar el tema las iteraciones extras o el
ancho de la ventana todavía, así la comparación es directamente con eso.

Ahí está corriendo eso. Mientras, voy a hacer las otras dos correcciones. Ya cambié el uso del
vector Exp por el vector Tanh. Es un cambio  de nombre para ser más claro.
 También modifiqué la cantidad de iteraciones extras y el ancho de ventanas para que esto corte
más rápido en los casos en que el sistema deja de variar rápido.

Mientras termina de correr la simulación que mandé, voy a preparar la presentación del miércoles.

Memes y cosas para introducir en la charla:
-------------------------------------------
1) Descripción distópica y útopica del tema con imágenes de Megaman battle network.

Después continuo esto.

El cambio que hice en los cálculos de las exponenciales no parece tener ningún efecto.
Es raro eso, no tiene mucho sentido. A menos que haya algo que está mal anotado en el
código, revisar eso. Porque tendría que reducirse mucho la cantidad de cuentas.

------------------------------------------------------------------------------------------

07/05/2024

Hoy quería ponerme a estudiar alemán, no creo que lo haga. Primero voy a mandar a correr de nuevo
los barridos en las pc's, pero modificando el instanciar para que no tenga el cero de cos(delta)
duplicado y modificando el ancho de ventana e iteraciones extras, eso debería modificar
algunos tiempos de simulación. Después voy a probar un poco más el tema de la modificación
en el código sobre el cálculo de las exponenciales, el cuál parece no tener efecto.

IMPORTANTE: EN ALGARVE ALGUNAS SIMULACIONES NO COMPLETARON PARA BETA=0 Y COS(DELTA)=1. REVISAR
DE MANDARLO DESPUÉS. AHORA MANDÉ PARA QUE ARRANQUE DE NUEVO A PARTIR DE BETA=0.2.

Ya mandé a correr todo de nuevo, haciendo las modificaciones que hice en la pc de la
facultad. Veamos ahora el tema de si puedo hacer correr esto más rápido. Necesito que
así sea, porque estas cosas están tardando tiempos imposibles.

No encontré la forma de hacer que esto vaya más rápido. Por ahora lo voy a dejar, voy
a mandar a correr simulaciones con redes de 5000 agentes a ver si puedo usar eso para
realizar las comparaciones. Con 5000 agentes el sistema me tarda 15 minutos. Ya fue,
trabajemos con 5000 agentes por ahora. Es mucho más razonable.

Cargué los archivos en las tres pc's, cuando terminen las corridas previas mando a correr
las nuevas simulaciones. No debería tardar mucho. A 15 minutos por simulación, me puedo
dar el lujo de hacer un barrido un poco más fino. Recorriendo 11 puntos en cada eje, son
121 puntos en el espacio de parámetros. Con 15~20 minutos por simulación, en el peor caso
eso es 40 horas por iteración. Así que en 2 o 3 días debería tener resuelto esto, considerando
que para los Betas cerca de 1 los tiempos de simulación se van a disparar. Espero que salga
bien la cosa, tendré 30 simulaciones para mirar.

Voy a ponerme a preparar la presentación para mañana.

------------------------------------------------------------------------------------------

08/05/2024

Revisé los programas que están en las pc's y están tardando aprox. 40 minutos cada simulación.
Recién resolvió dos betas de los 11. Así que eso va a estar un buen rato, con algo de suerte
va a estar terminado para el viernes. La pregunta importante es:
¿Me pongo hoy a estudiar Alemán o mañana? Yo diría que mejor mañana, así mañana cualquier
cosa tengo algo para mostrarle a Pablo. Hoy pongámonos a armar el Excel que decíamos con
Pablo de preguntas de las ANES.

------------------------------------------------------------------------------------------

09/05/2024

Por el paro, hoy estoy trabajando en casa. Estoy mirando la ANES y clasificando preguntas.
En la encuesta ANES 2020 hay preguntas de estereotipos sobre que tan trabajador o violentos
son según grupo étnico. Esas preguntas van desde V202515 hasta V202526. Todas estas preguntas
tienen 7 posibles respuestas. A partir de la pregunta V202580 hay muchas preguntas que parecen
tener 7 respuestas, varias que no son políticas. Pero son demasiadas y poco interesantes
realmente. Quizás si hace falta las podría revisar, pero en principio no es importante.

Ya revisé toda la ANES 2020. ¿Debería seguir con este trabajo?

------------------------------------------------------------------------------------------

10/05/2024

El 9 trabajé desde casa, pero por lo que veo no lo comitee, quizás genere problemas.
Tengo problemas más serios. Resulta que lo que estoy mandando a correr está tardando una eternidad.
Es una eternidad más corta que el caso de 10000 agentes, pero aún así el de 5000 está tardando
una eternidad siendo que las simulaciones que polarizan tardan 36 horas aprox. en resolverse.
Tengo que ver de buscarle una vuelta a eso. Simplemente es inviable trabajar así.
¿Debería resolver eso ahora?

Lo que habíamos charlado con la gente de GOTHAM era catalogar preguntas, armar a partir de eso
un conjunto de preguntas interesantes y quizás ver a lo largo de varias ANES cómo evoluciona
la polarización de esas preguntas. Creo que puedo conseguir más resultados si sigo catalogando
preguntas. Pero en ese caso, ¿Qué buscaría mostrarle a la gente de GOTHAM el miércoles que
viene? Con suerte, podría mostrarles el subset de preguntas que pensamos mirar y algunos 
gráficos donde veamos cómo fue evolucionando esa polarización. Porque mostrarles cuáles son
los tipos de gráficos que planeamos comparar no tiene sentido.

Sabiendo que los datos de simulaciones no van a estar como para hacer un estudio razonable
de acá al miércoles, yo propondría primero ir comparando lo que tengo con datos obtenidos
de 1000 agentes, como los que armé para el espacio reducido en Beta-Cosd, y de ahí armar algo
que funque y que en principio sea un puntapié al análisis, total una vez que tenga los datos
es una cuestión de cambiar el N del código de 1000 a 5000 o 10000. Entonces primero seguiré
catalogando preguntas, y ya a la tarde o después de hablar con Pablo definiremos los siguientes
pasos en estos días de acá al miércoles. Después habrá que volver a ver qué podemos hacer para 
que el código corra más rápido, porque simplemente no se puede vivir así. La primer idea que
surge es hacer una Tabla con datos para la función exponencial e interpolar. Tengo que pensarla
de alguna forma correcta, cosa de que el argumento sea la distancia al cuadrado del vector
y no la distancia, así aprovecho y me ahorro la raíz cuadrada.

Estoy mirando el guidebook de 2012 y estoy notando dos cosas importantes. La primera, es que el
formato es mucho más feo que las versiones anteriores, va a tomar mucho revisar las preguntas.
La segunda es que este guidebook no parece tener separados los datos en códigos como los otros
dos. Eso me preocupa.

De acá para el lunes es importante mandar a correr mi código para 10000 agentes en una dimensión
y el código de Hugo para 10000 agentes en una dimensión. Corrido eso, vamos a tener una buena
idea de la diferencia de tiempos y si los tiempos del código de Hugo es razonable o viable.

------------------------------------------------------------------------------------------

11/05/2024

Mandé a correr el código mío y tardó 7600 segundos. El código de Hugo en cambio tardó 47 segundos.
Hay una diferencia de dos órdenes de magnitud en el tiempo que tarda mi código y el de ellos.
No comprendo por qué. Eze me dice que quizás sea un tema de la cantidad de fors que estoy usando.
No creo que sea eso, pero se puede probar.

Mañana habrá que hacer gráficos con las preguntas que tengo de la ANES, armar una clasificación
clara y después preparar algo para presentar con eso.

------------------------------------------------------------------------------------------

13/05/2024

Soy un reverendo pelotudo, cinco veces pensé en commitear el trabajo de casa y no lo hice.
Ahora voy a tener un bardo entre los archivos y cosas. En la facultad hoy voy a
ponerme a trabajar en los archivos de Python para armar la clasificación de las preguntas
y los gráficos asociados.

El sueño que tengo me está complicando laburar fuerte. Ya no es joda hermano. No sé si
es la ropa que tengo puesta o el cansancio general, simplemente estoy deteriorándome. Y
el invierno no me gusta.

Anoté las preguntas que voy a mirar, armé los gráficos y los estuve repasando un poco,
pero no me parece muy interesante lo que estoy viendo. Pablo me propuso mirar directamente
las distribuciones 1D y con eso ir descartando cuáles son las preguntas que quiero mirar y
cuáles no.

¿Qué criterios usé para remover preguntas? Saqué las que tuvieran una gran cantidad de agentes
en una opinión neutra o que tuvieran distribuciones muy homogéneas.

Hice un primer filtro de cuáles voy a querer y cuáles no. En el drive voy a marcarlas como
descartadas, mientras que en Python las voy a borrar directamente.

Las preguntas que clasifiqué y separé me parece que son un buen filtro, me dejan los gráficos
que inicialmente quería mirar. Anotemos las preguntas descartadas en el drive. Después de eso,
empiezo a ver cómo medir la distancia de jensen-shannon.

Hice las anotaciones que quería en el drive, tengo clasificadas las preguntas que voy a querer
revisar. Mañana veré de armar el conjunto de preguntas y mostrárselo a Pablo, así como mostrarle
de estas preguntas cuáles podrían tener una cierta trazabilidad hacia atrás.

Lo que voy a hacer ahora es descargar los datos del barrido de Zoom Beta-Cosd y a partir de esos
ver cómo comparar esos datos con los datos de las distribuciones. Voy a elegir dos o tres
gráficos para comparar y a partir de esos voy a intentar armar algunas comparaciones.

Descargué los archivos a la carpeta de Comparacion_datos. Lo que necesito es un archivo de Python
que arme la Clasificación de las opiniones finales y compare eso con los datos de la encuesta.
Tengo algo que hace eso creo, que lo preparé para la semana pasada. Así que simplemente tengo
que lograr hacer un for. Y después voy a tener errores porque obviamente tengo huecos en mis
distribuciones T.T.

------------------------------------------------------------------------------------------

14/05/2024

Ayer llegué a casa y tampoco comitee mis datos. Soy un re boludo. Voy a copiar los datos de la
ANES en la carpeta de Comparación_datos y ahí voy a trabajar la parte de las comparaciones de
las distribuciones usando distancias Jensen-Shannon.

Ya tengo los datos del barrido reducido y tengo los datos de la ANES para comparar. Lo siguiente
sería empezar a comparar los datos. Voy a probar contra una distribución que tiene una buena
forma de polarización ideológica, el gráfico que sale de "Govt. Asssitance to Blacks" vs
"Guaranteed Job Income", que son los códigos "V201258" vs "V201255".

Por lo que leí en Wikipedia, debería revisar un poco más el tema, la idea es que al calcular
la distancia Jensen-Shannon, la distribución p, que es la primera que le paso a la función,
es la distribución medida. Es decir que primero le paso la distribución obtenida de la encuesta.
La segunda distribución, la distribución q, debería ser mi aproximación o mi resultado simulado.

Estoy armando el código para calcular la distancia entre dos distribuciones. Tengo una primera gran
duda: ¿Las distribuciones que estoy comparando, elemento a elemento, corresponden entre ellas?
La respuesta es que sí, se corresponden. Eso es genial, no puedo creer que haya funcionado.

Lo siguiente ahora es armar una función que calcule esta distancia y arme gráficos en el espacio
de parámetros. Ahí lo mandé a correr, funcionó. Y da razonable. Charlar eso con Pablo mañana.

------------------------------------------------------------------------------------------

15/05/2024

Pablo mandó un mensaje para posponer la reunión hasta la semana que viene. Así que para
la semana que viene tengo que tener algo más sólido armado. Para eso tengo que trabajar
en las siguientes cosas:

1) Acondicionar el código de Hugo para que trabaje con dos tópicos.
2) Continuar estudiando la distancia Jensen-Shannon en el espacio de parámetros para otras
configuraciones de preguntas. (Esto va a implicar adaptar la función de Clasificación para
los casos con tamaños que no sean 7x7). También debería estudiar un poco más la función
que calcula la distancia Jensen-Shannon.
3) Revisar los resultados analíticos y armar un plan de qué falta hacer. Quizás hacer
análisis de las ecuaciones en papel mezclado con simulaciones.
4) Revisar si quedaron ideas que valga la pena estudiar del tema de las simulaciones.
5) Probar cómo hacer que mi código funcione tan rápido como el de Hugo.

Vuelvo a mirar mi código, no veo nada raro. No comprendo. Pero bueno, empecemos a modificar
el código de Hugo para que funcione como yo quiero. Mientras, pongamos a prueba los tiempos
una vez más. Mandé a correr los dos códigos, sólo para comparar los tiempos.

Mandé mi presentación al curso de Verano ese en Uruguay que Pablo había compartido. Por otro
lado, no terminé de adaptar el código de Hugo. Mañana termino eso. Quedé a mitad de
adaptar la parte donde evoluciona y calcula la variación promedio. Lo que me queda revisar
también es agregar el cálculo de la norma no ortogonal. Creo que hechas esas dos cosas,
debería estar resuelto esto.

De paso, mandé a correr los códigos para comparar los tiempos, sigue ocurriendo que el
código de Hugo es 100 veces más rápido que el mío.

------------------------------------------------------------------------------------------

16/05/2024

Llevo toda la mañana y un poco de la tarde en terminar de adaptar el código de Hugo para que
corra como yo espero. Veamos si realmente funciona. Crucemos los dedos.

Corre y resuelve en poco tiempo. Queda hacer una comparación sobre si mi código genera el
mismo resultado. Suponiendo que el código funciona bien, tengo que reemplazar lo que ya 
está en funcionamiento y mandar a correr este nuevo código. Vayamos preparando eso mientras
se resuelve el código que mandé en la pc de la facultad que compara lo que hace mi código
con lo que hace el de Hugo.

Ya está corriendo el código de Hugo adaptado, el cuál corre mucho más rápido que el mío.
Lo que voy a hacer ahora es probar que el cálculo de la distancia de jensen-shannon sea
razonable, que esa cosa calcula correctamente.

Revisé la función de Jensen Shannon comparando dos distribuciones normales para ver cómo
varía esta distancia. Parece funcionar perfecto, incluso trabajando sin drama ante la idea
de tener 0 en partes de la distribución. Parece que no va a generar ningún problema
esto.

Mañana podría ponerme a modificar la función de Clasificación para poder agrupar las opiniones
en arrays de 6*7.

Ahora lo siguiente que necesito hacer para presentar es armar una función que primero
aisle la región de datos en la cuál quiero armar mi ajuste, y que luego haga ese ajuste.
Como sea que tenga que ser eso. Yo diría que por hoy estoy en horario, guardaría todo,
iría para casa y luego veré cómo construir eso el finde. O el lunes, creo que el lunes
tendría que salir eso.

------------------------------------------------------------------------------------------

20/05/2024

Estoy trabajando desde casa, hoy no me siento en condiciones de ir a la facultad.
Lo que quiero hacer es el ajuste de los parámetros. Para eso recorto una región en
la cuál observe un mínimo. A esa región, le hago un ajuste por cuadrados mínimos a la
Distancia de Jensen Shannon en función de los parámetros Beta y Cos(delta), ajustando
con la función de un paraboloide.

Armé la función que hace el ajuste de cuadrados mínimos. Después tengo que ver cómo obtener
el error del ajuste. Pero lo importante es que con esto podría calcular los coeficientes
de mi paraboloide con el que ajusto este espacio.

Digamos que Beta lo ajusto entre [0.5,0.72] y Cosd entre [0.04,0.15]

------------------------------------------------------------------------------------------

21/05/2024

Ya logré armar el cálculo del mínimo del valor 

Lista de tareas:
1) Chequear dónde se demoran mis simulaciones.
2) Resumen de la parte numérica. Qué está hecho y qué faltaría.
3) Resumen de la parte teórica. Qué está hecho y qué faltaría.
4) Resumen de la selección de datos y comparación del modelo.

Para la charla de mañana, quizás ver de hacer un ranking y también 
mostrar el espacio clasificado según las simulaciones.

Estoy teniendo un problema horrible con el cálculo de los gráficos
de distribución de opiniones de las encuestas. Es ese problema que me ocurre sólo en casa,
y que no logro comprender por qué. ¿Será mi versión de Win Py? Buscaré cómo actualizar eso.

Mandé a correr las simulaciones de la 30 a la 50 en Coimbra. En Algarve y Oporto no terminaron
todavía.

Las dos primeras preguntas que revisé son: 'V201258' vs 'V201255'. Son preguntas dudosas
Las variables óptimas obtenidas fueron: [Cosd = 0.104, Beta = 0.602].
Revisé 'V201420x' vs 'V201231x'. Son preguntas políticas
Revisé 'V202320x' vs 'V202320x'. Son preguntas No políticas

------------------------------------------------------------------------------------------

22/05/2024

Para bien o para mal, hoy es la reunión. Hay que hacer funcionar esto. Logré graficar 
las distribuciones de las encuestas usando matplotlib. Gracias por tanto Hugo.
Lo que tengo que hacer es elegir tres pares de preguntas. Uno ya lo tengo elegido,
es el que le mostré a Pablo, creo que Govt. Assistance to Blacks vs Guaranteed Job
Income.

De las preguntas políticas tengo dos opciones que me parece que podrían resultar
interesantes. La primera es "Birthright Citizenship vs Liberal-Conservative Self placement"
(V201200 vs V201420x). Se parece un poco a polarización descorrelacionada porque no va
tanto a extremos sino que llena un poco más las zonas intermedias. La segunda opción es 
la de "Less or more Government vs Birthright Citizenship" (V201420x vs V202255x).
Esta no me convence tanto porque tiene bastante vacío el medio, eso se parece más a una
polarización descorrelacionada sin anchura. Aunque debería igualmente dar mejor 
cerca de Beta =1.

En el caso de las no políticas, observo que son todas básicamente casos de consenso radicalizado.
Si ploteo lo que observo en la salida del plt.hist2d, lo que obtengo no es algo normalizado, es una
distribución con números más grandes que uno en muchos casos. Pero son todos floats, no es que
es la cantidad de agentes en cada región exactamente.
Me parece que razonablemente puedo proponer como ejemplo del de "Government action about opiod
drug addiction vs Economic Mobility compared to 20 years ago" (V202320x vs V202350x). Todos los
pares de preguntas parecen razonablemente observarse como consensos, ese par me parece preguntas
claramente apolíticas.

El par de preguntas apolíticas que estoy mirando está dando muy mal, por algún motivo me queda la
distribución al revés de lo que esperaría ver. No, ya lo pensé, ahí lo entiendo todo, la forma en
que calculo la distancia claramente está generando problemas. No estoy rotando las distribuciones.

Probemos cómo da el caso de Vaccines in Schools vs Best way to deal with Urban Unrest. 
(V201429 vs V202341x).

.) Considerar que la gente responde nulo cuando no se le da la opinión de no responder.
.) Usar agentes neutros a la fuerza. Es una forma de resolver el tema de la caja de agentes
 con opiniones. La otra es anular el elemento que corresponde a la caja central
.) Normalizar los gráficos de la distribución de la ANES.
.) Salvar los ceros en las regiones que faltan agentes.
.) Considerar que quizás tenemos dos Betas. Pensar en temas que tengan Betas distintos quizás,
 como el del Muro con México y el ..., para ver si tienen dos mínimos.
.) Arrancar con las preguntas que vieron ellos en el paper que sean bimodal o unimodal.
.) Comparar gráficos con igual resolución.

------------------------------------------------------------------------------------------

23/05/2024

Hoy lo primero que quiero hacer es organizar un poco mis archivos, y después resolver alguno
de los elementos que charlamos con la gente de España.

1) Normalizar los gráficos de distribuciones de ANES.
2) Armar reversiones de mis gráficos 
3) Rearmar la función de Clasificación para que tome preguntas de 6 respuestas en vez de 7.
4) Finalizar los ajustes, así como el graficado scatter de las distancias.

Al final solo logré hacer un poco de orden en las cosas que tenía, no avancé en nada del
trabajo por el tema de cómo me está resultando la operación. Roguemos que todo va a mejorar.

------------------------------------------------------------------------------------------

24/05/2024

Hoy estuve con el tema de la inflamación. Recién a la tarde arranqué a laburar. Pablo me va
a proponer usar zealots neutrales en las simulaciones. Mi proposición sería que no porque 
eso es algo a implementar en el código y más fácil sería hacer lo que dijo Hugo, simplemente
retirar el elemento del centro de la distribución.

Creo que normalizar los gráficos de la ANES es la primer prioridad. 
Segunda es modificar la función de Clasificación,
Tercero es graficar los histogramas 2D de mis simulaciones con la misma resolución que mis distribuciones.

Si eso está hecho, podría ver de pasar a ver cómo hacer lo de comparar distribuciones que tengan
betas diferentes para comparar. Para eso necesitaría la info que Hugo me dijo que me iba a compartir.
Si hoy no está, se la pido ya el finde. 

También voy a tener que repasar la parte teórica del modelo y charlar eso como para hacer una
presentación interesante al respecto. ES IMPORTANTE QUE PARA DENTRO DE DOS SEMANAS TENGAMOS
MEJOR PRESENTADO EL AJUSTE HECHO EN LOS DATOS, ASÍ COMO UN RESUMEN DE LA PARTE TEÓRICA Y
LA PARTE DE SIMULACIONES.

Empecemos por la parte de normalizar las distribuciones. Con ponerle un density = True parece
que alcanza. Aunque me genera un poco de duda eso, por cómo funcionan los pesos. La idea
es que el histograma cuenta cuántas son las personas que opinaron X o Y. Pero al pesarlo,
¿Afecta ese valor según un número? ¿No debería ser más bien como que la cantidad de gente
que cuenta se ve afectada? ¿Está el plt.hist2d haciendo el segundo trabajo o el primero?
Yo ya no estoy seguro de qué está haciendo.
 Si esto funciona bien, lo que debe estar haciendo es primero definir donde va cada "evento",
y luego no los cuenta como unidad, sino como su peso. Entonces si el peso es 0.97, no
cuenta como una persona, cuenta como 0.97 persona. Bien, es razonable. Normalizar eso
es una tontería después.
 En particular, al normalizar me queda algo tal que si sumo todos los valores me da 1. Eso
es porque cada cajita mide 1 de lado. 

------------------------------------------------------------------------------------------

26/05/2024

Ahí modifiqué el armado de la función de Clasificación, no lo probé, confío en que está bárbaro.
Acabo de ver que en la función que lee los datos de la ANES ya estaban los nombres de las
preguntas. Debería ver de extraer eso de ahí y listo.

Revisé la función que arma los histogramas 2D, para conseguir mis gráficos de 7x7 como quiere Pablo,
necesito simplemente cambiar el número de bins, ni hace falta que arme una función nueva.
Pero sí aproveché a modificar la función de Clasificación, todos los usos que encontré de eso, y 
por tanto los de Diccionario Metricas y de Calcular Entropia.

------------------------------------------------------------------------------------------

27/05/2024

Llegué no tan temprano, pero con motivos. Organicé cosas, revisé que el armado de gráficos con Seaborn
siga funcionando, aunque pasé a armar los gráficos con matplotlib. Ahora voy a ponerme a hacer
los gráficos de histogramas de opiniones 2D de 7x7.

Mientras está corriendo el armado de los gráficos de Zoom_Beta-Cosd voy a revisar que se estén armando los
gráficos correspondientes en las computadoras del cluster. Eso sigue corriendo todavía. En especial en
Algarve y Oporto creo que están todavía en la primera vuelta, falta la segunda. En cambio en Coimbra
ya casi está terminado. Mañana voy a ver si ya está terminado y mando a correr de nuevo.
Estos gráficos se podrían rearmar de forma de que los cuadrados en los que divido el espacio de opiniones
representen la proba de tener agentes en esa región. Actualmente representan otra cosa porque los cuadrados
miden 2.8...

Bien, ya resolví las cosas que me anoté el viernes. ¿Qué es lo próximo que tengo que hacer?
Hay dos cosas que se me ocurren hacer. Lo primero es revisar el tema del estudio analítico.
Completar el análisis de la polarización ideológica con el análisis de la polarización descorrelacionada.
La idea sería utilizar alguna simulación para ver la estabilidad del modelo en función de Beta
para ver si el estado de polarización descorrelacionada se rompe a medida que Beta crece.

La segunda opción es ver cómo puedo rotar las distribuciones de opiniones para poder comparar eso con las
distribuciones de ANES. Una vez hecho eso, puedo volver a realizar los ajustes que dejé truncados en
la última reunión.

------------------------------------------------------------------------------------------

28/05/2024

En la mañana estuve trabajando un rato en mi cuaderno en armar un código que rote la matriz.
Después me puse a estudiar alemán, fui a cursar y a la vuelta trabajé un poco más antes de
irme a casa.

------------------------------------------------------------------------------------------

29/05/2024

En la mañana me escribí el código para rotar matrices que necesitaba. Ahora que tengo eso,
puedo ponerme a hacer lo segundo que es lo que me dijo Pablo, ver de remover elementos de
las distribuciones. Podríamos removerlos de dos formas. La primera, es remover sólo el elemento
central. La segunda es remover TODO agente que haya respondido con las preguntas centrales
an alguna de las preguntas. Vamos a probar hacer las dos cosas y de ahí vamos a ver qué resulta
mejor.

Pero antes de eso, ¿Tengo resuelto la rotación de mis matrices? Lo que hice funciona bien si mi
matriz es cuadrada. Pero en caso de no serlo, ¿Cómo puedo rotar mi matriz? ¿Tiene sentido rotar la matriz?
Creo que por ahora no me voy a preocupar demasiado por esto. Avancemos con lo otro, y cuando surja
ese problema, lo enfrentaré.

Probaré primero sacando un elemento en el centro. Me parece que va a ser más fácil de implementar.
Al mismo tiempo implementaré una corrección para el hecho de que las distribuciones no tengan ningún
punto nulo.

Para remover el punto central, eso es bastante directo. Si mis preguntas son de 7x7, significa que
tengo que eliminar el punto en la posición [3,3]. O lo que sería lo mismo, de mis 49 elementos de
mi array con la distribución de la encuesta, tengo que eliminar el elemento 24.

Admito que me gustaría además que el gráfico que hago de la encuesta tenga ese elemento bloqueado.
Debería ver de pedirle al pandas que al graficar ese punto esté tapado.

Bien, para remover los agentes del centro o para remover la cruz ya Chat GPT me dió una linea fácil de
cómo hacer eso con Pandas, probé graficarlo y efectivamente lo que se grafica es lo que estoy buscando.
También miré las distribuciones generadas. Tienen la forma correcta. Lo siguiente es entonces
Ya vi que eso funca, lo que me queda es hacer lo de que si la distribución de la simulación tiene ceros,
entonces tengo que agregar agentes en esa distribución. Lo que puedo hacer en ese caso es sumar agentes
de a 1. Luego, según la cantidad que sumé, restar esos agentes del lugar donde haya más agentes.

Si pongo 1 agente en cada lugar vacío, la distancia Jensen Shannon da distinto que si no tengo agentes
ahí. En particular, tomé el ejemplo del par de preguntas políticas y lo comparé con una distribución de
Consenso Radicalizado. Para esta distribución con ceros, la distancia JS da 0.824, en cambio cuando 
relleno los lugares con cero obtengo una distancia de 0.774. Habrá que hacer esto de rellenar los lugares.

Me queda hoy probar lo de remover el punto central. Al remover el punto central, la distancia da
distinto a si dejo un cero en ese punto. Ok, definitivamente removeré ese punto cuando haga las cuentas.
Ya tengo armado el esqueleto para construir el código que quiero hacer, ahora queda nomás pasarlo
al código de funciones que se encarga de armar el mapa de colores de Distancia JS.

------------------------------------------------------------------------------------------

30/05/2024

Hoy el plan es hacer dos cosas importantes. La primera es lograr ver la distancia de JS de pares de
preguntas removiendo el centro y removiendo la cruz central. Tengo más o menos armado el código para
hacer eso, ahora tengo que organizar todo en carpetas razonables. Creo que lo que voy a hacer es
preparar tres carpetas. Una para el caso normal, una para el caso sin el centro y otra para el caso
sin la cruz. El caso normal lo voy a llamar "Base". El caso sin el centro lo voy a llamar "Sin Centro"
y razonablemente el último caso va a ser "Sin Cruz".

Hecho eso, puedo empezar a revisar pares de preguntas, medir las distancias JS y hacer los gráficos
correspondientes.

Lo segundo que voy a querer hacer hoy es mandar las simulaciones con los Zealots. Eso lo tengo
que mandar a correr en las pc's de la facultad. Igual eso lo voy a mandar a correr recién mañana,
hoy no voy a poder porque la pc de la facultad todavía está corriendo el barrido en Beta-Cos(delta).

Probé varias cosas, pero ninguna parece resultar para cerrar esa región de la cruz. Así que por ahora
dejemos eso y sigamos con el resto del laburo. Para lograr esto creo que la idea va a ser en la misma
función de cálculo de la Distancia de JS hacer las modificaciones para que se calcule correctamente la
distancia y desde ahí armar los dos gráficos de una sola vez. Eso va a ser lo mejor.

Hice todas las modificaciones como para poder correctamente armar los gráficos. Fue un bardo, va a
tirar 15 errores, pero bueno, ahora estoy en condiciones de probar a ver qué da. Va a tardar una eternidad
más, porque ahora hace muchas más operaciones. Además está todo mezclado en un sólo paquete para trabajar
sólo con preguntas de 7x7. Va a ser un bardo desarmar eso para que trabaje con preguntas de 6x6 o 6x7.
Voy a tener que ver cómo se automatiza eso para trabajar en esos casos. O, quizás, sólo quizás, cuando
trabaje con esas preguntas mejor simplemente me pongo a armar una función distinta que ya sepa de antemano
la forma de la función que le voy a mandar. Veré, no sé honestamente qué es mejor.

Ahora voy a trabajar con tres pares de preguntas que me resultan las más simples de utilizar:
1) V201255 vs V201258. (Govt. Assistance to Blacks vs Guaranteed Job Income.)
2) V201200 vs V201420x (Birthright Citizenship vs Liberal-Conservative Self placement)
3) V202331x vs V202341x (Background checks for gun purchases vs Vaccines in Schools)

Logré que haga los cálculos, pero no da muy lindo. Mañana armaré algunas preguntas más en la facultad
como para ver qué es lo que da y si ahora el caso de las preguntas no políticas que parecen un consenso
radicalizado dan mejor.

Lo siguiente es ponerme a trabajar en el código actual para introducir el uso de Zealots cuyas
opiniones se mantienen fijas en (0,0). Entiendo que la idea es que una fracción de esos
agentes se mantengan en esa opinión. Supongamos que el plan es que un 10% se mantenga en ese
número.

Ahí hice lo de los Zealots, la verdad fue bastante rápido, buenísimo. Bueno, ya son las 18:30,
creo que puedo dejarlo acá por ahora. Mañana seguiré sacando gráficos de distancia JS
y veré qué tal quedan.

------------------------------------------------------------------------------------------

31/05/2024

Ahora estoy en la facultad. Lo primero que voy a hacer ahora es mandar a armar los gráficos
para los pares de preguntas que tengo ahí considerado, así se ve mejor si esto funca bien
o no.

Armé gráficos de distancia JS en el espacio de parámetros. Dan un poco mejor que antes, pero
tampoco la gran cosa. Habrá que ir viendo qué tal. Se me ocurre que puedo agarrar algunos
pares de preguntas más, revisarlos y después de ahí sacar conclusiones.

Lo que voy a hacer ahora es armar un poco una charla, unas pocas diapositivas para armar
la idea de lo que vamos a charlar para el miércoles que viene. Había malentendido yo, 
esto es para tener un esquema de trabajo nuestro en el cuál tengamos bien claro lo que estamos
queriendo hacer y lo que falta del trabajo. Tengo anotado el armar simulaciones extendiendo la
región de simulación del espacio Beta-Cos(delta). La idea está bien, vamos a tener que considerar
seriamente cuál es el nivel de granularidad de ese barrido cosa de que sea consistente en toda la
región.

Para el miércoles lo ideal sería llegar con más laburo hecho del lado de los ajustes y las
distancias calculadas de JS. Para eso necesito entonces armar un conjunto de seis pares
de preguntas que me interese revisar. Fijemos algunas preguntas como me dijo Pablo y de
ahí vamos viendo cuáles combino y como.

Algo para aclarar de paso, noté hace un rato que el cálculo de la distancia JS con las simulaciones
más similares está mal hecho porque no estoy haciendo un sort según distancia. Así que eso lo tengo
que corregir. Otra cosa que voy a tener que hacer es corregir el cómo se hace el ajuste, porque eso
no tiene la parte de rotar los gráficos. También estaría bueno agregar al mapa de colores de 
distancia JS algo que saque el gráfico que más se parece a la distribución de la encuesta considerada.

Una cosa más a revisar es el tema de cómo está dando la distancia JS. Parece que nos está dando
muy alto. Pero justamente la palabra clave es parece. No tenemos claro si es un número alto o
no, necesitamos más claridad respecto a qué es un gráfico similar o no a lo que estamos viendo.
Así que voy a tener que experimentar un poco con eso para ver cómo sale. Por último, voy a tener
que ver de normalizar los gráficos de histogramas 2D de forma tal que la suma de las fracciones
graficadas de 1.

Bien, tengo bastante claro el laburo a hacer. Y tengo bastante laburo. Arranquemos. Primero
las preguntas. Me armé un conjunto de preguntas. Suficientemente chico como para no matarme
revisando 30 gráficos. La idea es armar seis, siete gráficos de pares de preguntas y con eso
empezar a revisar cosas.

------------------------------------------------------------------------------------------

01/06/2024

Obviamente me olvidé de subir al drive los gráficos de histogramas que había elegido ayer.
Porque obviamente me iba a olvidar de eso. Ahí armé los gráficos, los hice con matplotlib.
Por ahora voy a trabajar sólo con preguntas que tengan seis respuestas.

Bien, ya tengo seleccionadas las preguntas que creo van a resultar útiles. Ahora armo las
distribuciones 2D de esas preguntas para decidir cuáles 6 preguntas quiero mirar.
Los gráficos que esoty viendo no me gustan, no hay nada que se parezca a lo que queremos
ver. Sí, ya sé que tampoco lo que veíamos se parecía tanto, pero igual no me gusta. Por
ahora dejemos eso así, avancemos con las otras cosas, total si lo otro está armado, simplemente tengo
que elegir nuevos pares de preguntas y volver a intentar.

Ya corregí lo de la similaridad. Era tan simple como poner un np.sort. Lo siguiente que se me
ocurre es armar una función que me muestre el gráfico más y menos similar. El tema de
armar una función aparte es que va a tener que volver a calcular todas las distancias JS
y eso tardaría mucho para mostrar un simple gráfico. Creo que lo mejor sería intentar aprovechar
la función del Mapa de colores DJS. Hagamos eso.

Suponiendo que está todo bien, se arman los histogramas 2D de mínima y máxima similaridad
para cada encuesta sin centro y sin cruz. Aunque no estoy haciendo el histograma 2D de la
simulación sin la cruz o sin el centro. Tengo que ver cómo hacer que esos gráficos respeten
eso. Lo cuál no es obvio porque en las simulaciones las opiniones no son valores enteros.

------------------------------------------------------------------------------------------

02/06/2024

Revisé los gráficos de distribución de la ANES, en el centro de opiniones existen como mucho
un 12% de agentes, siendo más bien en general entre un 6% y un 8%. Así que mandar un 10% de agentes
como Zealots parece una buena idea. Lo que tengo que hacer ahora entonces es cargar el archivo
de opinion a todas las pc's, armar la nueva carpeta de los Zealots y ya mandarlo a correr.

Mandé a correr 10 hilos en Coimbra y 10 en Oporto. Iba a mandar en Algarve, pero todavía le
queda un hilo a Algarve, entonces para no hacer macanas corté lo que estaba mandando ahí y volví
a cargar el archivo de opinion que tenía previamente y lo compilé para que ese ejecutable sea el que
esté armado. Con algo de suerte, no arruiné nada.

Bueno, si corrijo el cómo hace el cálculo de JS la función de ajuste, entonces habré hecho todo lo
que me anoté el viernes para hacer. Que era un montonazo. Me parece un gran plan.

------------------------------------------------------------------------------------------

03/06/2024

En la facultad acabo de rehacer los gráficos de distribuciones de ANES. Sostengo que los gráficos
hechos con las preguntas elegidas no me gustan. Voy a tener que elegir algunas preguntas nuevas.

Ahora voy a mandar en Algarve a correr el armado de las simulaciones con Zealots. Ya mandé eso a
correr. Dentro de todo parece correr bien, los primeros agentes tienen opinión nula mientras que el
resto de los agentes está convergiendo a algún lugar.

Lo siguiente es mandar a hacer los gráficos de Distancia JS. Los gráficos se hicieron, parece funcar
bárbaro. Las distancias dan bastante menor, cercano a 0.35 en promedio. Tengo que corregir una cosa
de esto, y eso es cómo se arma el histograma de máxima y mínima similaridad. También tengo que 
cambiar esos títulos, son confusos. Pero cuestión que tengo que cambiarlo para que esos gráficos
tengan efectivamente 0 en los lugares correspondientes, ya sea en el caso en que no tiene el
centro o el caso en que no tiene la cruz.

Creo que en vez de hacer el histograma, es mejor si simplemente hago el gráfico usando la función de
clasificación y un pcolormesh. Bien, ahí hice algo, espero que funcione. No me gusta mucho cómo están
armadas las funciones, después en algún momento tendré que encontrar la oportunidad para rearmarlas y
escribirlas de forma más prolija. Pero mientras funcionen por ahora, estoy hecho.

Lo siguiente es lograr que la función de ajuste funcione claramente. Que creo que lo está haciendo.
Así que si eso funca, tengo que seguir con la función de Ajuste. Aunque ahí trabajé la función de Ajuste,
si todo está bien ya hace lo que debe hacer. Entonces lo que necesito es tomar los gráficos de 
Distancia en el espacio de parámetro que calculé y calcular los rangos en los que voy a hacer los ajustes.
Otra cosa interesante para hacer sería juntar todos los datos de 10000 agentes y empezar a laburar con
eso, mandar a correr este programa en la máquina de Coimbra. O quizás Algarve. Hoy pareciera que Algarve
es una mejor opción, tiene más hilos libres, como para mandar a correr esto ahí. Empecemos a juntar los
archivos de Comparacion_datos ahí.

El armado del histograma de forma tal que se vea bien normalizado me está costando horrores. No puedo creer
que esté perdiendo tanto tiempo en esto. Ahora creo que lo armé de una manera más razonable, Dios quiera
que esto funque mejor así.

Con esto ya tengo armado todo lo que me anoté el viernes. Debería ahora ir preparando la charla. Una vez que el
código corra bien en la pc de la facultad, voy a ver de pasarlo a Algarve así mando a armar los gráficos ahí.
Aparte de eso, debería ver de implementar correctamente el ajuste. Para eso necesito tener más o menos armados
los rangos de Beta y Cdelta para cada par de preguntas. Si estoy con tiempo, hoy reviso algún par de preguntas
más y veo de armar gráficos con eso.

El código funciona hasta el final, arma el gráfico del paraboloide, hace el mapa de colores de Distancia JS y
hace el ajuste para el caso de las distribuciones sin centro y sin cruz. Ya puedo mandarlo a correr en la pc
de Algarve. Voy a tener que hacer algunos ajustes para eso. En estos últimos 20 minutos, armemos el esqueleto
de la idea de lo que quiero mostrar, mañana lo mando a correr esto mientras voy mirando alguna que otra pregunta
que me parezca más valiosa.

------------------------------------------------------------------------------------------

04/06/2024

Estoy armando la presentación de mañana. Estoy viendo que tengo bastante para mostrar como trabajo,
no tanto como resultados positivos. Siento que buena parte del problema es que estamos mirando
combinaciones de preguntas que dan terrible. Igual vamos a charlarlo con Pablo y ver qué opina al respecto.

No lo encontré a Pablo. Intentemos mejorar los resultados. Para eso hagamos lo siguiente:
1) Corregir el tema de los gráficos de histogramas, que la distancia anotada sea un número con
dos cifras significativas.
2) Aumentar un poco más la distancia de los labels en el gráfico de la superficie 3d.
3) Asegurarme que la distancia de JS graficada se grafique con hasta dos cifras significativas, sino se chocan
los números con las palabras.

Esas últimas dos cosas las puedo dejar para después y ahora ponerme con la parte de buscar pares de preguntas
que me resulten más interesantes.

Ok, estoy sinceramente estancado, tengo que hablar con Pablo para ver qué opina. No sé exactamente cómo encarar
esto.

Necesito una discusión conmigo mismo para organizar mis ideas. El plan es contar a la gente de GOTHAM que hicimos
TODO lo que charlamos la última vez. Normalicé los gráficos, armé histogramas 2D, removí el elemento central de las
distribuciones de las encuestas, hice cálculos de las distancias tanto para casos sin el elemento central como sin
la cruz central. De esto puedo concluir que se puede trabajar ambos casos casi indistintamente, no dan muy distinto.

También considero que no es necesario mostrar seis preguntas, es un montón de bardo y gráficos, con tres estamos más
que hechos. Realicé algunos ajustes, y la verdad los resultados para mostrar son un poco feos.
Estoy teniendo un problema por un lado de que me está quedando los mínimos muy cerca del borde de la
región de ajuste, entonces el valor de Cos(delta) que ajusta está dando mal. No sé si convendría simular
un poco para ese lado cosa de que esos datos ubiquen correctamente el mínimo en 0 o si debería más
bien imponer que el mínimo valor de Cos(delta) sea cero.

Estoy pensando, ¿Tengo una buena respuesta sobre cuál es una distancia chica respecto de dos gráficos?
¿Cómo mido eso rápido? Podría tomar una distribución en dos ejes que arranque igual e ir aumentando
su diferencia migrando todos los agentes a un sólo lugar y ver cómo me da eso. Eso lo puedo probar de
hacer ahora y ver de graficarlo como para tener una idea qué tal da la distancia entre gráficos.

Los ajustes dan un poco más lindo si no encierro tanto el ajuste. Démosle un poco de espacio, quizás
esta ajustando mucho sobre una zona plana.

Hablé con Pablo, organizamos bastante la charla. Me dijo que en vez de mostrar los que más se parecen
y los que menos, muestre el que más se parece y el décimo que más se parece.

------------------------------------------------------------------------------------------

07/06/2024

El 05 estuve preparando la charla con la gente de España. A la mañana tuvimos la reunión de grupo.
No estuve en la pc para anotar lo que charlamos en la presentación. Problemas de internet.
Después de la charla me reuní con Pablo y empecé a armar un cálculo de tiempo de simulación que iba
a tomar el armar el barrido en los espacios de parámetros.

El 06 llegué tarde porque tuve problemas para arrancar el auto. Después también tuvimos la charla
de Diego. No llegué a terminar el cálculo del tiempo de simulación, pero casi.

Hoy a la mañana terminé el cálculo del tiempo de simulación de ambos espacios de parámetros. El
barrido no resulta fino, es algo que tendremos que discutir.

Después me puse a estudiar un poco de alemán.
Lo siguiente que voy a hacer es enviarle a Hugo un mail sobre cómo es el cluster que tienen, cuántos
hilos tienen y cuántas cosas podríamos mandar a correr.

------------------------------------------------------------------------------------------

09/06/2024

Hoy lo que quiero hacer es mandar a correr en las pc's de la facultad el nuevo barrido que hablamos con Pablo.
Para eso, ya que también le voy a pedir a la gente de GOTHAM que mande a correr esto, creo que es importante
modificar el formato de los archivos de salida, cosa de que pesen lo menos posible. Para eso, en vez
de devolver el estado final del sistema, voy a hacer que devuelvan la clasificación de opiniones. Voy
a hacer que además no escriban ni las opiniones iniciales ni la variación promedio. Voy a dejar el dato
de la semilla y la matriz de adyacencia, por si acaso.

Estoy mirando la forma en que se construye la distribución de mis distribuciones de opiniones finales, y me
parece que la forma en que se construye con la función de Clasificación NO es igual a cómo se construye
la distribución de la encuesta. Me parece raro, porque los había comparado y había visto que eran iguales.
Bueno, había entendido todo mal, soy un gil. No puedo ser tan pelotudo. Efectivamente las distribuciones
se arman distinto, la que tengo hecha de las simulaciones está traspuesta respecto a la de las encuestas.
Corrijamos eso ahora. Y estemos atentos a cuál es la forma correcta de hacer esto.
Lo corregí en Python, ahí lo corrijo en el clasificador de C también.

Bien, ya lo armé y funca bien por lo visto. Ahora lo voy a poner a correr en las 3 pc's. Voy a asegurarme
de mandar a correr el espacio que charlamos con Pablo.

Estoy mandando a correr en cada pc 20 simulaciones, por lo que tendré en total 60 simulaciones. Lo que estoy
barriendo son las regiones que etiqueté como B+C+D+F+G+H. La región E la dejo para barrerla al final.

Lo mandé a correr en Algarve y Coimbra, en Oporto no porque faltan 3 simulaciones de lo de los Zealots para
terminar. Faltan dos para el peso siempre boludo. Bueno, si tengo suerte, antes de irme a dormir puedo mandar
a correr en Oporto eso que falta.

------------------------------------------------------------------------------------------

10/06/2024

Lo primero que hice en la mañana es mandar a correr desde Oporto las 20 simulaciones que
faltaban para completar 60. Las últimas 40 voy a ver si se las puedo pedir a Hugo.

¿Qué debería hacer hoy? De lo que tengo anotado como primordial, ya mandé a correr simulaciones
en la pc de la facultad y modifiqué la salida de los datos para que los archivos sean lo más
livianos posibles.

Como prioritario me queda hacer:
1) Realizar ajustes con los conjuntos de simulaciones más similares, armando un ranking agrandando
el conjunto de a poco.
2) Armar un archivo con el análisis teórico hecho para pasárselo a Hugo.
3) Charlar con Capuzzi sobre el cluster de Dirac.

El trabajo interno quizás lo iré revisando ya el miércoles o jueves. El martes podría hacer
lo del análisis teórico. Hoy me pongo con el punto 1 totalmente. Antes que exactamente eso,
lo primero que voy a hacer es organizar el código, hacer que se vea más prolijo, agregar las
funciones al archivo de funciones generales y si todo queda más lindo, ahí hago lo que dijo
David que se arma en dos o tres líneas.

Lo que tengo que hacer es borrar la parte de laburar borrando el centro, sino que tengo que
acomodar para que la función trabaje con preguntas de seis respuestas.
 En la función hice que la distribución de la encuesta siempre salga como una matriz de 6x6.
Independientemente de si lo que recibe son preguntas de 7 respuestas o preguntas de 6 respuestas
o mezclado.

No terminé esto, pero vamos bastante bien. Mañana veré de terminar esto.

------------------------------------------------------------------------------------------

11/06/2024

Estuve trabajando sobre la función que realiza los mapas de colores de forma tal que trabaje
sobre preguntas que tengan seis o siete respuestas y para que además arme los gráficos que hablamos
ayer con Pablo.

Voy a probar que funque bien, que pueda trabajar con un par de preguntas de 7x7, 6x7 y 6x6.
Por lo pronto está corriendo, así que eso es bueno. Ahora me voy a poner a hacer lo que sigue,
que es mandarle un mail a Hugo con los archivos para correr las simulaciones.
Estoy corrigiendo muchos pequeños errores con esto, y eso me distrae del laburo. Es sólo eso,
nada más lo que me distrae.

Armé un mail lo más prolijo que pude y le envié a Hugo con los archivos para simular, así
como una explicación de qué hacen y lo que espero que haga. Veremos lo que me contesta mañana
y eso.

------------------------------------------------------------------------------------------

13/06/2024

El 12 no anoté nada porque estuve trabajando en el google drive para armar la presentación
de el análisis teórico realizado. La idea era terminar eso el 12 para mandárselo a Hugo.
Logré terminarlo y programé el mail para enviárselo a Hugo temprano.

Hoy en la mañana me puse a estudiar un poco de Alemán. Ale nos contó que nació su beba.
Eso significa que el Lunes no vamos a jugar la partida.

¿Qué voy a hacer hoy? Primero, debería mandar a correr lo que calcula la Distancia Jensen-Shannon
y arma gráficos con promedios de conjuntos cada vez más grande. Pongámosle un nombre. Ranking
de promedios de distancias de Jensen-Shannon.

Hasta ahora no hablé con Capuzzi por el tema de los clusters de Dirac. Tengo que hacer eso hoy si
me lo cruzo en el aula Federman.

¿Qué resultados tengo para mostrar? Hice los gráficos de ranking de promedios de distancias
Jensen-Shannon. Lo que tendría que hacer ahora es lo que me decía Pablo, de intentar ver
cómo se componen los estados del ranking. La pregunta es, ¿cómo lo hago?

La idea es que yo tengo mi matriz de Distancias JS, que su número de filas es la cantidad de Cos(delta),
su número de columnas es la cantidad de Betas, y su tercer coordenada es la cantidad de iteraciones.
Para cada simulación, que se identifica con una combinación de estas tres variables, ubico su
distancia JS en un lugar de esta matriz. Yo quiero agarrar un conjunto de estas simulaciones, ordenados
en distancias de menor a mayor, a ese conjunto quiero identificar qué estados son y obtener algún gráfico
que visualmente me indique qué estoy viendo.
 Ponele que estoy mirando las primeras 10 simulaciones, y quiero que arme dos gráficos de frecuencias de
estados. Uno con lo que es el estado más probable, y otro con el segundo más probable. Se entiende por
más probable el que aparece más veces en TODO el espacio.
 Tengo una idea de cómo hacerlo, vuelvo a recorrer todo el espacio de parámetros, uso la matriz que tiene
las distancias JS y en cada vector asignado a una combinación de parámetros Beta, Cos(delta), busco el
décimo elemento ordenado de menor a mayor y me quedo con las iteraciones ubicadas en las posiciones
de los elementos cuya distancia sea menor o igual a la del décimo elemento. Luego, construyo mi matriz
con las frecuencias de esos estados. Una vez hecho eso, voy contando cuántos estados tengo y listo.
También veo de armar un gráfico de frecuencias de estados y palo y a la bolsa. Planazo.

La siguiente pregunta es: ¿Meto esto también en la función de cálculo de distancias JS? ¿Debería separar
esa función en nuevas funciones? Lo meto en la función, siento que separarlo sería un problema en
sí mismo porque cada una de esas funciones nuevas necesitaría que les pase un montón de cosas, sería
un bardo en sí mismo.

#################################################################################################
#################################################################################################

Lo pensé de nuevo, puedo hacerlo en partes separadas. Pero creo que mejor lo dejo para la próxima eso.
Lo voy a hacer después de la próxima reunión. O en el finde quizás.
.) La idea es que la primer función returnee la matriz ZZ de distancias Jesnsen-Shannon.
.) Armo una segunda función que arme los gráficos de ranking de promedios de distancia JS.
.) Armo una tercera que grafique la simulación más similar y la menos similar. Para eso voy
a tener que agregar de forma externa el cálculo del Dic_total que surge de la función de 
Diccionario_metricas. La idea es que eso lo hago una sóla vez, por fuera del for de cada par
de preguntas.

TODO esto, después de la próxima charla.

#################################################################################################
#################################################################################################

Tengo que guardarme la matriz ZZ así como viene originalmente, así que voy a tener que agregar
una nueva matriz que sea la ZZ_sorted.

Arranqué con esto, mañana lo resuelvo y empiezo a armar la presentación.

------------------------------------------------------------------------------------------

14/06/2024

Primero hice lo de armar los gráficos de Frecuencias de estados para los dos estados más dominantes
en el espacio de parámetros. Ahora estoy intentando lograr que funcione, porque estoy teniendo unos
problemas de tamaños en el archivo, no entiendo bien por qué.

Hecho eso, ya me puedo poner a armar la presentación. ¿Qué voy a mostrar en la presentación?

.) Se me ocurre que puedo arrancar mostrando las preguntas a considerar. Ya lo vimos antes, 
pero para recordar, en especial ahora que estamos fijándonos en las preguntas sin la cruz
del centro.

Termino esto mañana.
##############################################################################################

Por algún motivo raro, el código que hace el mapa de colores de FEF para los dos estados predominantes
está teniendo un problema en un caso particular. Por alguna razón para los valores de Beta=0.4 y
Cos(delta) = 0.1 pareciera que al calcular la Distancia Jensen-Shannon, todas las distancias dan lo
mismo. RARO. Voy a intentar printear esa "fila" del vector ZZ y ver qué pasa ahí.

------------------------------------------------------------------------------------------

15/06/2024

Estoy en casa intentando hacer funcionar el código que arma los gráficos de Frecuencia de Estados
Finales rankeados de las dos distribuciones más dominantes. Estoy teniendo problemas con las matrices
construidas, pero no sé por qué y tarda mucho el código para poder mostrarme cuál es el problema.

Puedo seguir hardcodeando mis problemas, pero hay muchas chances de mandarme cagadas. Mejor me pongo
a revisar las cosas de a poco. Voy a desarmar el código de mapa de colores de Distancia Jensen-Shannon
de forma de correrlo una vez y empezar a trabajar con la matriz ya construida de forma más fácil.

La idea es que la función devuelva la matriz de Jensen-Shannon, después otra función con eso grafica
el mapa de colores, otra arma los ranking y una tercera hace la parte de las simulaciones predominantes.
Haré eso entre mañana y el lunes.

------------------------------------------------------------------------------------------

16/06/2024

Armé la función que construye la matriz de Distancia Jensen-Shannon y la returnea.
Algo que estoy notando es que quizás convenga definir cuál es el código x y el código
y por fuera de estas funciones. Mejor hacerlo en el código de Graficar.

------------------------------------------------------------------------------------------

17/06/2024

Logré separar el código en tres partes. Lo cuál es un golazo. Lo siguiente es ver si puedo
descubrir el error que tiene para abrir la matriz. Si puedo hacer eso, puedo revisar entonces
qué es lo que está pasando que falla en el armado de los gráficos de FEF.

Luego de bastante revisar, al final el error que tenía era una boludez, simplemente pasa que
estaba pasando un float para ubicar filas de un array. La cosa está funcionando ahora. Lo que voy
a hacer ahora es volver a mandar a correr las cosas las pc's de la facultad. Y también voy a mandar
a correr las funciones de Graficación en Algarve, para tener los gráficos hechos a partir de las
simulaciones de 10000 agentes.

.) En Algarve voy a mandar a correr todo a partir de Beta=0.9. Así que después tengo que completar
la segunda simulación de Beta=0 a 0.8.
.) En Coimbra, la primer simulación se terminó y estaban en la segunda. Así que ahora mando todo
a partir de Beta=0.3.
.) En Oporto voy a mandar a correr todo a partir de Beta=1.1. Así que después tengo que completar
la segunda simulación de Beta=0 a 1.

------------------------------------------------------------------------------------------

18/06/2024

Estoy armando la presentación para mañana, ya tengo varios de los gráficos. Tengo que ver
de mandar a hacer gráficos de histogramas con los 10000 agentes. En especial porque necesito
un gráfico de un estado de transición para mostrar.

Como de costumbre, Pablo me tiró una idea de qué hacer ahora, que es un bardo de rearmar. Veamos
qué podemos hacer de acá para mañana. Si tengo esto resuelto para una o dos preguntas, estoy hecho.
La idea es mirar el estado promedio. Juraría que cuando hicimos esto, lo que se veía era una cagada.
Debí haber recordado eso cuando charlaba con Pablo.

Tengo que considerar adaptar el armado de los histogramas 2D de opiniones para que acepte el caso de
que las preguntas tengan 6 respuestas en vez de 7.

------------------------------------------------------------------------------------------

19/06/2024

Notas de la reunión:
-------------------

.) El gran dilema es si deberíamos tomar pocas cantidad de simulaciones o no al hacer
los análisis. David propone que deberíamos complementar el análisis de pocas simulaciones
con un segundo análisis indicando la composición de estados en el espacio de parámetros.
.) Método cuantitativo, tomar las distancias, ver la dispersión de distancias. Podría dar una
idea de la comunidad de distancias.
.) Armar un histograma de distancias de Jensen-Shannon. La idea es ver si se pueden conseguir
histogramas que indiquen comunidades.
.) Gráfico de probabilidad de encontrar una configuración en función de su distancia. Esto sería
el primer paso para algo mejor, que es un segundo gráfico que tenga para cada combinación de
parámetros, la probabilidad de encontrar comunidades de distancias similares.
.) Nos están comentando sobre el trabajo con la persona esta, Pablo Etchenique. Es un trabajo
en que analizan las ideologías 

Luego de la charla me puse a cocinar y mi intención era estudiar Alemán. No estudié un carajo.
Cuatro horas se me fueron entre cocinar, limpiar la cocina, comer y cosas. Definitivamente fue
mucho tiempo. No sé qué pasó.

------------------------------------------------------------------------------------------

22/06/2024

Revisé las pc's, las simulaciones casi terminaron hoy, mañana podría mandarlas a las regiones que
faltan. Oporto podría mandarla hoy. Mañana lo que puedo hacer es revisar un poco
el código y ver de armar algo que construya los histogramas de distancias de Jensen-Shannon.

Tener algún argumento para charlar con Pablo sobre si tomar más o menos simulaciones. Revisar
las otras preguntas para tener más info qué conversar. Podría también considerar actualizar
las documentaciones.

------------------------------------------------------------------------------------------

23/06/2024

Algarve todavía no terminó, mañana mando a correr cosas ahí. Esto es lo que tengo que mandar
a correr nuevamente. Ignorando la región 

.) En Algarve voy a mandar a correr todo a partir de Beta=0.9. Así que después tengo que completar
la segunda simulación de Beta=0 a 0.8.
.) En Coimbra, la primer simulación se terminó y estaban en la segunda. Así que ahora mando todo
a partir de Beta=0.3.
.) En Oporto voy a mandar a correr todo a partir de Beta=1.1. Así que después tengo que completar
la segunda simulación de Beta=0 a 1.

En Coimbra se terminó todo, así que ahora tengo que mandar en la región chiquita que faltaba.
En Oporto falta una buena parte de la segunda simulación, ahí la mando a correr.
Ya mandé a correr todo. Ahora me voy a poner a estudiar un poco de Alemán.

Arranqué a construir una función que arme los histogramas en el punto de distancia mínima. El
problema con eso es que ese punto medio depende de la cantidad de simulaciones que tome. Y hacer
un histograma con 10 simulaciones no tiene mucho sentido. Necesito definir bien qué critero voy a tomar.
Eso lo haré mañana charlando con Pablo. Y también debería tener un buen argumento sobre si tomar
muchos o pocas simulaciones. Igual posiblemente lo mejor sea hacer lo que dijo David,
hacer los dos análisis en simultáneo al mostrar los resultados.

------------------------------------------------------------------------------------------

24/06/2024

Algarve todavía no terminó, así que habrá que ver de mandar a correr cosas el miércoles
o algo así.

Volviendo al tema de los histogramas de distancias, me parece que lo mejor es arrancar con
histogramas de distancias en los puntos de mínima distancia promedio, utilizando 100 distribuciones
para el histograma.
 Ahí tengo armados estos histogramas. ¿Expando la región que observo? Me parece que hacer un histograma
de cada punto en el espacio de parámetros es un montón. Una gran pregunta es después cómo encontrar
máximos o cosas así. Pero para saber qué quiero buscar, voy a necesitar revisar un poco qué forma
tienen los histogramas obtenidos. Quizás quiera revisar ciertos percentiles o cosas así.

Si hoy no llego a reunirme con Pablo, siento que podría ponerme a revisar un rato el tema de
por qué mi código va tanto más lento que el de Hugo y la gente de Gotham. En cuanto logre armar
los histogramas hago eso.
 Viendo los histogramas, tengo un gran pico con distancias grandes, y un pequeño conjunto
de estados con distancias pequeñas. Voy a tener que ver cómo reconocer esos conjuntos de
datos. También considerando que por ejemplo en el caso del par de preguntas no-políticas,
la distribución de distancias es simplemente un único pico.

Ya revisé el código que tengo en el src. Corregí la función de Clasificación para que funcione
correctamente. Ahora puedo empezar a jugar con esto para intentar ver qué es lo que está funcionando
mal. Hice una corrida de 10000 agentes con 500 pasos, tardó 11 minutos y medio. Probemos con 1000
agentes. Esto tarda 139 segundos. Puedo intentar trabajar con esto para intentar reducir los tiempos
de simulación. Veré de trabajar en esto mañana. O quizás hoy lo mire un poco en casa, ya veré.

------------------------------------------------------------------------------------------

25/06/2024

Hoy a la mañana estuve estudiando Alemán. Después fui a cursar, volví de eso y me encontré con Nacho.
Terminado eso, intenté ponerme un poco con el código que hice yo, pero no tuve mucho tiempo. Revisé
de nuevo de a poco las cosas iniciales, es todo igual. Así que debería empezar a retocar el RK4 para
ver qué pasa ahí.

------------------------------------------------------------------------------------------

26/06/2024

En Coimbra tengo todas las simulaciones que quería resueltas. También tengo lo que me pasó Hugo,
puedo empezar a revisar de compilar todos los datos y simulaciones juntos.

En Algarve mandé a correr las segundas iteraciones, barriendo Cos(delta) [0.16, 0.5] y Beta [0,0.8].
Cuando eso termine, voy a tener que mandar el pedazo de región que falta, la región E. Que va
con Beta [1.1,1.5] y Cos(delta) [0,0.14].

En Oporto se están terminando las segundas iteraciones, barriendo Cos(delta) [0.16, 0.5] y Beta [0,1].
Acá también voy a tener que mandar el pedazo de región que falta, la región E.

Veamos de ir armando el conjunto de datos para revisar en Coimbra.

En la carpeta de Barrido_final puse los datos que tenía reformateados, para que coincidan con todos los
datos que vengo construyendo. Hay algo que podría ser un leve problema para el futuro, y eso es que
estos archivos no tienen un espacio final en los datos que sea una tabulación. Mis códigos están armados
contemplando eso. Pero creo que lo puedo solucionar fácil, tengo que considerar simplemente que lo
que levanto son los valores de las distribuciones, las cuales tienen tamaño 42x42. Entonces simplemente
puedo pedir que cuando construya la distribución, esta tome valores del array de 0:42*42 y listo.

Más problemas creo que me va a traer TODO lo demás, como el Diccionario_metricas o el graficado de los
histogramas 2D, los cuales ahora tendría que readaptarlos a las nuevas distribuciones. O, mejor idea,
puedo armar una función que a partir de las distribuciones que estoy observando, reconstruya las opiniones
de los 10000 agentes, de esa manera tengo ese array de opiniones y ya de ahí no modifico nada de todo
lo demás. Soy un genio. Suena como lo más sensato, en vez de cambiar todo el código, cambiar simplemente
eso.

Voy a mandarle un mensaje a Pablo para juntarnos, mientras termino de subir todos mis archivos a Coimbra.
Ya tengo armados los archivos reformateados de la región inicial. Ahora voy a subir lo que ya tengo
a Coimbra. Lo subo a Coimbra porque es ahí donde se terminó el barrido del espacio de parámetros que
queríamos hacer. Faltará combinar las cosas de Algarve y Oporto, cuando esas terminen de correr.

Hablando con Pablo, lo que charlamos es primero arrancar estudiando cuál es la composición de estados
en el primer cluster de distancias. También querríamos ver si el mínimo de las distancias promedio
se encuentra en el mismo lugar al tomar ese pequeño conjunto de distancias.

Arranco analizando la pregunta de Impeachment vs Wall with Mexico. Para esta pregunta considero las
distancias menores a 0.4. Eso es un pequeño conjunto de distancias. Lo primero que quiero hacer
es entonces estudiar la composición de esos estados.

Ahí armé en casa una buena idea del programa para mostrarle a Pablo, así que ya lo puedo dejar
y mañana lo concreto con los detalles finos, voy a tener que modificar los xticks y eso.

------------------------------------------------------------------------------------------

27/06/2024

Mirando todos los histogramas, por lo que observo, con pedir que las distancias de Jensen-Shannon
sean menores a 0.5, puedo revisar eso como criterio para poder revisar todos los pares de preguntas.
Siguen sin estar terminados los barridos en Algarve y Oporto.

Emprolijé los archivos de histogramas de estados en el conjunto recortado de simulaciones. Lo hice para
que se entienda qué corno está graficado. Además, agregué el armado de Mapas de colores de Distancia JS
con el conjunto de simulaciones elegido. Lo hice para poder observar si con ese conjunto, el mínimo de
distancia promediado se encuentra en el mismo lugar que el observado en los ranking de distancias.

Lo siguiente que tengo que hacer es aumentar los puntos en los cuáles miro los histogramas de distancias.

------------------------------------------------------------------------------------------

28/06/2024

Las corridas en Algarve y Oporto todavía no terminaron. Tengo que mandar a correr la parte que falta
en ambas pc's. Sigamos ahora con la parte de armar histogramas de distancias en puntos cercanos 
al punto del mínimo de distancia promedio. Para eso tomo una región de puntos cerca del punto
de tupla XX e YY.

Ya logré armar los histogramas de la región circundante del punto en el que está el mínimo. Lo siguiente
para hacer entonces es organizar esto un poco, porque tengo gráficos pero no es muy claro entonces
las conclusiones de eso. Con esto entonces lo que tenemos es la primer parte de lo que indicaba
Hugo, la idea de tener histogramas con la proba de obtener ciertas distancias. La segunda parte,
lo que nos decía Hugo que queríamos construir a partir de estos gráficos, no tengo idea de cómo
deberíamos armarlo. Me parece que habrá que charlarlo con Pablo para ver qué tal. Así que hoy
podría reventarme la cabeza por eso, podría retomar lo de ver el tiempo de simulación o
podría ir armando la presentación con estos gráficos. Yo diría de armar esa presentación el finde.

Estoy un poco confundido con los archivos que estoy construyendo. Más que nada mi confusión es si
estoy mirando correctamente el entorno del punto que quiero mirar al construir los gráficos
de composición de estados. Y esta confusión surge porque el array YY está como al revés. Eso
me está confundiendo un toque. Hagamos unas pruebas, después mando a correr cosas en Coimbra y
en Oporto, y después me iré para casa una vez definido todo. Luego el finde trabajaré un poco
en esto y en cosas de Alemán.

Mandé en Oporto las simulaciones de la región que faltaba. Lo de Algarve lo tengo que mandar
mañana. Mandé en Coimbra a correr el barrido en Beta-Kappa de la región de Beta [0,1.5] y
Kappa [0.5,10].

Miré lo que me confundía, ahora mismo estoy en la sensación de que me dejé confundir al pedo.
Si quiero mirar el Y que está adelante y el que está atrás, tengo que usar los puntos
tupla-1:tupla+2. Esto recorre los puntos (tupla-1,tupla,tupla+1). Entonces esto va a funcionar
bien así. Bien, creo que ya tengo lo que quiero, después mando eso a correr en Algarve. También
queda probar si mi idea de cómo armar los títulos va a funcionar bien. Veamos qué pasa con eso
después.

------------------------------------------------------------------------------------------

29/06/2024

Revisé, está corriendo todo. Lo de Beta-Kappa parece correr más rápido, quizás es una sensación.
Lo de Oporto está corriendo tranca, lo de Algarve todavía no terminó. Así que lo siguiente sería
mandar en Algarve a armar los gráficos que había planteado antes.

Ya mandé a correr el armado de gráficos en Algarve, mañana veo de armar alguna presentación
con eso.

------------------------------------------------------------------------------------------

01/07/2024

Estamos un poco contra las cuerdas. En estos casos de alta presión, lo mejor es descomprimir.
Después voy a tener que considerar si continuo el curso de Alemán 2 o no. La duda tiene que ver
con si voy a tener tiempo para rendir el final de la materia de Flujos de Mininni. Y es importante
rendir eso para pedir los puntos. Charlarlo con Pablo, aunque siento que la respuesta de
Pablo va a ser "rendilo y fue".

Hoy armemos una presentación rápida con lo que tengo para charlar con Pablo lo que vine
haciendo estos días.

Antes que nada, como en Oporto se terminaron las simulaciones de la región E, ya mandé el barrido
de Beta-Kappa de las simulaciones entre 20 y 39. Después en Algarve más tarde mandaré las simulaciones
entre 40 y 59.
 En cambio, en Algarve mandé las simulaciones en la región E. Cuando se termine eso, ya puedo empezar
a juntar cosas, más lo nuevo que volvió a mandarme Hugo. Y faltará lo último del código.

Los gráficos se ven interesantes, creo que hay cosas copadas para mostrar y a partir de ahí podemos
terminar de armar algo para el jueves. Me están faltando gráficos de Comp. de estados. Y hay algunos
de Promedios de estados que se ven raros. Revisemos el código y corrijamos eso.

Mandé a rearmar los gráficos de los cuatro pares de preguntas. Con eso voy a armar mi presentación
para mostrarle a Pablo lo que tengo armado. Digo yo que tengo algo razonable revisado. Después
tengo que revisar detalles del armado de los gráficos.
 Los gráficos parecen estar bien, sólo me queda raro que no se armaron algunos gráficos de comp. de
estados de otros pares de preguntas. Raro.

Hablando con Pablo, le parece que el trabajo está bien y lo que estoy haciendo sirve, pero es
poco. Revisando la semana, no me parece que realmente sea poco, pero no puedo evitar
la mala fama.

Mientras se arman los gráficos que necesito para mostrarle a Pablo el laburo hecho, me voy a poner
a reorganizar el código, mientras intento descubrir el problema del código. No lo entiendo. NO hace
los gráficos. No hay razón de por qué, pero no los hace. Tengo miedo de sacar el archivo actual que
grafica y hacer cagadas. Pablo me dijo que arme la presentación con esos gráficos y mañana charlamos
de nuevo.

Yo podría mandar a correr esto ahora, voy para casa y ya en casa me pongo a resolver lo que falta.
Lo otro que puedo hacer es mandar a correrlo, quedarme acá mientras eso corre y mientras eso se resuelve
estudiar alemán. Por último podría irme a casa más temprano y continuar el laburo desde ahí. Creo que voy
a hacer eso, así tengo en general más tiempo para armar esa presentación y mientras voy pensando qué
otra cosa hacer para el jueves que viene.

------------------------------------------------------------------------------------------

02/07/2024

Hoy a la mañana bajé los gráficos de comp. de estados que había armado y los puse en la charla
que le quiero mostrar a Pablo. Luego estuve estudiando Alemán, fui a cursar, creo que el examen
me fue bien y volví para agregar el par de preguntas de "Transgender Policy vs Refuse Same sex Service".

Hecho esto, se me ocurren tres cosas para hacer para agregar a la charla, algunas propuestas de Pablo,
otra propuesta mía.
1) Armar histogramas de los estados más y menos similares del conjunto de estados con distancias
menor a 0.45. Eso estaría bueno para comprobar que los estados tienen las formas que estamos considerando.
2) Hacer un nuevo binneado en el histograma de distancias. Esto me justificaría a tomar algún valor
intermedio de distancias y además podría servir para reconfigurar un poco más los histogramas. No suena
como un gran resultado, me gusta cómo se ven.
3) Revisar los histogramas de las regiones cercanas al mínimo de distancia Jensen Shannon. Eso podría servir
para ver cómo se comportan esas regiones, que darán posiblemente similar.
4) Armar un gráfico en el cuál se vea la fracción de los histogramas de distancia Jensen Shannon que tienen
una cierta cantidad de estados por debajo del criterio de corte de distancia. 

Hablando con Pablo, lo que me dijo es que dilucide un poco mejor lo que ocurre en ese histograma que construí.
Estas ideas que tengo de hacer, las dejos para después y mañana las charlo con Pablo. Me dijo que para mañana
tenga resuelta el histograma, complicado. Vamos igual a intentar resolverlo lo mejor posible.

Mandé a correr esos histogramas en la pc de la facultad. Si funca bien, lo mando a correr en Algarve.
Listo eso, voy a casa y quizás rankeo o mierdas. Después veo mañana de revisar alguna otra cosa que dijimos
con Pablo.

------------------------------------------------------------------------------------------

03/07/2024

A la mañana miré los gráficos de composición de estados. No sé qué se graficó, pero claramente no es
lo que quería ver. No entiendo cómo se graficó así o por qué. Mi sensación es que los arrays en el
zip son tales que uno de ellos tiene dos elementos nomás. No sé por qué.

Después fuimos a la recibida de Sofi. Muy lindo todo. Hay que preparar una reunión para la semana
que viene, alguna reunión de grupo, cosas.

Luego de revisar un rato el código, y charlando con Ale, encontré el problema de por qué los gráficos
se estaban armando mal. Ahora sí, la cosa va a funcionar. Mientras se resuelve el programa, me pondré
a revisar si tengo algo que hacer en la presentación, como para ir adelantando trabajo. Lo siguiente
será responder el mail de la gente de Uruguay. Y sino, ponerme con el armado del gráfico que se me ocurrió
a partir de los gráficos de histogramas.

Hice un cambio en el armado de los gráficos de histogramas para que se ajuste a la región graficada y que
la región que no tiene nada no se muestre.
 Lo que debería hacer es que se construyan histogramas en la región circundante al mínimo observado.
Eso creo que ahí lo armé, no resulta tan complicado por lo visto. Lo siguiente entonces sería intentar
armar ese gráfico que consideré antes, de fracción de histogramas que tienen X simulaciones con distancias
menor a 0.45. Aprovecho para agregarle una línea vertical.

Hablando con Pablo, va a ser importante revisar los puntos mínimos secundarios. Una paja armar eso, pero
podemos intentar. Luego de pelearme mucho con la idea, al final voy a armar los mínimos por mi cuenta, y
luego mandarle eso a la función para que revise esos mínimos. El primer número define la posición del y,
la cuál crece de arriba para abajo. El segundo número define el x. Ahí mandé a armar los gráficos de histogramas

Si todo funciona bien, debería armar histogramas de distancias en las regiones cercanas a los mínimos
y los gráficos de comp. de estados sólo sobre los mínimos designados. Con eso tengo los gráficos para construir
los histogramas en esas regiones que queremos mirar. Lo que quedaría quizás es armar el gráfico que estaba
considerando. Veamos si podría construirlo.

Lo mandé a correr en la pc de la facultad, ahora debería funcionar bárbaro esto. Tuve que poner un max en
una parte para que no se salteara algunos gráficos el armado de gráficos de los histogramas de distancias.
También agregué el armado del gráfico de fracción de histogramas en función de cantidad de simulaciones con
distancias menores a la distancia de corte.

------------------------------------------------------------------------------------------

04/07/2024

Cosas charladas:
----------------
1) Armar histogramas con binneados más chicos.
2) Hay que definir si es mejor elegir un conjunto chico de simulaciones
o si tomamos un corte de distancia y nos quedamos con las simulaciones que haya. (o no).
3) Lo que Hugo proponía es hacer un gráfico que en el eje Y tenga el número de estados 
y en el eje X el promedio de las distancias de los estados que haya (o no) debajo del
criterio de corte de distancia.
4) David propone armar dos mapas de calor. Uno con el promedio de distancias de lo que haya
(o no) por debajo del criterio de corte y otro con la fracción de simulaciones que hay
en cada uno de esos puntos.

Sobrevivimos a la charla, la idea es armar estos gráficos que charlamos pero con más
preguntas. Pablo dijo 20, veamos si podemos hacer con 10 y de ahí vamos construyendo la presentación.

Lo primero que quiero hacer ahora es ponerme a ordenar un poco los archivos. Tengo algunos cambios
que hice en la pc de Algarve que quiero corregir los archivos locales. Después puedo mandar a armar
los gráficos enteros, todo de nuevo. Por último, tengo que leer el paper de Sebas para juntarme a
charlar con Lucio mañana.

En Hist2D se construye el Dic_total. Podría ver de construirlo por fuera de las funciones. En especial
porque es indistinto de cada pregunta considerada.

------------------------------------------------------------------------------------------

05/07/2024

A la mañana llegué y me puse a trabajar con Lucio. Repasamos el paper de Seba, revisamos
ideas y fijamos como objetivo preparar para la semana que viene un google Colab en el cuál
simulemos el modelo de Granoveter con agentes y de ahí ver de quizás agregar el término de
pérdida de memoria de los agentes.

Ahora que estoy en la pc, debería empezar a revisar de construir los gráficos que hablamos con Hugo
y David. Si esto funca bien, lo siguiente que puedo hacer el lunes es ya mandarlo para múltiples preguntas.

Primero voy a armar el google Colab que hablamos con Lucio. Hecho eso, lo que sigue es revisar cómo vienen
las simulaciones. Está todo corriendo. Como Ale mandó a correr cosas, ahora todo va a tardar más. Ponele
que dentro de una semana reviso de nuevo cómo está esto.

Ahora sí, a armar el gráfico que quiero hacer, el que me propuso Hugo y David. La idea es tomar los histogramas,
fijar un valor que sea el criterio de distancia y tomar todas las simulaciones que sean menores a eso para calcular
su valor medio de distancia y además calcular la fracción de simulaciones que estoy mirando en
cada punto. Haré varios de estos gráficos variando el criterio de corte.
 De paso, antes que nada, voy a probar duplicar la cantidad de bines en el histograma de distancias. Creo
que duplicar es la cantidad adecuada. Más bines que eso sería una cantidad cercana a la cantidad de simulaciones.

Ahí armé un código, que si funciona bien, construye efectivamente esos gráficos que David me dijo que arme.
Veremos qué tal, si tira errores o qué. Igual, creo que por hoy ya estoy listo.

------------------------------------------------------------------------------------------

06/07/2024

Mirando lo que está corriendo en las pc's, en Coimbra se terminó el barrido de simulaciones entre
0 y 19. En Oporto se están haciendo las simulaciones entre 20 y 39. Así que voy a mandar
las simulaciones de 40 a 69 en Coimbra, y después en Oporto mando las que van desde 70 a 99.

Mandé a correr las cosas en Coimbra del barrido Beta-Kappa. Mientras estoy descargando los datos 
de Beta-Cosd para hacer simulaciones en la pc con eso.

Parece que el código que arme funca bien, veré de mandarlo en cuanto se hayan descargado todos los
archivos y pueda probarlo. Mientras voy a ir mandando los mails y cosas que venía charlando ayer con
mi vieja.

Bien, logré armar los gráficos que decía David. ¿Qué es lo siguiente para hacer? Bueno, de lo que
charlamos tengo armado lo que me dijeron. Se me ocurren dos cosas:

1) Modificar el armado de los histogramas de distancias, hacerlos en el lugar del mínimo de los
promedios nomás, lo de ver componentes en otros lados, ahora, no me sirve.
2) Tengo que revisar pares de preguntas. Juntemos tántas preguntas como se pueda. Pensemos que si
llego a juntar unos 10 o 15 pares de preguntas, correr esto va a tardar posiblemente 6 o 7 horas.

Hice estas dos últimas cosas y mandé a correr esto en la pc de Algarve. No creo que sean todos buenos
pares de preguntas, pero hay como 40 pares de preguntas. Pablo va a estar feliz. Hasta que vea
que las preguntas son una paja, entonces ya no va a estar tan feliz. Veremos qué sale.

------------------------------------------------------------------------------------------

10/07/2024

Estoy en la facultad, bajé los archivos de los gráficos que hice. Son MUCHOS gráficos, MUCHAS
preguntas. No sé si siquiera son preguntas interesantes o que valga la pena revisar. Visto que esto
funca, podría intentar armar primero una presentación con las tres preguntas principales y de ahí
agregar el resto, una vez que tengo una buena idea de lo que quiero hacer.

Revisé lo que está corriendo en las pc's del cluster, está funcando todo. Quizás el viernes da para mover
cosas. También me anoté en el congreso que nos dijo Pablo. Del Hostel no me respondieron, así que tengo que ver
de volver a preguntar ahí o preguntar en el de Casa Copada. Tengo que ver de comprar los pasajes del Buquebus.

Hoy a la tarde me gustaría ponerme con lo que charlamos con Lucio. Después debería ver de dedicar un momento
para armar funciones que levanten las distribuciones y no las opiniones. Así como dedicarme a ver lo de por qué
el código de Hugo va más rápido que el mío. Eso lo veré después seguramente. Ahora a comer.

Traspasé la mitad del código. No fui tan efeiciente como me hubiera gustado.

------------------------------------------------------------------------------------------

11/07/2024

Descargué en la pc de casa las imágenes que hice en Algarve. Ahora voy a ver de armar una presentación
con esa info lo mejor ordenada posible.

Ya armé la presentación para cinco preguntas. Mañana la idea es juntarme con Lucio y arrancar charlando
del paper de Lorenz-Spreen. O ver cómo está el collab. Quizás la reunión de mañana no sea tan larga.

------------------------------------------------------------------------------------------

12/07/2024

A la mañana me junté un momento con Pablo, charlamos ideas de cosas para modificar y corregir en los
gráficos que estoy armando. Las ideas para modificar son:

1) Sacar las líneas rojas verticales de los histogramas. (Ya corregí eso en el armado de los histogramas
de distancias)
2) Tengo la cruz que marca el mínimo en las distancias de JS. ¿Necesito sacarlo? Creo que no, no parece
que sea un problema
3) Ver los histogramas de mínimos de distancia en los puntos de mínimos.
4) Modificar en el promedio de distancias la barra de colores, para que no se sature lo graficado.
5) Mostrar la composición de los estados en los diversos histogramas de distancias.
6) En los gráficos de similitud, quitar la clasificación de estados. Va a achicar el tamaño
de los títulos y además justamente es algo que no venimos prestándole mucha atención.
7) Utilicemos el mismo código de colores para los gráficos de promedios de distancias según 
criterio de corte que para los promedios de distancias total.

Voy a poner los cambios en el código. Terminado eso, completaré el formulario de la SICSS.
De paso, ya se terminó el barrido en el espacio Beta-Cos(delta) que estaba haciendo en Algarve.
Ya puedo mandar un barrido en el espacio Beta-Kappa, o alguna otra cosa ahí.

Siento que van a ser muchos los gráficos de composición de estados. Por ahora no los voy a armar.
Ahí mandé a correr todo en Algarve. De ahí veré qué tengo y qué construyo. Voy a mandar a hacer
los gráficos de composición de estados. Después los separaré en otra carpeta manualmente.

Dejé corriendo los gráficos, tendré que ver qué hago en la carpeta de Algarve.
El lunes armo la presentación con los nuevos gráficos.

------------------------------------------------------------------------------------------

15/07/2024

Hugo me pasó hoy temprano los archivos que simuló. Ahí los pude descargar. Le tengo que responder
que descargué los archivos sin problemas. Después los intentaré mirar un poco a ver si encuentro
algún problema.

Estoy revisando los archivos para ver dónde los estoy juntando. Por lo que me estoy dando cuenta,
no junté archivos en ninguna pc. Yo diría de juntar todos los archivos en la pc de Coimbra. Después
los archivos de Beta-Kappa los voy a juntar en Oporto. Bien, parece que todo está correctamente
juntado en Algarve. Hermoso. Veré si mañana puedo mandar a correr algo como para empezar a armar
mapas en esa zona.

Armé una buena parte de la presentación, preparé cuatro preguntas para eso, corregí los gráficos
que se veían feos. Creo que fue un día razonable. No sé si bueno, razonable.

------------------------------------------------------------------------------------------

16/07/2024

Me levanté y no pospuse la alarma, pero costó salir de la cama. Llegué a la facultad, hablé con
Pablo y me puse a revisar la presentación. Hoy quiero resolver cuatro cosas:

1) Completar la sección de la última pregunta
2) Armar el gráfico de cómo se agrupan las preguntas en el espacio de parámetros que
observamos antes. Podría hacer eso superponiéndolo al gráfico que tengo del espacio de
parámetros que caracterizamos para 1000 agentes.
3) Armar un gráfico parecido a ese pero con un criterio de corte según los clusters de
distancias. Eso requeriría que lo mire un poco más a ojo, pero es algo que podría armar
a partir de los gráficos que tengo. Repito que tendría que aclarar que no está hecho
de forma automatizada, sino que es un poco a ojo.
4) El inicio de la charla, agregarle dos diapositivas para definir bien las preguntas que uso
y cómo las ordeno.

Ahora me voy a poner a estudiar un cachito de Alemán y después me iré a la clase de Alemán más
tarde.

Volví a la tarde. Ya completé la sección de la última pregunta. Queda quizás completar el desglose
de las distribuciones de la cuarta pregunta, pero no creo que valga tanto la pena.

Ahora voy a seguir con el punto 2, el gráfico de cómo se agrupan las preguntas en la región del espacio
de parámetros. Ponele 3 o 4 preguntas por cluster. Si llegas a cinco preguntas por cluster, sos un
genio.

------------------------------------------------------------------------------------------

17/07/2024

Soy tan boludo que no comitee el laburo que hice ayer en la facultad. Por suerte igual no
fue la gran cosa, no va a ser muy problemático el merge.

Ideas de la charla:
-------------------

1) La distancia JS tiene problemas para detectar los estados de Consenso Radicalizado.
2) El modelo no está logrando replicar estados con tres picos.
3) Otra opción es la distancia de Kolmogorov-Smirnoff. Puede servir para identificar mejor
los estados de Consenso Radicalizado.
4) Probar rehacer el último gráfico mirando sólo un 10% o 20% de estados más similares.
5) Permitir que el modelo clasifique por sí mismo las preguntas y no seamos nosotros los
que definimos cuáles son políticas y cuáles no.
6) Ver algunas preguntas de encuestas viejas para ver si se van moviendo en el espacio de parámetros.

Para facilitar los gráficos, Pablo me propone que:
-------------------------------------------------

1) Agregue sobre los márgenes de los histogramas 2D de las encuestas, debería agregar los histogramas
1D de los cuáles surgen las distribuciones de encuestas.
2) Cambiar los colores de graficado para que se observe mejor los contrastes. Me propuso usar una escala
que arranque con blanco en el cero y crezca hasta el negro en 1.

¿Qué hago ahora? Lo primero que se me ocurre es intentar armar un texto para la encuesta de lo del 
instituto de verano de Uruguay. Así ya mañana llego, veo de sacarme unas fotos después de comer y ya
cargo eso.

Después veo el tema de habilitar la tarjeta de crédito de la VISA y veo el tema de poder hacer el
espermograma en un laboratorio más cercano que el de Avellaneda. Por último, me pondré con el laburo
que estamos haciendo con Lucio, primero continuando el traspaso del código de Sebas. Mañana quizás pueda
ver de hacer el barrido que hablábamos con Lucio.

------------------------------------------------------------------------------------------

18/07/2024

Llegué a la facultad, no muy temprano. Mergee los archivos. Me puse a mirar lo que hizo Lucio con el
código de Granovetter. Tengo algunas dudas del código, pero en principio funciona y la idea está.
Me confundió un poco lo de que los agentes deben interactuar o con otros agentes o con el campo externo.
Pero la idea es razonable. En la ecuación se obtiene el punto fijo a partir de la suma de las contribuciones
del término de la probabilidad acumulada y de la cobertura. Pero en la evolución lo que se representa
es que los agentes se pueden enterar de las noticias por sus vecinos o por leer del tema en los medios.
O pueden al no enterarse por ningún camino, decidir desactivarse.

Hoy estoy trabajando poco eficiente. Tengo muchas cosas por hacer pero no estoy metido en ninguna.
Lucio me dió una mano, me sacó una foto y cargué los datos en la encuesta de la SICSS.

¿Qué trabajos tengo para hacer?

1) El trabajo con Lucio sobre el modelo de Granovetter. Estaría bueno caer con una idea más clara
sobre cómo meter la competencia de tópicos en el modelo. Yo pensaba en hacer algún barrido o
cosas, pero creo que no es principal eso ahora, puede esperar a la próxima reunión.
2) El trabajo con la gente de GOTHAM. Venimos bien, la idea es rearmar el gráfico de distribución
de preguntas en el espacio de parámetros. También debería ver lo de probar usar la distancia de Kolmogorov-
Smirnoff para ver si eso registra mejor los estados que son más bien consensos radicalizados.
3) Tengo que ponerme a ver los videos sobre programación en R y leer el libro que proponen en la página
del SICSS.

Voy por un café, me voy a poner a leer un poco el paper para lo de mañana y así llego más preparado
para la charla. Bien, me anoté cosas, creo que estoy en buena idea para mañana.

Voy a hacer dos cosas más y después me voy a casa. Primero voy a imprimir el boleto de viaje a Uruguay.
Después voy a ver el tema de laboratorios más cerca de casa como para hacer el estudio del espermograma.

------------------------------------------------------------------------------------------

19/07/2024

Llegué maso temprano, organicé algunos mensajes. Ahora me voy a poner a ver cosas sobre codear en R.
Nos juntamos con Lucio para seguir trabajando en el proyecto del modelo de Granovetter. Armamos
un código que contempla dos tópicos, que corre dentro de todo bien. Consideramos que lo que está
haciendo el código no refleja quizás lo que queremos, pero estamos encaminando. Eso va bastante
bien.

Hoy voy a intentar resolver dos cosas. Lo primero es lograr que el código levante los datos de las
distribuciones y desde ahí corra todo los mismo que viene laburando. Lo segundo es seguir viendo 
algunos videos de codear en R.

La idea es que tengo 42x42 puntos. Cada uno de esos puntos tiene la fracción de agentes. Esos
cuadrados tienen por lado 2/42. Entonces la idea es reconstruir un vector de opiniones a partir
de esta distribución. En el punto [0,0], la idea es que están las opiniones que se encuentran entre
[-1,-1+1/21] para X y [-1,-1+1/21] para Y. Ok, se me ocurre que lo que podría hacer es armar un array
con los valores medios de cada caja. Luego en función de la posición en la distribución, me construyo
mi array final.

Ahí armé la función. Estoy viendo de agregar eso a la parte de Barrido_final. Aunque creo que va a ser
más higiénico si simplemente copio los archivos de funciones y graficar que tengo en Comparación datos
y ya arranco desde ahí. Va a ser un bardo y mucho tiempo perdido al pedo sino.
 Bien, ahí parece que está todo. Confío en que ahora esto funca correctamente. Hace falta probarlo.
Yo diría de intentar construir algunos gráficos de histogramas 2D, como para ver que tenga sentido.
Claramente, no está teniendo sentido. Esto es un bajón. Veré si puedo hacer que tenga sentido antes de
irme el martes. No sé cuándo lo haré igual. Un re bajón.

------------------------------------------------------------------------------------------

22/07/2024

El finde estudiamos con Lucio sobre las materias de los finales que queremos rendir. Hoy terminé de
ver el bootcamp de R y ya me puse con la función que reconstruye opiniones a partir de las
distribuciones finales.

Ahí corregí los errores de la función. Voy a incorporar eso a la función general para ver que se hacen
bien las distribuciones y ya mando a correr esto. Ya lo incorporé, funca bárbaro. Bueno, lo siguiente entonces
es definir qué gráficos necesito del espacio.

Gráficos importantes:
---------------------

1) Entropía en el espacio de parámetros
2) Covarianza en el espacio de parámetros.
3) FEF en el espacio de parámetros
4) Gráfico manual de regiones
5) Distancia JS en el espacio de parámetros
6) Hist2D similares en mínimos de promedios de Distancia JS
7) Histogramas de las distancias JS en los puntos mínimos
8) Composición de bines de los histogramas
9) Mapas de colores de promedios de distancia y fracción de estados promediados
según una distancia de criterio de corte.

Ya incorporé todo esto en el armado de gráficos, e incluso me encargué de reducir ciertas partes para que
no tarde tanto, específicamente reduje el calculado del diccionario de métricas y el cálculo de la entropía
reiterado.
 Funciona bien esto, ya puedo mandarlo a correr en Coimbra con los datos que tengo ahí.

Mientras, mandé a correr las últimas 10 simulaciones del barrido del espacio Beta-Kappa en Coimbra.
Ya con eso, no quedará nada más por correr. A menos que querramos ser más finos en nuestro barrido,
que eso es algo discutible.

Imprimí algunos documentos que necesitaba. Mandé a correr el armado de archivos en Coimbra y eso presenta
un problema. Los archivos que armé en la región fuera de la región pequeña: Beta [0,1] y Cosd [0,0.15],
tienen un tab extra al final de la distribución, que los archivos que construí yo no tienen. Tengo que solucionar
eso de forma de que o todos los archivos tengan el tab o ninguno lo tenga.

Por otro lado, hablando con Pablo, coincidimos en que la idea sería armar el gráfico que ubica las preguntas en
el espacio de parámetros según dónde se encuentren los mínimos para el total de las simulaciones y para un
conjunto de 20 o 30 simulaciones. Esto se puede hacer sencillo, total es pasarle el conjunto de preguntas a la
función, calcular los mapas de distancias JS y luego que vaya graficando. Va a ser una función que tarde mucho en correr
porque tiene que calcular todos los mapas de distancias. Pero supongo que se puede hacer.

------------------------------------------------------------------------------------------

02/08/2024

Ya volví de la SICSS. Estuvo muy bueno. Ahora tengo que ocuparme de dos cosas claves. La primera es
que tengo que anotarme en lo de CAPES. Lo segundo es seguir laburando en el laburo del modelo de agentes.
Lo tercero que tengo que hacer ahora es repasar lo que investigué como para ver qué mencionarle a Pablo.

Me parece que lo clave de mencionarle a Pablo del SICSS es que conocí gente, que vi una info interesante
sobre la ética de manipular datos que refieren a personas, que descubrí data sets interesantes del
Latinobarómetro, CSES o Gdelt, y también que vi algo interesante sobre cómo armar encuestas.

Hablé con Pablo, le pareció interesante lo que mostré, ya seguiremos hablando más en la próxima semana.
Lo que quedamos es en posponer la charla de la semana que viene. Primero le mando un mail a Hugo sobre
eso y después me pongo con lo de anotarme al CAPES, a ver qué puedo hacer hoy.

------------------------------------------------------------------------------------------

04/08/2024

Ya identifiqué los archivos que tengo que corregir. Se encuentran en una carpeta que dice Beta-Cosd en el inicio
de la pc de Coimbra. Esos mismos los tengo descargados en mi pc de casa. Lo que voy a hacer ahora, con la ayuda de
Chat GPT, es colocar un tab al fondo de esos números.

Bien, parece estar funcionando ahora. Lo veré más tarde a ver si quedó bien.

------------------------------------------------------------------------------------------

06/08/2024

El 05/08 fue el DDF. Hoy vamos a ponernos con el trabajo de la gente de España, intentemos organizar
un esqueleto de presentación. Pero antes de eso, ¿Qué es lo que tengo que hacer de trabajo?

1) Preparar presentación para la reunión de la próxima semana con la gente de GOTHAM.
Tengo que implementar las cosas que me dijeron en la última charla.
2) Continuar con el trabajo de Granovetter que estábamos haciendo con Lucio. Revisar
las notas en el Drive para ver cómo continuar eso.
3) Preparar presentación para la próxima reunión de grupo sobre las cosas que aprendí o
vale la pena contar en el grupo de mi viaje a Uruguay.
4) Completar presentación para la presentación de Brasil de Mova La America.

Hoy voy a continuar con la implementación de la presentación de GOTHAM, a la tarde continuo
un poco con la presentación de Brasil. Bien, me descargué un conjunto de los archivos con 
el espacio de tab al final de las distribuciones. Lo que debería hacer ahora es por un lado
armar los mismos gráficos que armé en el espacio Beta-Cosd, para el espacio Beta-Kappa.
Luego de eso, lo que haré será analizar los gráficos armados para ver qué pongo en la presentación.
Mirado eso, lo tercero que haré hoy será continuar con la presentación de cosas para la
beca de Mova La America de Brasil.

------------------------------------------------------------------------------------------

08/08/2024

El 07 estuve todo el día trabajando en completar los documentos que necesitaba para la inscripción
del programa de Mova la América de Brasil. Lo bueno es que ya terminé con eso, así que eso es un
laburo hecho. Tengo que empezar a despertarme más temprano, hoy llegué re tarde. No puedo seguir
así.

Lo que voy a hacer ahora es primero descargar los gráficos que armé de los dos espacios de parámetros.
Lo segundo que quiero hacer es armar una carpeta en la cuál guardar los archivos de composición de estados,
así no me ocupan tanto lugar en mis carpetas.
Lo tercero es armar una función que grafique los mínimos de cada par de preguntas en el espacio de parámetros.
Lo cuarto sería agregar lo que me dijo Pablo de poner los histogramas de las preguntas en los bordes de los
histogramas 2D.

Bajé los gráficos. Como cosas rápidas, observé que en el espacio de Beta-Cosd y Beta-Kappa algunos gráficos
de distancias JS recortados se construyeron vacíos, no entiendo por qué. Lo otro que noto es que en el
espacio Beta-Kappa algunos gráficos del histograma 2D más similar me dan nulo. No comprendo por qué, tendré
que revisarlo. Una tercer observación es que las regiones que había delimitado antes para las simulaciones
con 1000 agentes parecen haberse movido un poco. No pareciera ser un problema eso, tendré que ver
de redefinirlas para la próxima reunión.

Lo primero que yo haría ahora es revisar por qué se generaron ciertos gráficos vacíos. Hecho eso, lo siguiente
sería armar la función que grafica los mínimos en el espacio de parámetros como charlamos la última vez.

------------------------------------------------------------------------------------------

09/08/2024

Hoy llegué más temprano. Viste que las amenazas sí funcionan.

Cuestión, ayer me volví temprano a casa y aún así tardé horrores en llegar, no pude hacer nada.
Hoy tengo que ponerme a descular qué corno estoy viendo y a armar el gráfico este de los mínimos
de los pares de preguntas en el espacio de parámetros. Eso va a requerir que catalogue el tipo de
preguntas que estoy viendo. No, cierto que el plan era que nosotros revisemos cómo se agrupan
y de ahí determinar si son preguntas políticas o no. Voy a necesitar construirme una tabla
con la info de las preguntas y guardarme eso, sino no se me ocurre cómo retener esa info en un
gráfico.

Vamos anotando las cosas a revisar. Empecemos por el mapa en el espacio Beta-Cosd:
1) La entropía está mal. (Modifiqué la función que calculaba la entropía)
2) La covarianza se ve rara. Pero le creo, se parece bastante a lo de antes.
3) Los gráficos de Fracción de estados finales parecen estar muy bien.

Necesito revisar la forma de los gráficos en diversas regiones. Y ver qué pasa con la entropía.
Ya ví qué está mal, estaba ploteando la varianza de la entropía y no la entropía. La varianza
tiene la forma que tiene que tener. Pasemos a lo siguiente, armar algunos gráficos para revisar que
efectivamente lo que veo es razonable. Los gráficos de histogramas los voy a guardar en carpetas
aparte.

Ya tengo esos archivos, están en la carpeta de distribuciones. Genial.
Lo siguiente que me genera dudas es:
1) ¿Por qué algunos gráficos de mapas de colores recortados me quedan los gráficos en blanco?
2) En el caso Beta-Kappa, tengo problemas con los gráficos de Histograma 2D de los estados
más similares. Por algún motivo, me quedan vacíos.

Ya revisé por qué algunos de los gráficos de distancia JS recortados están vacío, el problema
es que la dist_lim que elegí es 0.45, pero algunos gráficos tienen distancias por encima
de eso, así que cuando quiero hacer el corte de cantidad de simulaciones en el punto de
distancia promedio mínima, resulta que en ese punto ninguna simulación tiene distancia menor
a dist_lim, por lo que intenta plotear con una matriz vacía.
 Igual me doy cuenta que por lo que charlamos, no es ese el gráfico que quiero hacer ahora,
sino armar gráficos con una pequeña fracción de agentes. Así que voy a comentar este tipo
de gráfico y depués descomentar los gráficos de ranking de distancias JS.

Estoy revisando los gráficos de Hist_2D de las simulaciones similares a las distribuciones de
las encuestas. Todos los gráficos que tienen problema son los gráficos con K = 0.5. Quizás
hay un problema en los datos ahí. Aunque la fracción de estados finales parece estar en
cooncordancia con lo que esperaba ver.
 Ahora entiendo por qué están mal los gráficos de histogramas similares. De nuevo, el código funciona
bien, el problema es que remueve a los agentes que se encuentran en la cruz central. Y justamente
cuando K = 0.5 resulta que TODOS los agentes están ahí. Se me ocurre que eso se puede solucinar
cambiando el código para el caso Beta-Kappa de forma que si el PARAM_X <= 1, entonces omite esa
parte. Ahora igual eso me deja dudas, ¿Cómo corno arma el mapa de distancias Jensen-Shannon si esa
parte la saca?
 Hablé con Pablo. No hace falta que me preocupe por esto, al final no voy a hacer nada de comparación
con datos en el espacio Beta-Kappa. Y debería mandar a correr datos en las pc's, total están bastante
al dope actualmente. Después voy a tener que revisar bien qué quiero mandar y donde. La cosa es tener
cuidado de cómo expando la región.

Hagamos las correcciones al código de Beta-Kappa, subamos los dos códigos, mandemos a correr y después
intentemos armar el gráfico de las preguntas ubicadas en el espacio de parámetros.

Modifiqué las funciones de Histogramas 2D y de gráficos de Comp_estados, para que esos gráficos vayan
a carpetas aparte. Esas cosas me construyen MUCHOS gráficos.

El código para la región Beta-Cosdelta está, preparemos el código de Beta-Kappa.

Ya están los dos códigos cargados y todo corriendo. Esperemos que no se corte. Posiblemente sea buena
idea la semana que viene revisar un poco la documentación.

¿Qué cosas tengo para hacer ahora?
----------------------------------
1) Esa función que vengo prometiendo que asigna las preguntas en el espacio de parámetros según dónde
están los mínimos de la distancia JS.
2) Agregar los histogramas 1D en los histogramas 2D. Va a ser un tema eso, no muy simple en el sentido
de que voy a tener que revisar cómo incorporar esa parte del código en varios códigos. Bah, en el que
construye los gráficos de histogramas de las encuestas, en los otros no.
3) Revisar el tema de la distancia de Kolmogorov-Smirnoff. Estaría bueno tener aunque sea leído eso,
si no pude hacer mucho al respecto.
4) Revisar alguna pregunta y graficarla para ver cómo varía en el tiempo. Quizás esto lo podamos dejar
para la otra reunión.

Construyamos la función que ubica las preguntas en el espacio de parámetros. El problema de esta función
es que va a tardar mucho, porque tiene que calcular la matriz de DJS para cada par de preguntas de nuevo.
Bueno, hagamos una cosa. Arranquemos con hacerlo funcionar. Después lo que puedo ver de
hacer es guardarme esa info en su momento cuando armo por primera vez la matriz de DJS
y así no la recalculo cada vez.

Está básicamente armada la función. Hay que probarla para ver que realmente funciona.
Por hoy vamos a casa, comitteemos todo y listo.

------------------------------------------------------------------------------------------

12/08/2024

Hoy me levanté tarde, no entiendo por qué. La mañana básicamente se me arruinó. Vamos a intentar
armar todo lo que tengo que armar lo mejor posible. Estoy corriendo el pedazo de código que quiero
ver si construye el gráfico que quiero de las preguntas en el espacio de parámetros.
Efectivamente está tardando un buen rato la simulación. Debí haber probado con cinco preguntas
más o menos, como para arrancar. Mientras esto corre, tengo dos cosas que puedo hacer. Una es
mandar a correr en Coimbra, Oporto y Algarve las simulaciones que me faltan. Eso podría venir
bien total voy a estar esperando este resultado.

Lo segundo es ya agrandar este código para que se vea bien con las simulaciones con un porcentaje de
las preguntas. Me conviene hacer ya simulaciones con hasta 40 simulaciones.
 ¿Tengo una forma de guardar los datos de las matrices? Porque sino estoy corriendo esto montones
de veces y me tarda mucho en hacer el gráfico. Veamos cuánto tarda en hacerse eso, que tengo miedo
que tarde una eternidad. Además tengo que agregar el cruce de preguntas y por último tengo que
además lograr extraer qué preguntas caen donde. Bah, eso lo puedo hacer a ojo con los mapas de colores
de distancias JS.

Lo mandé a correr a las 11, son las 15 y todavía no termina esto corriendo en casa. Voy a necesitar
ser listo en cómo mando esto a correr. Primero, me parece que lo principal entonces es hacer lo que
charlamos, armar este gráfico con todas las simulaciones y con hasta 20 simulaciones. Algo que estaba
pensando, voy a tener que agregar ruido en el eje X y en el Y para que los puntos se vean diferenciados,
sino no voy a ver cuántas preguntas hay en cada lugar. Sólo habrá una pregunta si no meto el ruido. Lo que
voy a hacer es obtener una distribución centrada en cero con un sigma que sea un cuarto de la distancia
entre puntos. Eso me parece importante porque el 95% de los números obtenidos de la muestra van a estar
en 2 sigmas, entonces el 95% del ruido se va a encontrar a la mitad de la distancia entre puntos. Eso
me ayuda a que no se me corran preguntas en un punto con preguntas en otro punto.

Lo otro que pensé es que tendría que armar csv con las matrices de distancias JS. De esa manera, voy a
poder correr esto mucho más rápido. Sino la verdad que el tiempo que tarda en correr esto está escalando
demasiado y cada pequeño error puede costar horrores.

Bien, agreguemos el ruido y el tema del armado del gráfico para menor cantidad de simulaciones.
El gráfico terminó en mi pc. Se hizo, tardó casi 5 horas. Habrá que ver si tarda más o menos en
la pc de Coimbra.

Se me ocurrió cómo hacer esto de forma más rápida para tener en el mismo tiempo de corrida los gráficos para
una cantidad reducida de simulaciones. Voy a construir los vectores X e Y para todas las simulaciones en
el mismo for, así esto no tarda 24 horas, tardará 10 más o menos. Y eso es una victoria.

Ya está corriendo y está agregado el tema del ruido y de que se armen los gráficos con un subconjunto
de simulaciones. Ahora puedo mandarlo a correr en Coimbra.

Lo siguiente que quiero hacer entonces es mandar a correr datos para el espacio Beta-Cosd en las tres pc's.
Aunque Ale está usando mucho Coimbra, un poco Algarve y nada Oporto. Tendré que ver cómo reparto código en
las tres pc's. Pero para hacer esto tengo que asegurarme que tengo el código correcto Y que voy a mandar
las simulaciones a la carpeta correcta. Eso es importante porque si mezclo las nuevas simulaciones
con el armado de datos, va a ser un bardo. Un importante bardo.

Los archivos que tengo que agregar al final los voy a ir guardando en la carpeta Extras_Beta_CD.
Considerando que Ale está laburando bastantes cosas, yo diría de mandar a correr símplemente unos 5
hilos, para resolver 20 iteraciones en esta pc.

Lo que estoy haciendo es armar un barrido más fino en Beta, por lo que la idea es que Beta corra
entre [0,1.5] de a 0.05.

¿Qué iteraciones corro en cada pc?
----------------------------------
1) En Coimbra tengo 5 hilos que van a correr cada uno 4 iteraciones, por un total de 20 iteraciones entre
0 y 19.
2) En Algarve tengo 10 hilos que van a correr cada uno 4 iteraciones, por un total de 40 iteraciones entre
20 y 59.
3) En Oporto tengo 10 hilos que van a correr cada uno 4 iteraciones, por un total de 40 iteraciones entre
60 y 99.

Bien, ya mandé a correr cosas en las tres pc's. Mañana me pongo con lo de agregar los histogramas a los bordes
de los histogramas 2D. Y si veo que es necesario, me haré el armado de los csv con la info de las matrices de DJS.
No creo que para esta semana llegue con lo de revisar una pregunta que vaya evolucionando en el tiempo, lo dejaré
eso para la otra reunión.

Me parece bien cortar acá, ya tenemos las tres pc's laburando a full. Dentro de un mes posiblemente esté terminado
el barrido que les mandé. Lo bueno es que todas tienen que hacer 4 iteraciones, vamos a ver cuál termina más rápido.

------------------------------------------------------------------------------------------

13/08/2024

Llegué a la facultad. Ahora sí tengo miedo. Los gráficos importantes que quería mostrar, no están.
No salieron. Y parece que van a tardar un poco más. Estoy medio jugado. Va a estar para mañana.
Pero no me gusta llegar tan justo. En lo que eso se resuelve, aprovechemos el tiempo, resolvamos las dos
cosas que ayer me quedaron en el tintero. Primero, agregar los gráficos 1D en los histogramas 2D.

Bien, logré armar los gráficos como yo quiero. Éxito. Costó un poco, tuve que aprender a usar el Gridspec.
Aún así, logré en 30 minutos lo que me podría haber tardado 6 horas fácil. Ya cargué esos gráficos al
drive. Por si de boludo resulta que en casa esos gráficos nos los puedo armar.

Ahora voy a construir los csv con las matrices de distancia Jensen-Shannon. La idea es armar un csv que en cada
fila tenga cada uno de los arrays de la tercer dimensión de la matriz. Bien, el csv se armar correctamente.
¿Me encargo de ver cómo levantarlos? Bah, ahora no hace falta. Me encargaré de mandarlo a correr ahora en
Coimbra, y después veo qué hago mientras. Bien, ya está corriendo. Ahora yo tengo que ponerme a armar la
presentación con lo que tengo. Después, veré qué tengo para mañana y qué puedo hacer con eso.
Dios, necesito ayuda.

Empecemos con la presentación. Estaría bueno tener el gráfico con las regiones marcadas que hice a mano.
Lo primero que me parece que estaría bueno es contar cómo queda configurado el espacio de parámetros
para 10000 agentes. Eso lo puedo observar de los gráficos de Entropía, Covarianza y Varianzas.

El código del gráfico de preguntas distribuidas en el espacio de parámetros está tardando mucho más
de lo esperado. Esto me está volviendo loco. Debería haber tardado como mucho 15 o 20 horas, no 25.
Sólo me queda rogar que cuando llegue a casa esto esté terminado.

Mientras estoy armando la presentación. En principio me parece que tengo para mostrar algo, pero
no es mucho avance. Sobre lo que charlamos la última reunión básicamente no avancé. Lo que planeo
mostrar suena interesante en mi cabeza, no sé qué tan interesante resultará. Espero que funque todo
bien. Me queda leer un poco sobre distancia de Kolmogorov-Smirnoff. Veré si saco algo de eso,
como para no caer muerto a la charla y tener algo más de dónde tirar.

Mañana tengo que conseguir alguna simulación de Polarización descorrelacionada en el espacio
Beta-Cosd. Para eso tengo que pedir Beta = 1.1.

------------------------------------------------------------------------------------------

14/08/2024

Notas de la charla:
-------------------
.) Revisar si el problema de la clasificación es que los picos están poblados
de forma no uniforme.
.) La forma de la polarización puede ser importante de revisar. ¿Ha cambiado la distribución
de opiniones respecto al caso 1D? Es importante para destacar la importancia del análisis
2D.
.) Revisar el tema del test de Kolmogorov-Smirnoff.
.) Podría hacer un gráfico de distancia vs simulación para  ver que no tengo simulaciones
outliers al considerar las 20 simulaciones más similares.
.) Prob. de polarización vs Beta-Kappa. Si hay tiempo con ganas. Esto estaría bueno
para que el paper no esté en el vacío, sino vinculado con el primer paper.
.) Secciones del numerical recipes 14.3 y 14.7, creo. Es sobre el test de Kolmogorov-Smirnoff.

Numerical Recipes in C.

Algo que noté es que algunos de los gráficos de las distribuciones están armados al revés. Revisar
por qué carajos pasó eso.

Bien, ya terminó la reunión y baje tres cambios. Vamos a continuar con el laburo y organizar lo que sigue.
¿Qué cosas hacer? Podría descargar el libro que me pasó Hugo. mañana me pongo
a trabajar en la cosa que estamos haciendo con Lucio. Ya tengo las tres pc's laburando en realizar
más simulaciones, no necesito solucionar eso ahora. Lo que se me ocurre es que debería
hoy armar la función que levanta las matrices de DJS de los archivos csv y ver de modificar los
códigos para que tenga eso introducido. De esa manera, nunca más va a tardar tanto ese gráfico.
 Trabajando en esta función noto que esto me genera un cambio en la estructuración del trabajo.
A partir de ahora, en vez de armarme una lista de preguntas a considerar y tener esa lista en 
el código de Graficar, voy a relegar esa lista al código de Profunc. Una vez ahí, construiré la
lista de preguntas a considerar. Con esa lista de preguntas es la que trabajaré siempre. Y cada
vez que quiera revisar nuevas preguntas, agrego esas preguntas al conjunto de matrices que tengo.

Otra cosa que puedo hacer hoy es empezar a documentar cosas, porque debe haber varias cosas
perdidas en el laburo.

Estoy pensando que debería rearmar las matrices de DJS de forma tal que los datos guardados
tengan seis decimales guardados. Cuatro me parecen poco.

Bien, tengo el código que quería. Ahora a armar una función y reorganizar todas las cosas que
hacen uso de las matrices de DJS. Al final no reorganicé el resto de cosas. Queda para
después.

------------------------------------------------------------------------------------------

15/08/2024

A la mañana fui a hacer el espermograma. Y sin embargo, fue todo tiempo perdido, porque al
final no pude entregar las muestras. El día pasó, poco y nada hice todavía.

Lo que sí hice fue inscribirme en el concurso de ayudante de primera de física. Por suerte
es bastante simple el proceso ahora.

Lo siguiente que voy a hacer es reemplazar la parte de la función que usa los csv y reconstruye
las matrices de DJS. Después quedará para hacer mañana, o el finde, revisar las preguntas con
lo que estábamos charlando con Pablo. La forma en que las preguntas se distribuyen en el
espacio Beta-Cos(delta) para 100 simulaciones es radicalmente distinto que para 20 simulaciones.
Incluso parece realmente que está teniendo errores en cómo los clasifica. Lo que Pablo me propone
es ir mirando de a clusters y con eso ir armando un análisis robusto de lo que estamos viendo.

Ahí hice los cambios, creo que están bien. Terminé sacando el Dict_Anes que usaba antes. No probé
el código, habrá que probarlo pronto y ver si todo funca bien. Yo confío que sí.

Miré el código de lo de Granovetter. No avancé nada, pero por lo menos ya lo tengo leído y estoy
en tema.
