------------------------------------------------------------------------------------------

22/03/2024

Al final terminé de revisar los archivos del barrido Beta-Kappa, sólo había problemas en la iteración
90 a 99. Así que tendré que en Oporto mandar a correr dos conjuntos de datos separados. Uno que recorra
todo el espacio para iteraciones entre 90 y 99 y otro que recorra el espacio para Beta mayor a 1
para iteraciones entre 50 y 69.

Voy a aprovechar la mañana para preparar el main cosa de que cuando se termine la corrida de Oporto,
que va a terminar en uno o dos días, ya lo pueda mandar a correr rápido. Después de comer me pondré
con el análisis de la ecuación dinámica del modelo. Bien, ya modifiqué el Instanciar. Lo que tengo
que hacer es mandar las simulaciones de 50 a 69 en Oporto mañana a la tarde.

------------------------------------------------------------------------------------------

26/03/2024

En la mañana fui a llevar el documento de matrimonio de mamá al estudio, pero al final el documento
no estaba actualizado. Tendré que conseguir la actualización del registro civil y de ahí
volver a intentar.

Las simulaciones en Algarve terminaron, así que podría mandar a resolver las simulaciones entre
80 a 99.

Hoy la verdad me agaró un sueño imposible, no avancé mucho. Pero estuve mirando lo que me pasó Hugo
y lo que tengo yo de la cuenta, logré armar la misma expresión para la derivada de la perturbación.
Queda entonces ver dónde queda efectivamente el valor de Beta de transición. Lo interesante es que
aparece un factor 2 que antes no estaba. Vamos a ver cómopuedo hallar entonces el valor de Beta de
equilibrio.

------------------------------------------------------------------------------------------

27/03/2024

Lo primero que hice en la mañana fue revisar mails, después mandé a correr las simulaciones entre
90 y 99 en el barrido beta-kappa en Oporto. Con eso voy a tener todas las simulaciones en ese espacio
y voy a poder armar los gráficos con la estadística de 100 simulaciones. Eso debería durar de acá a
la semana que viene. Quizás.

Mientras estoy haciendo el análisis de la ecuación dinámica para definir el Beta tal que el estado de
polarización ideológica transiciona de ser inestable a estable.

------------------------------------------------------------------------------------------

04/04/2023

En la mañana revisé las carpetas de Oporto y demás para ver que todo estuviera corriendo bien, mandé
a armar gráficos en Oporto ahora que tengo las 100 simulaciones por punto y estuve intentando pensar
cómo armar el gráfico que Pablo me pide que haga sobre el espacio Beta-Kappa.

Mientras tanto, se siguen resolviendo las simulaciones que faltan del espacio reducido Beta-Cos(delta).
Esas simulaciones van a terminar cerca de tres o cuatro días.

Lo que tengo que hacer ahora primero es ver cómo armar un gráfico que muestre clarametne la composición
de estados en el espacio Beta-Kappa. A partir de eso, podría pensar un mapa para el espacio de
Beta-Cos(delta).

Hoy apenas miré las cosas, no hice mucho más. La verdad, siento que perdí buena parte del tiempo. Dios,
como odio estos días. Y eso que vine temprano y todo.

------------------------------------------------------------------------------------------

05/04/2023

Hoy estuve todo el día armando los gráficos de distribución de estados en el espacio de parámetros.
Logré hacer los gráficos tanto para el espacio Beta-Kappa como para el espacio Beta-Cosd.
Siento que no son la gran cosa, pero Pablo me dijo que haga algo así, o mejor. Yo saqué esto.
Tengo que ser mejor que esto, espero estar mejorando con el tiempo, no estar estancándome.

Bueno, no nos matemos, mañana partida, el domingo tarea de Alemán y del curso de aplicaciones
a becas. Lunes retomamos con ganas y fuerzas.

------------------------------------------------------------------------------------------

08/04/2023

Hoy llegué más o menos temprano, los trenes están tardando mucho ahora, temas de despidos.
VLLC. A la mañana voy al curso de inglés. Revisé las simulaciones en el espacio reducido.
Ya casi están todas terminadas, queda una sola en la carpeta de algarve. Así que después de
comer, junto todas las simulaciones de Algarve en Coimbra y desde ahí armo los gráficos del
parámetro de espacios.

Veamos qué simulaciones tengo en cada pc. En Coimbra tengo dos carpetas.
) Datos: 0-9.
) Zoom_beta-Cosd: 30-39, 50-79.

Algarve.
) Zoom_beta-Cosd: 10-29, 80-99

Oporto.
) Zoom_Beta-Cosd: 40-49

Ahora lo junto todo. Ahí mandé a correr para que se armen todos los gráficos del espacio reducido.
La pregunta es qué hago ahora. Para mi tiene interés revisar qué es lo que pasa con el sistema
para el punto fijo de cuatro extremos, ese análisis de la ecuación dinámica, que creo que
razonablemente dará que Beta crítico es 1, yo creo que será una investigación interesante.

Otra cosa que puedo hacer esperando a la reunión con Pablo, es armar la presentación para el
miércoles. Aunque eso lo puedo hacer mañana. Lo tercero sería ponerme a leer algún paper en
el tiempo hasta juntarme hoy con Pablo.

Hablé con Pablo, la idea es armar los gráficos indicando las regiones no con colores, sino delineando
los contornos, usando números romanos para indicar las regiones, luego colocar cerca gráficos que
indiquen estados finales característicos y explicar cómo es que terminé definiendo esas regiones.
En particular, si habría alguna forma de identificar mejor la curva que surge en el espacio Beta-Kappa,
la cuál yo definí puramente a ojo.

Ahí armé los gráficos que me dijo Pablo, me falta colocarle los números romanos al segundo. Mientras
se están terminando los gráficos en la región reducida. Tengo mala espina.

------------------------------------------------------------------------------------------

09/04/2023

Revisé Coimbra, se hicieron los gráficos del espacio reducido. Se ve algo interesante respecto
de los estados con anchura, y se ve que coinciden los resultados con lo observado en el espacio
total Beta-Cos(delta).

Sigamos con el trabajo de Pablo hasta eso de las 11 y algo. Después a las 12 voy a comer, a las
13 voy al abrazo en el 0+inf y después a cursar.

Terminé de cursar, trabajé un poco en la presentación y después me fui a casa temprano para que
no me agarre la lluvia.

------------------------------------------------------------------------------------------

10/04/2023

A la mañana llegué y mandé a armar gráficos de Histogramas 2D. Después tuvimos la reunión de grupo.
Comí en la oficina y rápido terminé de armar lo que pude de la presentación para la
gente de GOTHAM. Pablo hoy no pudo venir, lo mismo Jesús. La charla la tuve yo con Hugo
y Mario.

De la charla saqué los siguientes puntos:
1) En el espacio de parámetros Beta-kappa, la curva que diferencia estados de Consenso Radicalizado
respecto de los estados Polarizados, en principio Hugo la estudió bastante desde varias perspectivas.
Su conclusión es que es un resultado de la saturación de la función de tanh. Una propuesta que
me hizo es intentar ver si reemplazando la función tanh por una función signo, entonces
debería ver si esa curva desaparece y sólo veo una línea constante en Beta aprox. 0.2.
2) Hugo me dice que esos estados de polarización descorrelacionada que estoy observando
si los dejara correr más tiempo, posiblemente vería que convergen a otro tipo de estados,
quizás Pol 1D con anchura o Pol 1D nomás, yo no creo que sea el caso. Vamos viendo.
3) Algo interesante sería intentar ver si el modelo 2D para el caso de Cos(delta) = 0 se puede interpretar
como dos modelos unidimensionales independientes. Una forma de comprobar eso sería tomar un
punto del espacio de parámetros en el cuál surjan estados de polarización descorrelacionada
y comparar esos estados con estados polarizados en el caso unidimensional. Si el caso 2D con
Cos(delta)=0 se pudiera interpretar como dos simulaciones independientes, una para cada tópico,
entonces lo que debería poder observar es que la polarización simultánea de ambos tópicos debería
ocurrir con una probabilidad que es la probabilidad al cuadrado de que cada tópico polarice. Y
eso se debería obtener a partir de realizar simulaciones 1D. Para ellos esto es una pregunta
interesante respecto de cómo el modelo 2D no es sólo el modelo 1D 2 veces, sino que trae algo
propio a la formación de opiniones por la distancia entre opiniones. (Creo)
4) Cuando vaya a hacer los cálculos analíticos, probar hacer unas simulaciones primero, para
ver que efectivamente lo que quiero ver se da como yo planteo y no perder un montón de tiempo
en cuentas que no llevan a nada.
5) Al hacer las simulaciones con las que vamos a trabajar, no guardar todos los datos, sino guardar
sólamente el histograma de datos. Y considerar que ese histograma de datos tiene que tener
una cantidad de cajas que coincidan con la cantidad de cajas de las preguntas que voy a mirar,
porque algunas preguntas tienen 6 cajas y otras 7.

------------------------------------------------------------------------------------------

11/04/2023

A la mañana hablé con Pablo sobre lo que fue la charla con la gente de GOTHAM. El plan ahora
es armar una lista de cosas para hacer en estas tres semanas hasta la próxima reunión. Ahora
mismo no estoy realizando simulaciones. Debería considerar arrancar con eso, para que ya
esté funcionando antes de hacer el resto de cosas.

En la mañana estuve organizando cosas, mandando mensajes, imprimiendo comprobantes y así.
Mañana voy a ir a buscar las fotos de mi recibida. Para eso, tengo que llamar antes. Entonces,
a eso de las 14 llamo y después a las 17 salgo para allá, total es tomarme el tren hasta Retiro,
pedalear 10 minutos desde ahí y después volverme.

Hagamos la lista de orden de cosas por hacer esta semana y la que viene:
(Una idea que propusimos es ya fijar Kappa=10 y dejar de preocuparnos)
-----------------------------------------------------------------------

Es importante arrancar con esto porque requiere simulaciones, así que eso puede ir corriendo
mientras hago otras cosas.
########################################################################################################
1) Podría arrancar con las simulaciones del sistema usando la función signo en vez de la función
tanh. Eso me parece importante para arrancar porque va a requerir varias simulaciones. Digamos
que lo armo con 30 iteraciones, eso debería alcanzar para ver algo. Y el espacio que voy
a barrer debería ser de Kappa [1,10], con Beta de [0,1]. Después puedo ver de agregar
más Kappa, pero lo importante es hacer un barrido bien rápido de la cosa, variar grueso,
con Kappa variando de a 1 y Beta variando de a 0.1. Esto ya lo podría mandar hoy.
2) Empezar a descargar los datos de la ANES, ir construyendo un conjunto de datos con 10000
agentes cosa de tener para ir comparando nuestras simulaciones con los datos extraídos de las
encuestas. La idea sería armar datos en la región reducida de Beta-Cos(delta). Además, tengo
que asegurarme de guardar los datos, no guardando las opiniones de TODOS los agentes finales,
sino guardar el histograma final de los agentes. Hugo me dió un consejo de cómo guardar los
datos de forma de poder comparar mis resultados en el caso de que la opinión tenga 6 respuestas
o de que tenga 7.
3) Hugo me dijo de hacer simulaciones en un punto del espacio de Parámetros donde observe
varios casos de simulación y que por un lado corra simulaciones en el modelo 1D y por el otro
corra simulaciones en el modelo 2D. La idea es ver si la probabilidad de observar estados polarizados
2D es igual al cuadrado de la posibilidad de que polarice un estado 1D. Esto tendría alguna comparación
en el caso en que Cos(Delta)=0, siendo que en ese caso la ecuación del tópico 1 queda casi
completamente desacoplada de la ecuación del tópico 2. Hay todavía un pequeño acople en lo que
a los pesos refiere, así que no debería ser lo mismo. Digo yo. Esto puedo mandarlo por un lado
en Algarve y por el otro en Coimbra, con 10000 agentes. Creo que habíamos discutido que era
una buena idea usar esa cantidad de agentes.
########################################################################################################

4) Antes de continuar las cuentas analíticas sobre el valor de Beta que cambia la estabilidad de las soluciones,
conviene intentar primero hacer simulaciones con redes completas y con la pequeña perturbación
propuestas, para ver si el resultado corrobora lo esperado. Así nos damos una idea del resultado
final. Después de esto puedo retomar mis cuentas. Eso significa, PRIMERO, revisar que me quedó
una cuenta pendiente del caso en el que considero la solución ideológica. LUEGO, continuo la cuenta
del caso de polarización descorrelacionada.

Cosas más opcionales:
---------------------
5) Hugo me había dicho la otra semana que revise si pasaba que partiendo de un estado que yo
sé que finaliza en un estado de polarización radicalizada, al ir aumentando el cos(delta) el
estado se transforma en un estado de polarización ideológica. La idea está buena y no requiere
mucho esfuerzo. Creo.
6) Me dijeron de revisar si encuentro encuestas en Argentina que nos permitan observar
polarización, porque en las encuestas que buscaron en España, la mayoría no tiene casos de polarización.
7) Podría ver de continuar con el clasificador neuronal, aunque en principio no es ni de
cerca necesario ahora.

Después de haberme distraído un poco, resolví el punto 1. Cambié la función en el archivo de avanzar,
armé una nueva etapa llamada Func_sign y mandé en Oporto a correr este barrido en la región que 
determiné antes.

------------------------------------------------------------------------------------------

12/04/2023

A la mañana fui a realizar el trámite del Banco Provincia. Llegué a la facultad a las 13.

Ahora estoy revisando la lista de cosas por hacer. Entre lo que tengo que hacer, me parece que
es mejor empezar por el punto 3 y no por el 2. Más que nada porque el punto 2 va a tardar tanto
que empezarlo ahora o el lunes da lo mismo, el otro punto en cambio me parece que me va
a dar resultados más rápido.

Estuve muy distraído hoy, pero armé el programa que simula en 1D. Más tardé con el armar una función
que en C me construya mi histograma. No era tan difícil, sólo soy un boludo que está desatento.
Ahora tengo que subir esto a Algarve o Coimbra y mandarlo a correr. Fijate que esto no contempla
estar en una carpeta de src. Pero creo que no es problema, simplemente tengo que compilarlo y
mandarlo. Voy a tener que modificar el archivo de Instanciar quizás, pero nada grave. O el
de Metainstanciacion. Espero que cuando arme la función para el caso 2D esto sea más fácil.
Vamos para casa. No es temprano en realidad.

------------------------------------------------------------------------------------------

15/04/2023

Al final el finde no hice la tarea que planeaba hacer, pero no fue tan terrible, la semana
arrancó igual y estamos todos bien. A veces no tiene tanto sentido hacerse la cabeza con
eso.

Hoy lo que tengo que tener terminado es el armado de las opiniones en cajas al final de la simulación,
cosa de ya mandar eso y entonces de los siete puntos que marqué para hacer, tener ya dos
resueltos.
 Repasé la función para el caso 1D, ahí logré hacer que funcione. El caso 1D está planteado
para redes con N=1000, Beta=0.7, Kappa=10 y Cosd=0. Cada simulación tarda 215 segundos.
Así que si corro 30 simulaciones en ese punto, no debería costarme más de 20 minutos,
siendo que esas simulaciones las voy a repartir en 10 hilos. Después tengo que subir
el archivo de opinion.e a Algarve y desde ahí modificar el Instanciar para mandar a correr
la simulaciones 1D.

Ahora me pongo con las simulaciones 2D. Logré que compile. Mañana lo mando a correr en las
pc's de la facultad. O quizá hoy en casa si llego temprano y no estoy para jugar ranked.
Perdí un poco de tiempo en esto, pero al final del el armar estas funciones que me construyan
los histogramas en el código en C es importante para el siguiente punto a trabajar.
Es cierto que faltan dos cosas importantes:
1) Probar que la función esa esté laburando bien. MUCHO MUY IMPORTANTE.
2) Organizar correctamente el cómo interpreto los números que la cosa esta
me tira. Así identifico correctamente qué va dónde. Armar las cajitas de 6*6 o las de 7*7
va a ser un bardo. Bah no, mentira, va a ser una boludez.

------------------------------------------------------------------------------------------

16/04/2023

No puedo mandar a correr las simulaciones en la pc de Algarve, ya fue, lo corro en la pc
de la facultad. Mientras eso corre, mandé las simulaciones en Coimbra, eso no fue tan simple.
Había un error medio boludo en la función de clasificación. Ahora me voy a poner a estudiar
alemán. Tengo que después hacer caso a mis notas sobre revisar que todo funcione bien,
no puedo moverme a ciegas como estoy haciendo ahora. Si bien la función está copiada
de algo que funciona, tengo dudas.

Fui a cursar Alemán.

Mandé en la pc de Coimbra para realizar 1000 simulaciones. Eso debería tardar unos días.
Mientras, voy a necesitar simulaciones en la pc de la facultad que lleguen hasta 1000 también
de 1D.

Repito para que no se olvide, es mucho muy importante que pruebe que las funciones de Clasificación
están funcionando bien. Para eso voy a tomar algunas simulaciones, usar sus semillas y simular en
la pc de la facultad. A esas simulaciones les voy a guardar las opiniones finales, y las distribuciones.
Voy a comparar que las distribuciones me den lo mismo que las opiniones finales.

------------------------------------------------------------------------------------------

17/04/2023

Mandé en la pc de la facultad cuatro procesos para resolver 250 simulaciones en cada terminal.
En la pc de Coimbra ya está casi terminada la tanda de simulaciones para el punto del espacio
Kappa=10, Beta=0.7 y Cosd=0. En la carpeta de Oporto está terminado el barrido en el espacio
Beta-Kappa para la función signo. Así que ya podría trabajar en ver que efectivamente se arma
el gráfico que esperamos.

Yo creo que hoy tendría que hacer dos cosas. La primera es ver de descargar datos de la ANES,
así ya puedo mandar a correr datos. Lo segundo es ver que efectivamente la función Clasificación
funciona bien. Para eso voy a descargar algunas simulaciones, rearmar esas simulaciones en esta
pc usando las semillas, guardar las opiniones finales y comprobar que los gráficos que puedo
recrear usando las distribuciones que surgen de la función Clasificación son iguales a las
distribuciones que surgen de las opiniones finales.

Tengo unas dudas sobre qué hacer con el tema de los datos de la ANES. Vengo revisando mis archivos,
no encuentro algo de lo que me decía Hugo de tener cuidado al revisar los datos de la ANES.
Lo que voy a hacer, luego de debatirme y pensar qué corno quiero, es hacer gráficos de distribución
de opiniones confrontando todas las preguntas entre ellas. 

Estoy revisando las etiquetas. Labels_pre tiene 20 etiquetas mientras que labels_post tiene 9 etiquetas.
Juntos suman 29 etiquetas. Pero dict_labels tiene apenas 23 etiquetas. Es decir que de las 29 etiquetas
que mira, sólo 23 están identificadas. Debería esforzarme por identificar las otras 6.
Ahí vi, las seis que están removidas en labels_pre y labels_post son 6 preguntas en labels_pre
que tienen 4 respuestas, en vez de seis o siete. En labels_post sacaron la pregunta sobre si Obama es
musulman, pero no la de ubicación propia a lo largo del eje conservador/liberal. Supongo que para arrancar,
por hoy, puedo dejarla.

Observando los gráficos, encontré claros casos de: Consenso Radicalizado, Polarización Ideológica, Polarización
1D con anchura, Polarización descorrelacionada, y quedaría definir qué cuenta como casos con anchura
o algunas cosas más. Creo que lo que estaría bueno es poder definir qué pares de preguntas vamos a
revisar y con qué vamos a comparar esos casos. También vale notar que algunos casos resulta que tienen
algunas casillas vacías. Quizás para no hacer un barrido demasiado grande y poder observar estos
resultados, estaría bueno moverse con Beta entre [0.6,1.2] y Cos(delta) entre [0.05,0.15]. Y para
eso hacer un barrido BIEN grueso, total no busco con eso caracterizar alguna curva, sólo quiero tener
gráficos para comparar con lo observado en la ANES.

Voy a descargar entonces cinco archivos de Probas_Pol en 2D así ya mañana arranco con los gráficos
para revisar que la Clasificacion está funcionando bien. Descargué cinco simulaciones al azar, las
cinco pareciera que convergen a estados de Consenso Radicalizado. Voy a tener que armar las simulaciones
mañana usando esas semillas y ya después veo qué pasó.

------------------------------------------------------------------------------------------

18/04/2023

A la mañana fui a llevar el acta de matrimonio al estudio de traducción, y volví al mediodía. Después
me puse a ver los datos del barrido en el espacio Beta-Kappa. El gráfico pareciera dar lo que yo busco,
pero no se ve muy claro. Debería probar extender un poco la región y hacer un poco más fino el barrido.
Mañana lo hablo con Pablo cualquier cosa.

Ahora me voy a poner a estudiar Alemán. Después me pondré con lo de escribir la carta de motivación y el 
CV. Por último, con algo de tiempo, quizás lea un paper. Mañana repasaré el tema de las simulaciones
en el espacio Beta-Kappa, y de las simulaciones en un punto del espacio de parámetros.c

------------------------------------------------------------------------------------------

19/04/2023

Lo primero que voy a hacer es comparar el gráfico de Func_sign en el espacio Beta-Kappa
con el gráfico que tengo de esa misma región hecho en la etapa de opinión actualizada.
Para eso voy a tomar la función que arma el gráfico del espacio de parámetros de Entropía
y reducir la región de los ejes X e Y.

Mientras se resuelve eso, voy a probar lo de revisar que las funciones de Clasificacion
estén laburando bien. Aunque me descargué sólo gráficos con estados finales de Consenso.
Busquemos primero dos o tres gráficos en estados de polarización. No encontré estados de
polarización, pero encontré estados que tardaron mucho en resolver. ¿Estará funcionando
mal la función de Clasificación?

Voy a identificar los estados según su número de iteración.
.) Iter=100: Los agentes convergen a un estado de Consenso radicalizado, en el punto [10,-10].
Pero la función de clasificación dice que están todos en el lugar final. Lo cuál no tiene
sentido, porque si el valor de Y es -10, en la asignación el valor de "fila" debería ser 0
y por tanto la casilla marcada debería ser una de las primeras 42, no la última.
.) Iter=110: Convergen al punto [10,-10]. Van al mismo lugar que los anteriores
.) Iter=120: Convergen al punto [10,10]. Este sí le corresponde marcar en la última casilla
del vector de Distribución. Pero claramente parece que la función está funcionando mal.
.) Iter=130: Convergen al punto [10,10].

Es al pedo seguir con esto, efectivamente la función de Clasificación está mal, pero lo está
por un error muy boludo, y es que el ancho que usaba para ver si un número iba a una fila u otra
era 0, entonces al dividir por cero daba infinito y todos los agentes iban a parar al mismo
lugar. Así que eso está mal y tengo que rehacer todas las simulaciones corrigiendo simplemente
ese detalle.
 De paso, increíblemente, para el caso 1D sí hice bien el cálculo del ancho. Genial, eso significa
que eso está bien hecho y no necesito rehacerlo. Lo cuál es genial, porque estas simulaciones
eran más complejas de hacer porque no podía hacerlas en las pc's del cluster.

Voy a cerrar el día de hoy con tres cosas.
1) Mando a correr en Coimbra las simulaciones de un punto del espacio de nuevo. Esta vez corrijo
la función de Clasificacion para que funcione correctamente.
2) Mando en Oporto unas simulaciones extras de la región Beta-Kappa para intentar delinear mejor
lo que observo. La idea es expandir la región, no la cantidad de simulaciones.
3) Armo una carpetita con algunas simulaciones separadas del tema de datos de la ANES, así me queda
más sencillo para mostrarle a Pablo después lo de algunas distribuciones razonables.

Para el punto 2 hago un barrido extra, agregando valores de Kappa en los puntos intermedio.
1.5, 2.5 y así.

------------------------------------------------------------------------------------------

22/04/2023

A la mañana fui a la última clase del curso de "Becas:Help!". Tomé algunas notas sobre cómo
mejorar el CV y discutimos con los demás consejos para buen CV.

Lo que voy a hacer ahora es armar el gráfico del mapa de entropía para la función signo,
y después ver cuál es la proba de que un estado esté polarizado para el caso 1D y para el
caso 2D.
 Miré los archivos armados. Por motivos que no comprendo, faltan archivos, otros están armados
a la mitad. Hubo un corte, es imposible que no haya habido un corte.

Tengo descargados los archivos de agentes en un punto del espacio de parámetros, en los cuales
me guardé la distribución de opiniones finales, no las opiniones finales. Lo que tengo que hacer
ahora es con Python, levantar los datos, reordenarlo en el formato de una matriz y desde ahí
construir los gráficos de histogramas. Además de eso, lo otro que tengo que hacer es calcular
la proba de que un estado sea polarizado en el caso 1D y de que polarice en ambos tópicos
en el caso 2D.

1) Armo histogramas a partir de la distribución de opiniones.
2) Clasifico esos estados según los criterios definidos previamente.
3) Calculo la proba de tener estados polarizados en 1D y la proba de tener estados con
polarización descorrelacionada en 2D. (¿Debería comparar con polarización descorrelacionada?
¿Cómo es la proba si considero polarización 1D?)

De estas tres cosas que quería hacer, no hice ninguna. Siento que hoy podría haber hecho
más, pero estuve trabado toda la tarde. También hice muchas pequeñas cosas. Voy
a ponerme a pensar mejor cómo trabajar esto y ya el miércoles veré de resolverlo más claro.
Mañana voy a estudiar para el final de Mininni y después marcha.

Hablando con Pablo, él me dijo de que descargue yo los datos de la ANES para revisarlos,
así voy trabajando eso por mi cuenta. Debería separar preguntas políticas y no políticas,
así como separarlas según sus distribuciones. Después con eso ver qué tipo de gráficos
me quedan así tengo una buena idea de qué cosas espero observar. Mirar el paper de Baumann
y el de Hugo vendría bien para repasar qué es lo que estoy queriendo buscar.

Hoy y mañana me voy a poner a pensar cómo construir mis nuevas funciones en Python, cosa
de ya cuando em vuelva a sentar, ponerme a escribirlo de una y no volver a trabarme con
el cómo armar las funciones en el caso de Probas_Pol.

Por último, Pablo me propuso que arme más estadística a las simulaciones de Func_Sign,
no que barra más fino. Debería cancelar lo que mandé a correr y mandar de nuevo
con más estadística. Más que nada porque sino voy a tener un problema al querer armar
el gráfico porque algunos puntos van a tener más estadística y otros menos.
Lo que voy a hacer es mañana borrar las simulaciones con valores de Kappa fraccionarios.

------------------------------------------------------------------------------------------

23/04/2023

Ya borré esos archivos con valores de Kappa fraccionarios, mientras en Oporto se completan
simulaciones para llegar a tener 100 en ese barrido.

Ayer me quedé pensando en lo que dijo Sebas. Quizás es mejor seguir guardando las opiniones
finales de los agentes. Y además, me hice un quilombo queriendo usar la función de Hugo para
las simulaciones 1D. ¿Por qué no usar mis simulaciones? Si dan similares los resultados,
no tiene sentido diferenciar unas de otras. Podría usar mis simulaciones y con eso armarme
en Coimbra las 1000 simulaciones para el caso 1D y para el caso 2D. Mandemos hoy las 2D 
guardando las opiniones finales y después veo qué hago mañana.

Hablando con Pablo, los dos pilares para la próxima charla es trabajar con los datos y poner
en orden el análisis teórico. Así que por lo visto, no es central esto que estoy haciendo.
Pero como ya empecé, tengo que aprovechar y presentarlo.

------------------------------------------------------------------------------------------

24/04/2023

A la mañana lo primero que hice fue mandar a correr la tanda de simulaciones 1D de Probas_Pol
en la pc de Coimbra. Lo siguiente que voy a hacer es repasar las ecuaciones dinámicas cosa de tener
algo que presentarle a Pablo mañana y organizar los datos para la presentación.

Estuve avanzando con esto, aunque en eso vamos. Mañana me voy a poner en la mañana a estudiar
un poco de lo de Mininni y después seguiré con esto un poco más.

------------------------------------------------------------------------------------------

26/04/2023

En el día de ayer estuve trabajando en el análisis de la ecuación dinámica básicamente todo
el día. Fui a una reunión de grupo y llegué tarde por el tema de estar esperando el link para
la charla por el Repositorio de Investigación.

Hoy llegué, revisé el tema del análisis dinámico, charlé con Sebas y me propuso considerar un
análisis matricial similar a lo que veíamos en Mate 3. Igual creo que lo mejor sería probar
hacer lo que dijo Hugo, de hacer simulaciones sobre el análisis perturbativo y ver qué da eso.

Las simulaciones en Coimbra están terminadas. Las de Oporto todavía no. Debería por un lado
armar lo de Coimbra, cosa de tener por lo menos ese resultado. Pero creo que puedo dejar
eso para el próximo lunes sin dramas. Yo hoy me pondría a ver el tema de descargar datos de la
ANES. Voy a revisar la ANES, ver qué se puede descargar, qué preguntas hay y hacer esa separación
que me dijo Pablo de preguntas políticas y preguntas apolíticas, cosa de tener un conjunto
saludable de preguntas a revisar.

Ahí estuve viendo un poco de alemán, ahora sigamos con lo del modelo de opiniones. Descargué
los datos de la ANES, habrá que ver de armar el conjunto de preguntas que querramos observar.
Eso tomará un tiempo. 

------------------------------------------------------------------------------------------

29/04/2023

Llegué al horario usual. Me puse a revisar mails y cosas que quedaron pendientes. Ahora que
resolví eso, me pongo con las cosas que dejé corriendo.

1) Ver lo de la entropía en el espacio Beta-Kappa para la función Signo.
2) Determinar la fracción de estados polarizados en el caso 1D y en el caso 2D.
Usaré el algoritmo que tengo para eso y compararé con tomar 200 gráficos de histogramas
3) Leer un paper
4) Seguir laburando los datos de la ANES.

El punto 1 ahora no voy a poder, no terminó de correr eso.
Para el punto 2 necesito armar funciones que trabajen con un sistema 2D y un sistema 1D.

Logré armar uno de los gráficos de torta que quería, pero claramente esto no es lo más
interesante para charlar en la próxima reunión. Lo que deberíamos charlar en la próxima
reunión es el trabajo con los datos, de los cuales apenas armé unos gráficos nuevos
y después descargué los datos de la ANES de 2020. Así que la cosa viene lento en
ese tramo. Habrá que hacer nuevas cosas si quiero avanzar. Ahora voy a leer rápido
el paper de Sebas respecto a lo de Granovetter, al final no recuerdo si ese fue el
paper que leí o no. O si leí un paper en algún momento. Dicho eso, lo que sigue es
ponerme a revisar las preguntas y cosas del modelo. Así que hagamos esto y preparemos
para ir a casa temprano hoy. Iré a buscar el documento que necesitaba la semana que viene.

La idea sería primero que nada tomar las preguntas que tenemos y separarlas en función de
si son políticas o no. ¿Qué definimos como preguntas políticas? La respuesta es que las
preguntas políticas son aquellas que los demócratas o republicanos responderían distinto,
mientras que las apolíticas son aquellas que no apelan a esa identidad partidaria.

Anotemos esto en el código. Ahí hice la separación, básicamente todas las preguntas
son políticas. Razonable. Veré mañana si puedo encontrar unas ocho o diez no
políticas y de ahí veré cómo resuelvo esto. Pero el armado de los gráficos de histogramas
funciona de una.

------------------------------------------------------------------------------------------

30/04/2023

No llegué más temprano que lo usual, pero casi. Armé los gráficos de las distribuciones
de las opiniones diferenciando preguntas políticas y no políticas. Habiendo charlado con
Pablo, la pregunta sería ver si estas preguntas políticas cruzadas con ellas mismas me
generan gráficos distintos a cruzarlas con las preguntas no políticas. Aunque siento
que las preguntas no políticas apenas tengo casos que mirar, quizás valga la pena revisar
la ANES nueva y de ahí ver qué puedo extraer. Al final del día, la forma de levantar
datos que usa Hugo me podría servir para la nueva ANES creo yo, simplemente tengo que levantar
el csv y convertirlo en un pandas.

Lo siguiente que puedo hacer entonces son los gráficos de la distribución en el espacio de
opiniones y de ahí ver qué puedo rescatar. Comparemos preguntas políticas con otras políticas
y apolíticas con apolíticas. De ahí vamos armando los gráficos. Una vez que tenga los gráficos,
ampliar el conjunto de preguntas, porque no me satisface lo que tengo. No creo que tenga
suficientes apolíticas.

Antes que esto, Pablo me dijo de aplicar la medida de la distancia Jensen Shannon. Olvidemos
lo anterior, hagamos esto YA. No tengo una distribución para comparar, pero podría aprovechar
dos distribuciones que tengo acá y medirles su distancia Jensen-Shannon, ver que la idea se
puede y que da razonable. Bien, ya vi que calcula y cómo hacer la cuenta. En su momento será
un bardo ver cómo clasificar los gráficos según si son preguntas de 6 casilleros o 7.

Hice la cuenta sobre los datos de la ANES 2020, aprox. tiene 1200 preguntas. Veamos de levantar
los datos de la ANES 2020. Bien, los datos parece que se levantan sin problemas.

Preguntas Políticas 2020:
-------------------------
1) V201200: SCALE LIBERAL-CONSERVATIVE SELF-PLACEMENT (7 Opciones)
2) V201225x: VOTING AS DUTY OR CHOICE (7 Opciones)
3) V201231x: PARTY IDENTITY (7 Opciones)
4) V201246: SPENDING & SERVICES: SELF-PLACEMENT (7 Opciones)
5) V201249: DEFENSE SPENDING: SELF-PLACEMENT (7 Opciones)
6) V201252: GOV-PRIVATE MEDICAL INSURANCE SCALE: SELF-PLACEMENT (7 Opciones)
7) V201255: GUARANTEED JOB-INCOME SCALE: SELF-PLACEMENT (7 Opciones)
8) V201258: GOV ASSISTANCE TO BLACKS SCALE: SELF-PLACEMENT (7 Opciones)
9) V201262: ENVIRONMENT-BUSINESS TRADEOFF: SELF-PLACEMENT (7 Opciones)
10) V201342x: ABORTION RIGHTS SUPREME COURT (7 Opciones)
11) V201345x: FAVOR/OPPOSE DEATH PENALTY (4 Opciones)
12) V201356x: FAVOR/OPPOSE VOTE BY MAIL (7 Opciones)
13) V201362x: FAVOR/OPPOSE ALLOWING FELONS TO VOTE (7 Opciones)
14) V201372x: HELPFUL/HARMFUL IF PRES DIDN’T HAVE TO WORRY ABOUT CONGRESS/COURTS (7 Opciones)
15) V201375x: RESTRICTING JOURNALIST ACCESS (7 Opciones)
16) V201382x: CORRUPTION INCREASED OR DECREASED SINCE TRUMP (7 Opciones)
17) V201386x: HOUSE IMPEACHMENT DECISION (7 Opciones)
18) V201405x: REQUIRE EMPLOYERS TO OFFER PAID LEAVE TO PARENTS OF NEW CHILDREN (7 Opciones)
19) V201408x: SERVICES TO SAME SEX COUPLES (6 Opciones)
20) V201411x: TRANSGENDER POLICY (6 Opciones)
21) V201420x: BIRTHRIGHT CITIZENSHIP (7 Opciones)
22) V201423x: SHOULD CHILDREN BROUGHT ILLEGALLY BE SENT BACK OR ALLOWED TO STAY (7 Opciones)
23) V201426x: WALL ON BORDER WITH MEXICO (7 Opciones)
24) V201429: BEST WAY TO DEAL WITH URBAN UNREST (7 Opciones)



Preguntas Apolíticas 2020:
--------------------------


------------------------------------------------------------------------------------------

01/05/2023

Volví del cumpleaños de Estaban. Ahora queda ponerme a hacer algunas cosas, empezar a preparar
la presentación de mañana. Se me hace importante primero revisar que las preguntas que
arme tengan gráficos útiles. Si eso es así, lo siguiente será ir viendo quizás de empezar
la presentación. Si no es así, me pongo a buscar algunas preguntas más.

Por algún motivo que no comprendo, mi función me está tirando errores, a pesar de que no
tiene nada distinto a lo que tenía ayer. Resolveré esto mañana en la facultad.

Hagamos un esquema de la charla:
--------------------------------

1) Les comento que estuve mirando las preguntas que estaban en el archivo que me pasó Hugo
y revisando esos gráficos que producen para ver cuáles gráficos podríamos querer comparar
con nuestros datos, en caso de querer observar tal o cual estado.
 Muestro varios gráficos y coloco al lado las distribuciones con las que digo que se podrían
comparar.
2) No creo que de ninguna forma me dé el tiempo, pero podría intentar medir la distancia
Jensen-Shannon de algún gráfico en particular con la de una de las distribuciones obtenidas
de la ANES.
3) Les cuento que bajé los datos de la ANES 2020, logré leer los datos, los cuáles tienen un
formato muy similar, y construir gráficos parecidos. Para eso estuve revisando la guía de
datos y de ahí seleccionando preguntas que podrían ser relevantes o útiles.
¿Por qué queremos la encuesta más nueva?
4) Debería definir una región en la cuál realizar las simulaciones de 10000 agentes.
Eso debería poder hacerlo posiblemente si tengo una idea de qué gráficos quiero buscar.
En Beta razonablemente tenga que ir entre [0,1] y Cos(delta) entre [0,0.15]. Un barrido
medio crudo sería de a 0.05 para Beta y 0.01 para Cos(delta). Necesito saber cuánto va
a tardar esto.
5) Si queda lugar, mostrar alguno de los otros resultados.

------------------------------------------------------------------------------------------

02/05/2023

A la mañana preparé la presentación para la gente de GOTHAM. Armé los gráficos de las
distribuciones 2D y de ahí fui armando alguna idea de las cosas importantes.

Después de la reunión, fui al coloquio de Darío, aunque no pude ver mucho, volví para
anotar algunas cosas y después me fui a casa. Estuve como cuatro horas viajando para 
ir a buscar el documento que faltaba por el tema de la nacionalidad italiana. Todavía
sin suerte.

No pude mandar a correr el barrido en el espacio de parámetros para el caso de 10000
agentes. Mañana es lo primero que mando a hacer en la mañana.

------------------------------------------------------------------------------------------

03/05/2023

No estoy pudiendo mandar a correr simulaciones en la pc de Coimbra, no sé qué error está
encontrando el código. Voy a rehacer un código único desde la pc de la facultad y subir
eso a las tres pc's y de ahí mando a correr todo. A este código le falta las funciones
de Clasificación y los vectores asociados.

Mandé a correr en mi pc un archivo de 10000 agentes, veamos cuánto tarda en resolverse.
Es un estado con Beta 0, debería converger a un estado de Consenso Radicalizado. Está
tardando más de una hora esto. Es un muy mal presagio esto.

Mientras termina de correr el programa con 10000 agentes, voy a descargar los datos de
la ANES de años anteriores. Descargué las encuestas de 2012, 2008 y 2004.
La de 2012 parece que tiene un formato muy similar a las últimas 2, esa creo que se
podría agregar a lo visto sin mucho problema. Pero la de 2008 y la de 2004 tienen un
formato muy distinto y no estoy seguro de tener los archivos correctos para observar
las preguntas consideradas.

La de 2008 tiene un codebook separado para la encuesta pre y otro para la encuesta 
post. Habría que repasar el codebook para separar las preguntas. Lo bueno es que
parece que también usan números negativos para respuestas fuera de formato, pero
algunas preguntas tienen MUCHÍSIMAS respuestas con números por fuera de los primeros
10, habrá que revisar si son un problema o si se pueden ignorar.

NO TERMINÉ DE VER CÓMO ES EL FORMATO DE LA ANES 2004. TAMBIÉN TENGO QUE VER DE LEVANTAR
LOS DATOS, VER SI ME TIRA ALGÚN ERROR.

Justo terminó el código en la pc de la facultad. Por lo visto corre y llega a un resultado
razonable. El problema es la cantidad de tiempo que tarda. Tardó 11813 segundos en resolver
7000 pasos. Una locura es eso. Para 1000 agentes tardó simplemente 40 segundos. Las escalas
son completamente distintas. Veamos si funciona con los datos de clasificación. De paso,
el archivo apenas ocupa 900 kb. Casi un mega. Si tengo 100 simulaciones, para 36 puntos,
eso es aprox. 3 GB. Puedo simplemente guardarme las opiniones finales por ahora.

El código con la clasificación funca perfecto en la pc. Igual, quedémonos sólo con lo
importante, que serían las opiniones finales y la semilla. Comitteo esto y ya mañana
mando a correr todo. ACORDATE DE USAR UNA SOLA CARPETA DE REDES DE ADYACENCIA.

------------------------------------------------------------------------------------------

04/05/2023

Hoy a la tarde mandé a correr las simulaciones en las tres pc's, pero esto va a tomar
una eternidad. Hablar con Pablo y contarle que voy a meterme un momento en el código a ver
si hay algo que pueda hacer para hacerlo correr más rápido.

------------------------------------------------------------------------------------------

05/05/2023

Mirando el código, encontré algo que claramente está gastando mucho tiempo. Estoy calculando
varias veces el mismo peso. Tengo que hacerlo de forma tal de calcularlo una sola vez. Eso
va a reducir en mucho el tiempo de simulación. Ese error está en la función de GENERAR_SEPARACIÓN.

Otra cosa que no tiene que ver con tiempos de simulación pero que estaría bueno cambiar
es el hecho de que la matriz que guarda las tanh se llama Exp. Habrá quedado de otro código,
cambiar eso.

Lo tercero que se me ocurre que puede servir para achicar los tiempos es reducir primero
el ancho de la ventana de promedio, de 1000 a 500, y después cambiar el número de iteraciones
extras que el sistema necesita para cortar a 1500. En especial porque muchas simulaciones que
cortan rápido hacen 7000 pasos totalmente al pedo, cuando con 4000 o 3000 habrían terminado.

Estoy pensando en quizás cambiar la cantidad de pasos_maximos, pero Hugo y demás usaban esa
misma cantidad de pasos máximos, me parece que cambiar sería una mala idea.

------------------------------------------------------------------------------------------

06/05/2023

Ahí hice el cambio sobre el cálculo de los pesos. Veamos en comparación con el cálculo que se hizo
el otro día. La otra vez tardó 11813 segundos. Voy a usar la misma semilla y correr el mismo
programa, a ver cuánto menos tarda ahora. No voy a cambiar el tema las iteraciones extras o el
ancho de la ventana todavía, así la comparación es directamente con eso.

Ahí está corriendo eso. Mientras, voy a hacer las otras dos correcciones. Ya cambié el uso del
vector Exp por el vector Tanh. Es un cambio  de nombre para ser más claro.
 También modifiqué la cantidad de iteraciones extras y el ancho de ventanas para que esto corte
más rápido en los casos en que el sistema deja de variar rápido.

Mientras termina de correr la simulación que mandé, voy a preparar la presentación del miércoles.

Memes y cosas para introducir en la charla:
-------------------------------------------
1) Descripción distópica y útopica del tema con imágenes de Megaman battle network.

Después continuo esto.

El cambio que hice en los cálculos de las exponenciales no parece tener ningún efecto.
Es raro eso, no tiene mucho sentido. A menos que haya algo que está mal anotado en el
código, revisar eso. Porque tendría que reducirse mucho la cantidad de cuentas.

------------------------------------------------------------------------------------------

07/05/2023

Hoy quería ponerme a estudiar alemán, no creo que lo haga. Primero voy a mandar a correr de nuevo
los barridos en las pc's, pero modificando el instanciar para que no tenga el cero de cos(delta)
duplicado y modificando el ancho de ventana e iteraciones extras, eso debería modificar
algunos tiempos de simulación. Después voy a probar un poco más el tema de la modificación
en el código sobre el cálculo de las exponenciales, el cuál parece no tener efecto.

IMPORTANTE: EN ALGARVE ALGUNAS SIMULACIONES NO COMPLETARON PARA BETA=0 Y COS(DELTA)=1. REVISAR
DE MANDARLO DESPUÉS. AHORA MANDÉ PARA QUE ARRANQUE DE NUEVO A PARTIR DE BETA=0.2.

Ya mandé a correr todo de nuevo, haciendo las modificaciones que hice en la pc de la
facultad. Veamos ahora el tema de si puedo hacer correr esto más rápido. Necesito que
así sea, porque estas cosas están tardando tiempos imposibles.

No encontré la forma de hacer que esto vaya más rápido. Por ahora lo voy a dejar, voy
a mandar a correr simulaciones con redes de 5000 agentes a ver si puedo usar eso para
realizar las comparaciones. Con 5000 agentes el sistema me tarda 15 minutos. Ya fue,
trabajemos con 5000 agentes por ahora. Es mucho más razonable.

Cargué los archivos en las tres pc's, cuando terminen las corridas previas mando a correr
las nuevas simulaciones. No debería tardar mucho. A 15 minutos por simulación, me puedo
dar el lujo de hacer un barrido un poco más fino. Recorriendo 11 puntos en cada eje, son
121 puntos en el espacio de parámetros. Con 15~20 minutos por simulación, en el peor caso
eso es 40 horas por iteración. Así que en 2 o 3 días debería tener resuelto esto, considerando
que para los Betas cerca de 1 los tiempos de simulación se van a disparar. Espero que salga
bien la cosa, tendré 30 simulaciones para mirar.

Voy a ponerme a preparar la presentación para mañana.

------------------------------------------------------------------------------------------

08/05/2023

Revisé los programas que están en las pc's y están tardando aprox. 40 minutos cada simulación.
Recién resolvió dos betas de los 11. Así que eso va a estar un buen rato, con algo de suerte
va a estar terminado para el viernes. La pregunta importante es:
¿Me pongo hoy a estudiar Alemán o mañana? Yo diría que mejor mañana, así mañana cualquier
cosa tengo algo para mostrarle a Pablo. Hoy pongámonos a armar el Excel que decíamos con
Pablo de preguntas de las ANES.

------------------------------------------------------------------------------------------

09/05/2023

Por el paro, hoy estoy trabajando en casa. Estoy mirando la ANES y clasificando preguntas.
En la encuesta ANES 2020 hay preguntas de estereotipos sobre que tan trabajador o violentos
son según grupo étnico. Esas preguntas van desde V202515 hasta V202526. Todas estas preguntas
tienen 7 posibles respuestas. A partir de la pregunta V202580 hay muchas preguntas que parecen
tener 7 respuestas, varias que no son políticas. Pero son demasiadas y poco interesantes
realmente. Quizás si hace falta las podría revisar, pero en principio no es importante.

Ya revisé toda la ANES 2020. ¿Debería seguir con este trabajo?

------------------------------------------------------------------------------------------

10/05/2023

El 9 trabajé desde casa, pero por lo que veo no lo comitee, quizás genere problemas.
Tengo problemas más serios. Resulta que lo que estoy mandando a correr está tardando una eternidad.
Es una eternidad más corta que el caso de 10000 agentes, pero aún así el de 5000 está tardando
una eternidad siendo que las simulaciones que polarizan tardan 36 horas aprox. en resolverse.
Tengo que ver de buscarle una vuelta a eso. Simplemente es inviable trabajar así.
¿Debería resolver eso ahora?

Lo que habíamos charlado con la gente de GOTHAM era catalogar preguntas, armar a partir de eso
un conjunto de preguntas interesantes y quizás ver a lo largo de varias ANES cómo evoluciona
la polarización de esas preguntas. Creo que puedo conseguir más resultados si sigo catalogando
preguntas. Pero en ese caso, ¿Qué buscaría mostrarle a la gente de GOTHAM el miércoles que
viene? Con suerte, podría mostrarles el subset de preguntas que pensamos mirar y algunos 
gráficos donde veamos cómo fue evolucionando esa polarización. Porque mostrarles cuáles son
los tipos de gráficos que planeamos comparar no tiene sentido.

Sabiendo que los datos de simulaciones no van a estar como para hacer un estudio razonable
de acá al miércoles, yo propondría primero ir comparando lo que tengo con datos obtenidos
de 1000 agentes, como los que armé para el espacio reducido en Beta-Cosd, y de ahí armar algo
que funque y que en principio sea un puntapié al análisis, total una vez que tenga los datos
es una cuestión de cambiar el N del código de 1000 a 5000 o 10000. Entonces primero seguiré
catalogando preguntas, y ya a la tarde o después de hablar con Pablo definiremos los siguientes
pasos en estos días de acá al miércoles. Después habrá que volver a ver qué podemos hacer para 
que el código corra más rápido, porque simplemente no se puede vivir así. La primer idea que
surge es hacer una Tabla con datos para la función exponencial e interpolar. Tengo que pensarla
de alguna forma correcta, cosa de que el argumento sea la distancia al cuadrado del vector
y no la distancia, así aprovecho y me ahorro la raíz cuadrada.

Estoy mirando el guidebook de 2012 y estoy notando dos cosas importantes. La primera, es que el
formato es mucho más feo que las versiones anteriores, va a tomar mucho revisar las preguntas.
La segunda es que este guidebook no parece tener separados los datos en códigos como los otros
dos. Eso me preocupa.

De acá para el lunes es importante mandar a correr mi código para 10000 agentes en una dimensión
y el código de Hugo para 10000 agentes en una dimensión. Corrido eso, vamos a tener una buena
idea de la diferencia de tiempos y si los tiempos del código de Hugo es razonable o viable.

------------------------------------------------------------------------------------------

11/05/2023

Mandé a correr el código mío y tardó 7600 segundos. El código de Hugo en cambio tardó 47 segundos.
Hay una diferencia de dos órdenes de magnitud en el tiempo que tarda mi código y el de ellos.
No comprendo por qué. Eze me dice que quizás sea un tema de la cantidad de fors que estoy usando.
No creo que sea eso, pero se puede probar.

Mañana habrá que hacer gráficos con las preguntas que tengo de la ANES, armar una clasificación
clara y después preparar algo para presentar con eso.

------------------------------------------------------------------------------------------

13/05/2023

Soy un reverendo pelotudo, cinco veces pensé en commitear el trabajo de casa y no lo hice.
Ahora voy a tener un bardo entre los archivos y cosas. En la facultad hoy voy a
ponerme a trabajar en los archivos de Python para armar la clasificación de las preguntas
y los gráficos asociados.

El sueño que tengo me está complicando laburar fuerte. Ya no es joda hermano. No sé si
es la ropa que tengo puesta o el cansancio general, simplemente estoy deteriorándome. Y
el invierno no me gusta.

Anoté las preguntas que voy a mirar, armé los gráficos y los estuve repasando un poco,
pero no me parece muy interesante lo que estoy viendo. Pablo me propuso mirar directamente
las distribuciones 1D y con eso ir descartando cuáles son las preguntas que quiero mirar y
cuáles no.

¿Qué criterios usé para remover preguntas? Saqué las que tuvieran una gran cantidad de agentes
en una opinión neutra o que tuvieran distribuciones muy homogéneas.

Hice un primer filtro de cuáles voy a querer y cuáles no. En el drive voy a marcarlas como
descartadas, mientras que en Python las voy a borrar directamente.

Las preguntas que clasifiqué y separé me parece que son un buen filtro, me dejan los gráficos
que inicialmente quería mirar. Anotemos las preguntas descartadas en el drive. Después de eso,
empiezo a ver cómo medir la distancia de jensen-shannon.

Hice las anotaciones que quería en el drive, tengo clasificadas las preguntas que voy a querer
revisar. Mañana veré de armar el conjunto de preguntas y mostrárselo a Pablo, así como mostrarle
de estas preguntas cuáles podrían tener una cierta trazabilidad hacia atrás.

Lo que voy a hacer ahora es descargar los datos del barrido de Zoom Beta-Cosd y a partir de esos
ver cómo comparar esos datos con los datos de las distribuciones. Voy a elegir dos o tres
gráficos para comparar y a partir de esos voy a intentar armar algunas comparaciones.

Descargué los archivos a la carpeta de Comparacion_datos. Lo que necesito es un archivo de Python
que arme la Clasificación de las opiniones finales y compare eso con los datos de la encuesta.
Tengo algo que hace eso creo, que lo preparé para la semana pasada. Así que simplemente tengo
que lograr hacer un for. Y después voy a tener errores porque obviamente tengo huecos en mis
distribuciones T.T.

------------------------------------------------------------------------------------------

14/05/2023

Ayer llegué a casa y tampoco comitee mis datos. Soy un re boludo. Voy a copiar los datos de la
ANES en la carpeta de Comparación_datos y ahí voy a trabajar la parte de las comparaciones de
las distribuciones usando distancias Jensen-Shannon.

Ya tengo los datos del barrido reducido y tengo los datos de la ANES para comparar. Lo siguiente
sería empezar a comparar los datos. Voy a probar contra una distribución que tiene una buena
forma de polarización ideológica, el gráfico que sale de "Govt. Asssitance to Blacks" vs
"Guaranteed Job Income", que son los códigos "V201258" vs "V201255".

Por lo que leí en Wikipedia, debería revisar un poco más el tema, la idea es que al calcular
la distancia Jensen-Shannon, la distribución p, que es la primera que le paso a la función,
es la distribución medida. Es decir que primero le paso la distribución obtenida de la encuesta.
La segunda distribución, la distribución q, debería ser mi aproximación o mi resultado simulado.

Estoy armando el código para calcular la distancia entre dos distribuciones. Tengo una primera gran
duda: ¿Las distribuciones que estoy comparando, elemento a elemento, corresponden entre ellas?
La respuesta es que sí, se corresponden. Eso es genial, no puedo creer que haya funcionado.

Lo siguiente ahora es armar una función que calcule esta distancia y arme gráficos en el espacio
de parámetros. Ahí lo mandé a correr, funcionó. Y da razonable. Charlar eso con Pablo mañana.

------------------------------------------------------------------------------------------

15/05/2023

Pablo mandó un mensaje para posponer la reunión hasta la semana que viene. Así que para
la semana que viene tengo que tener algo más sólido armado. Para eso tengo que trabajar
en las siguientes cosas:

1) Acondicionar el código de Hugo para que trabaje con dos tópicos.
2) Continuar estudiando la distancia Jensen-Shannon en el espacio de parámetros para otras
configuraciones de preguntas. (Esto va a implicar adaptar la función de Clasificación para
los casos con tamaños que no sean 7x7). También debería estudiar un poco más la función
que calcula la distancia Jensen-Shannon.
3) Revisar los resultados analíticos y armar un plan de qué falta hacer. Quizás hacer
análisis de las ecuaciones en papel mezclado con simulaciones.
4) Revisar si quedaron ideas que valga la pena estudiar del tema de las simulaciones.
5) Probar cómo hacer que mi código funcione tan rápido como el de Hugo.

Vuelvo a mirar mi código, no veo nada raro. No comprendo. Pero bueno, empecemos a modificar
el código de Hugo para que funcione como yo quiero. Mientras, pongamos a prueba los tiempos
una vez más. Mandé a correr los dos códigos, sólo para comparar los tiempos.

Mandé mi presentación al curso de Verano ese en Uruguay que Pablo había compartido. Por otro
lado, no terminé de adaptar el código de Hugo. Mañana termino eso. Quedé a mitad de
adaptar la parte donde evoluciona y calcula la variación promedio. Lo que me queda revisar
también es agregar el cálculo de la norma no ortogonal. Creo que hechas esas dos cosas,
debería estar resuelto esto.

De paso, mandé a correr los códigos para comparar los tiempos, sigue ocurriendo que el
código de Hugo es 100 veces más rápido que el mío.
