------------------------------------------------------------------------------------------

22/03/2024

Al final terminé de revisar los archivos del barrido Beta-Kappa, sólo había problemas en la iteración
90 a 99. Así que tendré que en Oporto mandar a correr dos conjuntos de datos separados. Uno que recorra
todo el espacio para iteraciones entre 90 y 99 y otro que recorra el espacio para Beta mayor a 1
para iteraciones entre 50 y 69.

Voy a aprovechar la mañana para preparar el main cosa de que cuando se termine la corrida de Oporto,
que va a terminar en uno o dos días, ya lo pueda mandar a correr rápido. Después de comer me pondré
con el análisis de la ecuación dinámica del modelo. Bien, ya modifiqué el Instanciar. Lo que tengo
que hacer es mandar las simulaciones de 50 a 69 en Oporto mañana a la tarde.

------------------------------------------------------------------------------------------

26/03/2024

En la mañana fui a llevar el documento de matrimonio de mamá al estudio, pero al final el documento
no estaba actualizado. Tendré que conseguir la actualización del registro civil y de ahí
volver a intentar.

Las simulaciones en Algarve terminaron, así que podría mandar a resolver las simulaciones entre
80 a 99.

Hoy la verdad me agaró un sueño imposible, no avancé mucho. Pero estuve mirando lo que me pasó Hugo
y lo que tengo yo de la cuenta, logré armar la misma expresión para la derivada de la perturbación.
Queda entonces ver dónde queda efectivamente el valor de Beta de transición. Lo interesante es que
aparece un factor 2 que antes no estaba. Vamos a ver cómopuedo hallar entonces el valor de Beta de
equilibrio.

------------------------------------------------------------------------------------------

27/03/2024

Lo primero que hice en la mañana fue revisar mails, después mandé a correr las simulaciones entre
90 y 99 en el barrido beta-kappa en Oporto. Con eso voy a tener todas las simulaciones en ese espacio
y voy a poder armar los gráficos con la estadística de 100 simulaciones. Eso debería durar de acá a
la semana que viene. Quizás.

Mientras estoy haciendo el análisis de la ecuación dinámica para definir el Beta tal que el estado de
polarización ideológica transiciona de ser inestable a estable.

------------------------------------------------------------------------------------------

04/04/2024

En la mañana revisé las carpetas de Oporto y demás para ver que todo estuviera corriendo bien, mandé
a armar gráficos en Oporto ahora que tengo las 100 simulaciones por punto y estuve intentando pensar
cómo armar el gráfico que Pablo me pide que haga sobre el espacio Beta-Kappa.

Mientras tanto, se siguen resolviendo las simulaciones que faltan del espacio reducido Beta-Cos(delta).
Esas simulaciones van a terminar cerca de tres o cuatro días.

Lo que tengo que hacer ahora primero es ver cómo armar un gráfico que muestre clarametne la composición
de estados en el espacio Beta-Kappa. A partir de eso, podría pensar un mapa para el espacio de
Beta-Cos(delta).

Hoy apenas miré las cosas, no hice mucho más. La verdad, siento que perdí buena parte del tiempo. Dios,
como odio estos días. Y eso que vine temprano y todo.

------------------------------------------------------------------------------------------

05/04/2024

Hoy estuve todo el día armando los gráficos de distribución de estados en el espacio de parámetros.
Logré hacer los gráficos tanto para el espacio Beta-Kappa como para el espacio Beta-Cosd.
Siento que no son la gran cosa, pero Pablo me dijo que haga algo así, o mejor. Yo saqué esto.
Tengo que ser mejor que esto, espero estar mejorando con el tiempo, no estar estancándome.

Bueno, no nos matemos, mañana partida, el domingo tarea de Alemán y del curso de aplicaciones
a becas. Lunes retomamos con ganas y fuerzas.

------------------------------------------------------------------------------------------

08/04/2024

Hoy llegué más o menos temprano, los trenes están tardando mucho ahora, temas de despidos.
VLLC. A la mañana voy al curso de inglés. Revisé las simulaciones en el espacio reducido.
Ya casi están todas terminadas, queda una sola en la carpeta de algarve. Así que después de
comer, junto todas las simulaciones de Algarve en Coimbra y desde ahí armo los gráficos del
parámetro de espacios.

Veamos qué simulaciones tengo en cada pc. En Coimbra tengo dos carpetas.
) Datos: 0-9.
) Zoom_beta-Cosd: 30-39, 50-79.

Algarve.
) Zoom_beta-Cosd: 10-29, 80-99

Oporto.
) Zoom_Beta-Cosd: 40-49

Ahora lo junto todo. Ahí mandé a correr para que se armen todos los gráficos del espacio reducido.
La pregunta es qué hago ahora. Para mi tiene interés revisar qué es lo que pasa con el sistema
para el punto fijo de cuatro extremos, ese análisis de la ecuación dinámica, que creo que
razonablemente dará que Beta crítico es 1, yo creo que será una investigación interesante.

Otra cosa que puedo hacer esperando a la reunión con Pablo, es armar la presentación para el
miércoles. Aunque eso lo puedo hacer mañana. Lo tercero sería ponerme a leer algún paper en
el tiempo hasta juntarme hoy con Pablo.

Hablé con Pablo, la idea es armar los gráficos indicando las regiones no con colores, sino delineando
los contornos, usando números romanos para indicar las regiones, luego colocar cerca gráficos que
indiquen estados finales característicos y explicar cómo es que terminé definiendo esas regiones.
En particular, si habría alguna forma de identificar mejor la curva que surge en el espacio Beta-Kappa,
la cuál yo definí puramente a ojo.

Ahí armé los gráficos que me dijo Pablo, me falta colocarle los números romanos al segundo. Mientras
se están terminando los gráficos en la región reducida. Tengo mala espina.

------------------------------------------------------------------------------------------

09/04/2024

Revisé Coimbra, se hicieron los gráficos del espacio reducido. Se ve algo interesante respecto
de los estados con anchura, y se ve que coinciden los resultados con lo observado en el espacio
total Beta-Cos(delta).

Sigamos con el trabajo de Pablo hasta eso de las 11 y algo. Después a las 12 voy a comer, a las
13 voy al abrazo en el 0+inf y después a cursar.

Terminé de cursar, trabajé un poco en la presentación y después me fui a casa temprano para que
no me agarre la lluvia.

------------------------------------------------------------------------------------------

10/04/2024

A la mañana llegué y mandé a armar gráficos de Histogramas 2D. Después tuvimos la reunión de grupo.
Comí en la oficina y rápido terminé de armar lo que pude de la presentación para la
gente de GOTHAM. Pablo hoy no pudo venir, lo mismo Jesús. La charla la tuve yo con Hugo
y Mario.

De la charla saqué los siguientes puntos:
1) En el espacio de parámetros Beta-kappa, la curva que diferencia estados de Consenso Radicalizado
respecto de los estados Polarizados, en principio Hugo la estudió bastante desde varias perspectivas.
Su conclusión es que es un resultado de la saturación de la función de tanh. Una propuesta que
me hizo es intentar ver si reemplazando la función tanh por una función signo, entonces
debería ver si esa curva desaparece y sólo veo una línea constante en Beta aprox. 0.2.
2) Hugo me dice que esos estados de polarización descorrelacionada que estoy observando
si los dejara correr más tiempo, posiblemente vería que convergen a otro tipo de estados,
quizás Pol 1D con anchura o Pol 1D nomás, yo no creo que sea el caso. Vamos viendo.
3) Algo interesante sería intentar ver si el modelo 2D para el caso de Cos(delta) = 0 se puede interpretar
como dos modelos unidimensionales independientes. Una forma de comprobar eso sería tomar un
punto del espacio de parámetros en el cuál surjan estados de polarización descorrelacionada
y comparar esos estados con estados polarizados en el caso unidimensional. Si el caso 2D con
Cos(delta)=0 se pudiera interpretar como dos simulaciones independientes, una para cada tópico,
entonces lo que debería poder observar es que la polarización simultánea de ambos tópicos debería
ocurrir con una probabilidad que es la probabilidad al cuadrado de que cada tópico polarice. Y
eso se debería obtener a partir de realizar simulaciones 1D. Para ellos esto es una pregunta
interesante respecto de cómo el modelo 2D no es sólo el modelo 1D 2 veces, sino que trae algo
propio a la formación de opiniones por la distancia entre opiniones. (Creo)
4) Cuando vaya a hacer los cálculos analíticos, probar hacer unas simulaciones primero, para
ver que efectivamente lo que quiero ver se da como yo planteo y no perder un montón de tiempo
en cuentas que no llevan a nada.
5) Al hacer las simulaciones con las que vamos a trabajar, no guardar todos los datos, sino guardar
sólamente el histograma de datos. Y considerar que ese histograma de datos tiene que tener
una cantidad de cajas que coincidan con la cantidad de cajas de las preguntas que voy a mirar,
porque algunas preguntas tienen 6 cajas y otras 7.

------------------------------------------------------------------------------------------

11/04/2024

A la mañana hablé con Pablo sobre lo que fue la charla con la gente de GOTHAM. El plan ahora
es armar una lista de cosas para hacer en estas tres semanas hasta la próxima reunión. Ahora
mismo no estoy realizando simulaciones. Debería considerar arrancar con eso, para que ya
esté funcionando antes de hacer el resto de cosas.

En la mañana estuve organizando cosas, mandando mensajes, imprimiendo comprobantes y así.
Mañana voy a ir a buscar las fotos de mi recibida. Para eso, tengo que llamar antes. Entonces,
a eso de las 14 llamo y después a las 17 salgo para allá, total es tomarme el tren hasta Retiro,
pedalear 10 minutos desde ahí y después volverme.

Hagamos la lista de orden de cosas por hacer esta semana y la que viene:
(Una idea que propusimos es ya fijar Kappa=10 y dejar de preocuparnos)
-----------------------------------------------------------------------

Es importante arrancar con esto porque requiere simulaciones, así que eso puede ir corriendo
mientras hago otras cosas.
########################################################################################################
1) Podría arrancar con las simulaciones del sistema usando la función signo en vez de la función
tanh. Eso me parece importante para arrancar porque va a requerir varias simulaciones. Digamos
que lo armo con 30 iteraciones, eso debería alcanzar para ver algo. Y el espacio que voy
a barrer debería ser de Kappa [1,10], con Beta de [0,1]. Después puedo ver de agregar
más Kappa, pero lo importante es hacer un barrido bien rápido de la cosa, variar grueso,
con Kappa variando de a 1 y Beta variando de a 0.1. Esto ya lo podría mandar hoy.
2) Empezar a descargar los datos de la ANES, ir construyendo un conjunto de datos con 10000
agentes cosa de tener para ir comparando nuestras simulaciones con los datos extraídos de las
encuestas. La idea sería armar datos en la región reducida de Beta-Cos(delta). Además, tengo
que asegurarme de guardar los datos, no guardando las opiniones de TODOS los agentes finales,
sino guardar el histograma final de los agentes. Hugo me dió un consejo de cómo guardar los
datos de forma de poder comparar mis resultados en el caso de que la opinión tenga 6 respuestas
o de que tenga 7.
3) Hugo me dijo de hacer simulaciones en un punto del espacio de Parámetros donde observe
varios casos de simulación y que por un lado corra simulaciones en el modelo 1D y por el otro
corra simulaciones en el modelo 2D. La idea es ver si la probabilidad de observar estados polarizados
2D es igual al cuadrado de la posibilidad de que polarice un estado 1D. Esto tendría alguna comparación
en el caso en que Cos(Delta)=0, siendo que en ese caso la ecuación del tópico 1 queda casi
completamente desacoplada de la ecuación del tópico 2. Hay todavía un pequeño acople en lo que
a los pesos refiere, así que no debería ser lo mismo. Digo yo. Esto puedo mandarlo por un lado
en Algarve y por el otro en Coimbra, con 10000 agentes. Creo que habíamos discutido que era
una buena idea usar esa cantidad de agentes.
########################################################################################################

4) Antes de continuar las cuentas analíticas sobre el valor de Beta que cambia la estabilidad de las soluciones,
conviene intentar primero hacer simulaciones con redes completas y con la pequeña perturbación
propuestas, para ver si el resultado corrobora lo esperado. Así nos damos una idea del resultado
final. Después de esto puedo retomar mis cuentas. Eso significa, PRIMERO, revisar que me quedó
una cuenta pendiente del caso en el que considero la solución ideológica. LUEGO, continuo la cuenta
del caso de polarización descorrelacionada.

Cosas más opcionales:
---------------------
5) Hugo me había dicho la otra semana que revise si pasaba que partiendo de un estado que yo
sé que finaliza en un estado de polarización radicalizada, al ir aumentando el cos(delta) el
estado se transforma en un estado de polarización ideológica. La idea está buena y no requiere
mucho esfuerzo. Creo.
6) Me dijeron de revisar si encuentro encuestas en Argentina que nos permitan observar
polarización, porque en las encuestas que buscaron en España, la mayoría no tiene casos de polarización.
7) Podría ver de continuar con el clasificador neuronal, aunque en principio no es ni de
cerca necesario ahora.

Después de haberme distraído un poco, resolví el punto 1. Cambié la función en el archivo de avanzar,
armé una nueva etapa llamada Func_sign y mandé en Oporto a correr este barrido en la región que 
determiné antes.

------------------------------------------------------------------------------------------

12/04/2024

A la mañana fui a realizar el trámite del Banco Provincia. Llegué a la facultad a las 13.

Ahora estoy revisando la lista de cosas por hacer. Entre lo que tengo que hacer, me parece que
es mejor empezar por el punto 3 y no por el 2. Más que nada porque el punto 2 va a tardar tanto
que empezarlo ahora o el lunes da lo mismo, el otro punto en cambio me parece que me va
a dar resultados más rápido.

Estuve muy distraído hoy, pero armé el programa que simula en 1D. Más tardé con el armar una función
que en C me construya mi histograma. No era tan difícil, sólo soy un boludo que está desatento.
Ahora tengo que subir esto a Algarve o Coimbra y mandarlo a correr. Fijate que esto no contempla
estar en una carpeta de src. Pero creo que no es problema, simplemente tengo que compilarlo y
mandarlo. Voy a tener que modificar el archivo de Instanciar quizás, pero nada grave. O el
de Metainstanciacion. Espero que cuando arme la función para el caso 2D esto sea más fácil.
Vamos para casa. No es temprano en realidad.

------------------------------------------------------------------------------------------

15/04/2024

Al final el finde no hice la tarea que planeaba hacer, pero no fue tan terrible, la semana
arrancó igual y estamos todos bien. A veces no tiene tanto sentido hacerse la cabeza con
eso.

Hoy lo que tengo que tener terminado es el armado de las opiniones en cajas al final de la simulación,
cosa de ya mandar eso y entonces de los siete puntos que marqué para hacer, tener ya dos
resueltos.
 Repasé la función para el caso 1D, ahí logré hacer que funcione. El caso 1D está planteado
para redes con N=1000, Beta=0.7, Kappa=10 y Cosd=0. Cada simulación tarda 215 segundos.
Así que si corro 30 simulaciones en ese punto, no debería costarme más de 20 minutos,
siendo que esas simulaciones las voy a repartir en 10 hilos. Después tengo que subir
el archivo de opinion.e a Algarve y desde ahí modificar el Instanciar para mandar a correr
la simulaciones 1D.

Ahora me pongo con las simulaciones 2D. Logré que compile. Mañana lo mando a correr en las
pc's de la facultad. O quizá hoy en casa si llego temprano y no estoy para jugar ranked.
Perdí un poco de tiempo en esto, pero al final del el armar estas funciones que me construyan
los histogramas en el código en C es importante para el siguiente punto a trabajar.
Es cierto que faltan dos cosas importantes:
1) Probar que la función esa esté laburando bien. MUCHO MUY IMPORTANTE.
2) Organizar correctamente el cómo interpreto los números que la cosa esta
me tira. Así identifico correctamente qué va dónde. Armar las cajitas de 6*6 o las de 7*7
va a ser un bardo. Bah no, mentira, va a ser una boludez.

------------------------------------------------------------------------------------------

16/04/2024

No puedo mandar a correr las simulaciones en la pc de Algarve, ya fue, lo corro en la pc
de la facultad. Mientras eso corre, mandé las simulaciones en Coimbra, eso no fue tan simple.
Había un error medio boludo en la función de clasificación. Ahora me voy a poner a estudiar
alemán. Tengo que después hacer caso a mis notas sobre revisar que todo funcione bien,
no puedo moverme a ciegas como estoy haciendo ahora. Si bien la función está copiada
de algo que funciona, tengo dudas.

Fui a cursar Alemán.

Mandé en la pc de Coimbra para realizar 1000 simulaciones. Eso debería tardar unos días.
Mientras, voy a necesitar simulaciones en la pc de la facultad que lleguen hasta 1000 también
de 1D.

Repito para que no se olvide, es mucho muy importante que pruebe que las funciones de Clasificación
están funcionando bien. Para eso voy a tomar algunas simulaciones, usar sus semillas y simular en
la pc de la facultad. A esas simulaciones les voy a guardar las opiniones finales, y las distribuciones.
Voy a comparar que las distribuciones me den lo mismo que las opiniones finales.

------------------------------------------------------------------------------------------

17/04/2024

Mandé en la pc de la facultad cuatro procesos para resolver 250 simulaciones en cada terminal.
En la pc de Coimbra ya está casi terminada la tanda de simulaciones para el punto del espacio
Kappa=10, Beta=0.7 y Cosd=0. En la carpeta de Oporto está terminado el barrido en el espacio
Beta-Kappa para la función signo. Así que ya podría trabajar en ver que efectivamente se arma
el gráfico que esperamos.

Yo creo que hoy tendría que hacer dos cosas. La primera es ver de descargar datos de la ANES,
así ya puedo mandar a correr datos. Lo segundo es ver que efectivamente la función Clasificación
funciona bien. Para eso voy a descargar algunas simulaciones, rearmar esas simulaciones en esta
pc usando las semillas, guardar las opiniones finales y comprobar que los gráficos que puedo
recrear usando las distribuciones que surgen de la función Clasificación son iguales a las
distribuciones que surgen de las opiniones finales.

Tengo unas dudas sobre qué hacer con el tema de los datos de la ANES. Vengo revisando mis archivos,
no encuentro algo de lo que me decía Hugo de tener cuidado al revisar los datos de la ANES.
Lo que voy a hacer, luego de debatirme y pensar qué corno quiero, es hacer gráficos de distribución
de opiniones confrontando todas las preguntas entre ellas. 

Estoy revisando las etiquetas. Labels_pre tiene 20 etiquetas mientras que labels_post tiene 9 etiquetas.
Juntos suman 29 etiquetas. Pero dict_labels tiene apenas 23 etiquetas. Es decir que de las 29 etiquetas
que mira, sólo 23 están identificadas. Debería esforzarme por identificar las otras 6.
Ahí vi, las seis que están removidas en labels_pre y labels_post son 6 preguntas en labels_pre
que tienen 4 respuestas, en vez de seis o siete. En labels_post sacaron la pregunta sobre si Obama es
musulman, pero no la de ubicación propia a lo largo del eje conservador/liberal. Supongo que para arrancar,
por hoy, puedo dejarla.

Observando los gráficos, encontré claros casos de: Consenso Radicalizado, Polarización Ideológica, Polarización
1D con anchura, Polarización descorrelacionada, y quedaría definir qué cuenta como casos con anchura
o algunas cosas más. Creo que lo que estaría bueno es poder definir qué pares de preguntas vamos a
revisar y con qué vamos a comparar esos casos. También vale notar que algunos casos resulta que tienen
algunas casillas vacías. Quizás para no hacer un barrido demasiado grande y poder observar estos
resultados, estaría bueno moverse con Beta entre [0.6,1.2] y Cos(delta) entre [0.05,0.15]. Y para
eso hacer un barrido BIEN grueso, total no busco con eso caracterizar alguna curva, sólo quiero tener
gráficos para comparar con lo observado en la ANES.

Voy a descargar entonces cinco archivos de Probas_Pol en 2D así ya mañana arranco con los gráficos
para revisar que la Clasificacion está funcionando bien. Descargué cinco simulaciones al azar, las
cinco pareciera que convergen a estados de Consenso Radicalizado. Voy a tener que armar las simulaciones
mañana usando esas semillas y ya después veo qué pasó.

------------------------------------------------------------------------------------------

18/04/2024

A la mañana fui a llevar el acta de matrimonio al estudio de traducción, y volví al mediodía. Después
me puse a ver los datos del barrido en el espacio Beta-Kappa. El gráfico pareciera dar lo que yo busco,
pero no se ve muy claro. Debería probar extender un poco la región y hacer un poco más fino el barrido.
Mañana lo hablo con Pablo cualquier cosa.

Ahora me voy a poner a estudiar Alemán. Después me pondré con lo de escribir la carta de motivación y el 
CV. Por último, con algo de tiempo, quizás lea un paper. Mañana repasaré el tema de las simulaciones
en el espacio Beta-Kappa, y de las simulaciones en un punto del espacio de parámetros.c

------------------------------------------------------------------------------------------

19/04/2024

Lo primero que voy a hacer es comparar el gráfico de Func_sign en el espacio Beta-Kappa
con el gráfico que tengo de esa misma región hecho en la etapa de opinión actualizada.
Para eso voy a tomar la función que arma el gráfico del espacio de parámetros de Entropía
y reducir la región de los ejes X e Y.

Mientras se resuelve eso, voy a probar lo de revisar que las funciones de Clasificacion
estén laburando bien. Aunque me descargué sólo gráficos con estados finales de Consenso.
Busquemos primero dos o tres gráficos en estados de polarización. No encontré estados de
polarización, pero encontré estados que tardaron mucho en resolver. ¿Estará funcionando
mal la función de Clasificación?

Voy a identificar los estados según su número de iteración.
.) Iter=100: Los agentes convergen a un estado de Consenso radicalizado, en el punto [10,-10].
Pero la función de clasificación dice que están todos en el lugar final. Lo cuál no tiene
sentido, porque si el valor de Y es -10, en la asignación el valor de "fila" debería ser 0
y por tanto la casilla marcada debería ser una de las primeras 42, no la última.
.) Iter=110: Convergen al punto [10,-10]. Van al mismo lugar que los anteriores
.) Iter=120: Convergen al punto [10,10]. Este sí le corresponde marcar en la última casilla
del vector de Distribución. Pero claramente parece que la función está funcionando mal.
.) Iter=130: Convergen al punto [10,10].

Es al pedo seguir con esto, efectivamente la función de Clasificación está mal, pero lo está
por un error muy boludo, y es que el ancho que usaba para ver si un número iba a una fila u otra
era 0, entonces al dividir por cero daba infinito y todos los agentes iban a parar al mismo
lugar. Así que eso está mal y tengo que rehacer todas las simulaciones corrigiendo simplemente
ese detalle.
 De paso, increíblemente, para el caso 1D sí hice bien el cálculo del ancho. Genial, eso significa
que eso está bien hecho y no necesito rehacerlo. Lo cuál es genial, porque estas simulaciones
eran más complejas de hacer porque no podía hacerlas en las pc's del cluster.

Voy a cerrar el día de hoy con tres cosas.
1) Mando a correr en Coimbra las simulaciones de un punto del espacio de nuevo. Esta vez corrijo
la función de Clasificacion para que funcione correctamente.
2) Mando en Oporto unas simulaciones extras de la región Beta-Kappa para intentar delinear mejor
lo que observo. La idea es expandir la región, no la cantidad de simulaciones.
3) Armo una carpetita con algunas simulaciones separadas del tema de datos de la ANES, así me queda
más sencillo para mostrarle a Pablo después lo de algunas distribuciones razonables.

Para el punto 2 hago un barrido extra, agregando valores de Kappa en los puntos intermedio.
1.5, 2.5 y así.

------------------------------------------------------------------------------------------

22/04/2024

A la mañana fui a la última clase del curso de "Becas:Help!". Tomé algunas notas sobre cómo
mejorar el CV y discutimos con los demás consejos para buen CV.

Lo que voy a hacer ahora es armar el gráfico del mapa de entropía para la función signo,
y después ver cuál es la proba de que un estado esté polarizado para el caso 1D y para el
caso 2D.
 Miré los archivos armados. Por motivos que no comprendo, faltan archivos, otros están armados
a la mitad. Hubo un corte, es imposible que no haya habido un corte.

Tengo descargados los archivos de agentes en un punto del espacio de parámetros, en los cuales
me guardé la distribución de opiniones finales, no las opiniones finales. Lo que tengo que hacer
ahora es con Python, levantar los datos, reordenarlo en el formato de una matriz y desde ahí
construir los gráficos de histogramas. Además de eso, lo otro que tengo que hacer es calcular
la proba de que un estado sea polarizado en el caso 1D y de que polarice en ambos tópicos
en el caso 2D.

1) Armo histogramas a partir de la distribución de opiniones.
2) Clasifico esos estados según los criterios definidos previamente.
3) Calculo la proba de tener estados polarizados en 1D y la proba de tener estados con
polarización descorrelacionada en 2D. (¿Debería comparar con polarización descorrelacionada?
¿Cómo es la proba si considero polarización 1D?)

De estas tres cosas que quería hacer, no hice ninguna. Siento que hoy podría haber hecho
más, pero estuve trabado toda la tarde. También hice muchas pequeñas cosas. Voy
a ponerme a pensar mejor cómo trabajar esto y ya el miércoles veré de resolverlo más claro.
Mañana voy a estudiar para el final de Mininni y después marcha.

Hablando con Pablo, él me dijo de que descargue yo los datos de la ANES para revisarlos,
así voy trabajando eso por mi cuenta. Debería separar preguntas políticas y no políticas,
así como separarlas según sus distribuciones. Después con eso ver qué tipo de gráficos
me quedan así tengo una buena idea de qué cosas espero observar. Mirar el paper de Baumann
y el de Hugo vendría bien para repasar qué es lo que estoy queriendo buscar.

Hoy y mañana me voy a poner a pensar cómo construir mis nuevas funciones en Python, cosa
de ya cuando em vuelva a sentar, ponerme a escribirlo de una y no volver a trabarme con
el cómo armar las funciones en el caso de Probas_Pol.

Por último, Pablo me propuso que arme más estadística a las simulaciones de Func_Sign,
no que barra más fino. Debería cancelar lo que mandé a correr y mandar de nuevo
con más estadística. Más que nada porque sino voy a tener un problema al querer armar
el gráfico porque algunos puntos van a tener más estadística y otros menos.
Lo que voy a hacer es mañana borrar las simulaciones con valores de Kappa fraccionarios.

------------------------------------------------------------------------------------------

23/04/2024

Ya borré esos archivos con valores de Kappa fraccionarios, mientras en Oporto se completan
simulaciones para llegar a tener 100 en ese barrido.

Ayer me quedé pensando en lo que dijo Sebas. Quizás es mejor seguir guardando las opiniones
finales de los agentes. Y además, me hice un quilombo queriendo usar la función de Hugo para
las simulaciones 1D. ¿Por qué no usar mis simulaciones? Si dan similares los resultados,
no tiene sentido diferenciar unas de otras. Podría usar mis simulaciones y con eso armarme
en Coimbra las 1000 simulaciones para el caso 1D y para el caso 2D. Mandemos hoy las 2D 
guardando las opiniones finales y después veo qué hago mañana.

Hablando con Pablo, los dos pilares para la próxima charla es trabajar con los datos y poner
en orden el análisis teórico. Así que por lo visto, no es central esto que estoy haciendo.
Pero como ya empecé, tengo que aprovechar y presentarlo.

------------------------------------------------------------------------------------------

24/04/2024

A la mañana lo primero que hice fue mandar a correr la tanda de simulaciones 1D de Probas_Pol
en la pc de Coimbra. Lo siguiente que voy a hacer es repasar las ecuaciones dinámicas cosa de tener
algo que presentarle a Pablo mañana y organizar los datos para la presentación.

Estuve avanzando con esto, aunque en eso vamos. Mañana me voy a poner en la mañana a estudiar
un poco de lo de Mininni y después seguiré con esto un poco más.

------------------------------------------------------------------------------------------

26/04/2024

En el día de ayer estuve trabajando en el análisis de la ecuación dinámica básicamente todo
el día. Fui a una reunión de grupo y llegué tarde por el tema de estar esperando el link para
la charla por el Repositorio de Investigación.

Hoy llegué, revisé el tema del análisis dinámico, charlé con Sebas y me propuso considerar un
análisis matricial similar a lo que veíamos en Mate 3. Igual creo que lo mejor sería probar
hacer lo que dijo Hugo, de hacer simulaciones sobre el análisis perturbativo y ver qué da eso.

Las simulaciones en Coimbra están terminadas. Las de Oporto todavía no. Debería por un lado
armar lo de Coimbra, cosa de tener por lo menos ese resultado. Pero creo que puedo dejar
eso para el próximo lunes sin dramas. Yo hoy me pondría a ver el tema de descargar datos de la
ANES. Voy a revisar la ANES, ver qué se puede descargar, qué preguntas hay y hacer esa separación
que me dijo Pablo de preguntas políticas y preguntas apolíticas, cosa de tener un conjunto
saludable de preguntas a revisar.

Ahí estuve viendo un poco de alemán, ahora sigamos con lo del modelo de opiniones. Descargué
los datos de la ANES, habrá que ver de armar el conjunto de preguntas que querramos observar.
Eso tomará un tiempo. 

------------------------------------------------------------------------------------------

29/04/2024

Llegué al horario usual. Me puse a revisar mails y cosas que quedaron pendientes. Ahora que
resolví eso, me pongo con las cosas que dejé corriendo.

1) Ver lo de la entropía en el espacio Beta-Kappa para la función Signo.
2) Determinar la fracción de estados polarizados en el caso 1D y en el caso 2D.
Usaré el algoritmo que tengo para eso y compararé con tomar 200 gráficos de histogramas
3) Leer un paper
4) Seguir laburando los datos de la ANES.

El punto 1 ahora no voy a poder, no terminó de correr eso.
Para el punto 2 necesito armar funciones que trabajen con un sistema 2D y un sistema 1D.

Logré armar uno de los gráficos de torta que quería, pero claramente esto no es lo más
interesante para charlar en la próxima reunión. Lo que deberíamos charlar en la próxima
reunión es el trabajo con los datos, de los cuales apenas armé unos gráficos nuevos
y después descargué los datos de la ANES de 2020. Así que la cosa viene lento en
ese tramo. Habrá que hacer nuevas cosas si quiero avanzar. Ahora voy a leer rápido
el paper de Sebas respecto a lo de Granovetter, al final no recuerdo si ese fue el
paper que leí o no. O si leí un paper en algún momento. Dicho eso, lo que sigue es
ponerme a revisar las preguntas y cosas del modelo. Así que hagamos esto y preparemos
para ir a casa temprano hoy. Iré a buscar el documento que necesitaba la semana que viene.

La idea sería primero que nada tomar las preguntas que tenemos y separarlas en función de
si son políticas o no. ¿Qué definimos como preguntas políticas? La respuesta es que las
preguntas políticas son aquellas que los demócratas o republicanos responderían distinto,
mientras que las apolíticas son aquellas que no apelan a esa identidad partidaria.

Anotemos esto en el código. Ahí hice la separación, básicamente todas las preguntas
son políticas. Razonable. Veré mañana si puedo encontrar unas ocho o diez no
políticas y de ahí veré cómo resuelvo esto. Pero el armado de los gráficos de histogramas
funciona de una.

------------------------------------------------------------------------------------------

30/04/2024

No llegué más temprano que lo usual, pero casi. Armé los gráficos de las distribuciones
de las opiniones diferenciando preguntas políticas y no políticas. Habiendo charlado con
Pablo, la pregunta sería ver si estas preguntas políticas cruzadas con ellas mismas me
generan gráficos distintos a cruzarlas con las preguntas no políticas. Aunque siento
que las preguntas no políticas apenas tengo casos que mirar, quizás valga la pena revisar
la ANES nueva y de ahí ver qué puedo extraer. Al final del día, la forma de levantar
datos que usa Hugo me podría servir para la nueva ANES creo yo, simplemente tengo que levantar
el csv y convertirlo en un pandas.

Lo siguiente que puedo hacer entonces son los gráficos de la distribución en el espacio de
opiniones y de ahí ver qué puedo rescatar. Comparemos preguntas políticas con otras políticas
y apolíticas con apolíticas. De ahí vamos armando los gráficos. Una vez que tenga los gráficos,
ampliar el conjunto de preguntas, porque no me satisface lo que tengo. No creo que tenga
suficientes apolíticas.

Antes que esto, Pablo me dijo de aplicar la medida de la distancia Jensen Shannon. Olvidemos
lo anterior, hagamos esto YA. No tengo una distribución para comparar, pero podría aprovechar
dos distribuciones que tengo acá y medirles su distancia Jensen-Shannon, ver que la idea se
puede y que da razonable. Bien, ya vi que calcula y cómo hacer la cuenta. En su momento será
un bardo ver cómo clasificar los gráficos según si son preguntas de 6 casilleros o 7.

Hice la cuenta sobre los datos de la ANES 2020, aprox. tiene 1200 preguntas. Veamos de levantar
los datos de la ANES 2020. Bien, los datos parece que se levantan sin problemas.

Preguntas Políticas 2020:
-------------------------
1) V201200: SCALE LIBERAL-CONSERVATIVE SELF-PLACEMENT (7 Opciones)
2) V201225x: VOTING AS DUTY OR CHOICE (7 Opciones)
3) V201231x: PARTY IDENTITY (7 Opciones)
4) V201246: SPENDING & SERVICES: SELF-PLACEMENT (7 Opciones)
5) V201249: DEFENSE SPENDING: SELF-PLACEMENT (7 Opciones)
6) V201252: GOV-PRIVATE MEDICAL INSURANCE SCALE: SELF-PLACEMENT (7 Opciones)
7) V201255: GUARANTEED JOB-INCOME SCALE: SELF-PLACEMENT (7 Opciones)
8) V201258: GOV ASSISTANCE TO BLACKS SCALE: SELF-PLACEMENT (7 Opciones)
9) V201262: ENVIRONMENT-BUSINESS TRADEOFF: SELF-PLACEMENT (7 Opciones)
10) V201342x: ABORTION RIGHTS SUPREME COURT (7 Opciones)
11) V201345x: FAVOR/OPPOSE DEATH PENALTY (4 Opciones)
12) V201356x: FAVOR/OPPOSE VOTE BY MAIL (7 Opciones)
13) V201362x: FAVOR/OPPOSE ALLOWING FELONS TO VOTE (7 Opciones)
14) V201372x: HELPFUL/HARMFUL IF PRES DIDN’T HAVE TO WORRY ABOUT CONGRESS/COURTS (7 Opciones)
15) V201375x: RESTRICTING JOURNALIST ACCESS (7 Opciones)
16) V201382x: CORRUPTION INCREASED OR DECREASED SINCE TRUMP (7 Opciones)
17) V201386x: HOUSE IMPEACHMENT DECISION (7 Opciones)
18) V201405x: REQUIRE EMPLOYERS TO OFFER PAID LEAVE TO PARENTS OF NEW CHILDREN (7 Opciones)
19) V201408x: SERVICES TO SAME SEX COUPLES (6 Opciones)
20) V201411x: TRANSGENDER POLICY (6 Opciones)
21) V201420x: BIRTHRIGHT CITIZENSHIP (7 Opciones)
22) V201423x: SHOULD CHILDREN BROUGHT ILLEGALLY BE SENT BACK OR ALLOWED TO STAY (7 Opciones)
23) V201426x: WALL ON BORDER WITH MEXICO (7 Opciones)
24) V201429: BEST WAY TO DEAL WITH URBAN UNREST (7 Opciones)



Preguntas Apolíticas 2020:
--------------------------


------------------------------------------------------------------------------------------

01/05/2024

Volví del cumpleaños de Estaban. Ahora queda ponerme a hacer algunas cosas, empezar a preparar
la presentación de mañana. Se me hace importante primero revisar que las preguntas que
arme tengan gráficos útiles. Si eso es así, lo siguiente será ir viendo quizás de empezar
la presentación. Si no es así, me pongo a buscar algunas preguntas más.

Por algún motivo que no comprendo, mi función me está tirando errores, a pesar de que no
tiene nada distinto a lo que tenía ayer. Resolveré esto mañana en la facultad.

Hagamos un esquema de la charla:
--------------------------------

1) Les comento que estuve mirando las preguntas que estaban en el archivo que me pasó Hugo
y revisando esos gráficos que producen para ver cuáles gráficos podríamos querer comparar
con nuestros datos, en caso de querer observar tal o cual estado.
 Muestro varios gráficos y coloco al lado las distribuciones con las que digo que se podrían
comparar.
2) No creo que de ninguna forma me dé el tiempo, pero podría intentar medir la distancia
Jensen-Shannon de algún gráfico en particular con la de una de las distribuciones obtenidas
de la ANES.
3) Les cuento que bajé los datos de la ANES 2020, logré leer los datos, los cuáles tienen un
formato muy similar, y construir gráficos parecidos. Para eso estuve revisando la guía de
datos y de ahí seleccionando preguntas que podrían ser relevantes o útiles.
¿Por qué queremos la encuesta más nueva?
4) Debería definir una región en la cuál realizar las simulaciones de 10000 agentes.
Eso debería poder hacerlo posiblemente si tengo una idea de qué gráficos quiero buscar.
En Beta razonablemente tenga que ir entre [0,1] y Cos(delta) entre [0,0.15]. Un barrido
medio crudo sería de a 0.05 para Beta y 0.01 para Cos(delta). Necesito saber cuánto va
a tardar esto.
5) Si queda lugar, mostrar alguno de los otros resultados.

------------------------------------------------------------------------------------------

02/05/2024

A la mañana preparé la presentación para la gente de GOTHAM. Armé los gráficos de las
distribuciones 2D y de ahí fui armando alguna idea de las cosas importantes.

Después de la reunión, fui al coloquio de Darío, aunque no pude ver mucho, volví para
anotar algunas cosas y después me fui a casa. Estuve como cuatro horas viajando para 
ir a buscar el documento que faltaba por el tema de la nacionalidad italiana. Todavía
sin suerte.

No pude mandar a correr el barrido en el espacio de parámetros para el caso de 10000
agentes. Mañana es lo primero que mando a hacer en la mañana.

------------------------------------------------------------------------------------------

03/05/2024

No estoy pudiendo mandar a correr simulaciones en la pc de Coimbra, no sé qué error está
encontrando el código. Voy a rehacer un código único desde la pc de la facultad y subir
eso a las tres pc's y de ahí mando a correr todo. A este código le falta las funciones
de Clasificación y los vectores asociados.

Mandé a correr en mi pc un archivo de 10000 agentes, veamos cuánto tarda en resolverse.
Es un estado con Beta 0, debería converger a un estado de Consenso Radicalizado. Está
tardando más de una hora esto. Es un muy mal presagio esto.

Mientras termina de correr el programa con 10000 agentes, voy a descargar los datos de
la ANES de años anteriores. Descargué las encuestas de 2012, 2008 y 2004.
La de 2012 parece que tiene un formato muy similar a las últimas 2, esa creo que se
podría agregar a lo visto sin mucho problema. Pero la de 2008 y la de 2004 tienen un
formato muy distinto y no estoy seguro de tener los archivos correctos para observar
las preguntas consideradas.

La de 2008 tiene un codebook separado para la encuesta pre y otro para la encuesta 
post. Habría que repasar el codebook para separar las preguntas. Lo bueno es que
parece que también usan números negativos para respuestas fuera de formato, pero
algunas preguntas tienen MUCHÍSIMAS respuestas con números por fuera de los primeros
10, habrá que revisar si son un problema o si se pueden ignorar.

NO TERMINÉ DE VER CÓMO ES EL FORMATO DE LA ANES 2004. TAMBIÉN TENGO QUE VER DE LEVANTAR
LOS DATOS, VER SI ME TIRA ALGÚN ERROR.

Justo terminó el código en la pc de la facultad. Por lo visto corre y llega a un resultado
razonable. El problema es la cantidad de tiempo que tarda. Tardó 11813 segundos en resolver
7000 pasos. Una locura es eso. Para 1000 agentes tardó simplemente 40 segundos. Las escalas
son completamente distintas. Veamos si funciona con los datos de clasificación. De paso,
el archivo apenas ocupa 900 kb. Casi un mega. Si tengo 100 simulaciones, para 36 puntos,
eso es aprox. 3 GB. Puedo simplemente guardarme las opiniones finales por ahora.

El código con la clasificación funca perfecto en la pc. Igual, quedémonos sólo con lo
importante, que serían las opiniones finales y la semilla. Comitteo esto y ya mañana
mando a correr todo. ACORDATE DE USAR UNA SOLA CARPETA DE REDES DE ADYACENCIA.

------------------------------------------------------------------------------------------

04/05/2024

Hoy a la tarde mandé a correr las simulaciones en las tres pc's, pero esto va a tomar
una eternidad. Hablar con Pablo y contarle que voy a meterme un momento en el código a ver
si hay algo que pueda hacer para hacerlo correr más rápido.

------------------------------------------------------------------------------------------

05/05/2024

Mirando el código, encontré algo que claramente está gastando mucho tiempo. Estoy calculando
varias veces el mismo peso. Tengo que hacerlo de forma tal de calcularlo una sola vez. Eso
va a reducir en mucho el tiempo de simulación. Ese error está en la función de GENERAR_SEPARACIÓN.

Otra cosa que no tiene que ver con tiempos de simulación pero que estaría bueno cambiar
es el hecho de que la matriz que guarda las tanh se llama Exp. Habrá quedado de otro código,
cambiar eso.

Lo tercero que se me ocurre que puede servir para achicar los tiempos es reducir primero
el ancho de la ventana de promedio, de 1000 a 500, y después cambiar el número de iteraciones
extras que el sistema necesita para cortar a 1500. En especial porque muchas simulaciones que
cortan rápido hacen 7000 pasos totalmente al pedo, cuando con 4000 o 3000 habrían terminado.

Estoy pensando en quizás cambiar la cantidad de pasos_maximos, pero Hugo y demás usaban esa
misma cantidad de pasos máximos, me parece que cambiar sería una mala idea.

------------------------------------------------------------------------------------------

06/05/2024

Ahí hice el cambio sobre el cálculo de los pesos. Veamos en comparación con el cálculo que se hizo
el otro día. La otra vez tardó 11813 segundos. Voy a usar la misma semilla y correr el mismo
programa, a ver cuánto menos tarda ahora. No voy a cambiar el tema las iteraciones extras o el
ancho de la ventana todavía, así la comparación es directamente con eso.

Ahí está corriendo eso. Mientras, voy a hacer las otras dos correcciones. Ya cambié el uso del
vector Exp por el vector Tanh. Es un cambio  de nombre para ser más claro.
 También modifiqué la cantidad de iteraciones extras y el ancho de ventanas para que esto corte
más rápido en los casos en que el sistema deja de variar rápido.

Mientras termina de correr la simulación que mandé, voy a preparar la presentación del miércoles.

Memes y cosas para introducir en la charla:
-------------------------------------------
1) Descripción distópica y útopica del tema con imágenes de Megaman battle network.

Después continuo esto.

El cambio que hice en los cálculos de las exponenciales no parece tener ningún efecto.
Es raro eso, no tiene mucho sentido. A menos que haya algo que está mal anotado en el
código, revisar eso. Porque tendría que reducirse mucho la cantidad de cuentas.

------------------------------------------------------------------------------------------

07/05/2024

Hoy quería ponerme a estudiar alemán, no creo que lo haga. Primero voy a mandar a correr de nuevo
los barridos en las pc's, pero modificando el instanciar para que no tenga el cero de cos(delta)
duplicado y modificando el ancho de ventana e iteraciones extras, eso debería modificar
algunos tiempos de simulación. Después voy a probar un poco más el tema de la modificación
en el código sobre el cálculo de las exponenciales, el cuál parece no tener efecto.

IMPORTANTE: EN ALGARVE ALGUNAS SIMULACIONES NO COMPLETARON PARA BETA=0 Y COS(DELTA)=1. REVISAR
DE MANDARLO DESPUÉS. AHORA MANDÉ PARA QUE ARRANQUE DE NUEVO A PARTIR DE BETA=0.2.

Ya mandé a correr todo de nuevo, haciendo las modificaciones que hice en la pc de la
facultad. Veamos ahora el tema de si puedo hacer correr esto más rápido. Necesito que
así sea, porque estas cosas están tardando tiempos imposibles.

No encontré la forma de hacer que esto vaya más rápido. Por ahora lo voy a dejar, voy
a mandar a correr simulaciones con redes de 5000 agentes a ver si puedo usar eso para
realizar las comparaciones. Con 5000 agentes el sistema me tarda 15 minutos. Ya fue,
trabajemos con 5000 agentes por ahora. Es mucho más razonable.

Cargué los archivos en las tres pc's, cuando terminen las corridas previas mando a correr
las nuevas simulaciones. No debería tardar mucho. A 15 minutos por simulación, me puedo
dar el lujo de hacer un barrido un poco más fino. Recorriendo 11 puntos en cada eje, son
121 puntos en el espacio de parámetros. Con 15~20 minutos por simulación, en el peor caso
eso es 40 horas por iteración. Así que en 2 o 3 días debería tener resuelto esto, considerando
que para los Betas cerca de 1 los tiempos de simulación se van a disparar. Espero que salga
bien la cosa, tendré 30 simulaciones para mirar.

Voy a ponerme a preparar la presentación para mañana.

------------------------------------------------------------------------------------------

08/05/2024

Revisé los programas que están en las pc's y están tardando aprox. 40 minutos cada simulación.
Recién resolvió dos betas de los 11. Así que eso va a estar un buen rato, con algo de suerte
va a estar terminado para el viernes. La pregunta importante es:
¿Me pongo hoy a estudiar Alemán o mañana? Yo diría que mejor mañana, así mañana cualquier
cosa tengo algo para mostrarle a Pablo. Hoy pongámonos a armar el Excel que decíamos con
Pablo de preguntas de las ANES.

------------------------------------------------------------------------------------------

09/05/2024

Por el paro, hoy estoy trabajando en casa. Estoy mirando la ANES y clasificando preguntas.
En la encuesta ANES 2020 hay preguntas de estereotipos sobre que tan trabajador o violentos
son según grupo étnico. Esas preguntas van desde V202515 hasta V202526. Todas estas preguntas
tienen 7 posibles respuestas. A partir de la pregunta V202580 hay muchas preguntas que parecen
tener 7 respuestas, varias que no son políticas. Pero son demasiadas y poco interesantes
realmente. Quizás si hace falta las podría revisar, pero en principio no es importante.

Ya revisé toda la ANES 2020. ¿Debería seguir con este trabajo?

------------------------------------------------------------------------------------------

10/05/2024

El 9 trabajé desde casa, pero por lo que veo no lo comitee, quizás genere problemas.
Tengo problemas más serios. Resulta que lo que estoy mandando a correr está tardando una eternidad.
Es una eternidad más corta que el caso de 10000 agentes, pero aún así el de 5000 está tardando
una eternidad siendo que las simulaciones que polarizan tardan 36 horas aprox. en resolverse.
Tengo que ver de buscarle una vuelta a eso. Simplemente es inviable trabajar así.
¿Debería resolver eso ahora?

Lo que habíamos charlado con la gente de GOTHAM era catalogar preguntas, armar a partir de eso
un conjunto de preguntas interesantes y quizás ver a lo largo de varias ANES cómo evoluciona
la polarización de esas preguntas. Creo que puedo conseguir más resultados si sigo catalogando
preguntas. Pero en ese caso, ¿Qué buscaría mostrarle a la gente de GOTHAM el miércoles que
viene? Con suerte, podría mostrarles el subset de preguntas que pensamos mirar y algunos 
gráficos donde veamos cómo fue evolucionando esa polarización. Porque mostrarles cuáles son
los tipos de gráficos que planeamos comparar no tiene sentido.

Sabiendo que los datos de simulaciones no van a estar como para hacer un estudio razonable
de acá al miércoles, yo propondría primero ir comparando lo que tengo con datos obtenidos
de 1000 agentes, como los que armé para el espacio reducido en Beta-Cosd, y de ahí armar algo
que funque y que en principio sea un puntapié al análisis, total una vez que tenga los datos
es una cuestión de cambiar el N del código de 1000 a 5000 o 10000. Entonces primero seguiré
catalogando preguntas, y ya a la tarde o después de hablar con Pablo definiremos los siguientes
pasos en estos días de acá al miércoles. Después habrá que volver a ver qué podemos hacer para 
que el código corra más rápido, porque simplemente no se puede vivir así. La primer idea que
surge es hacer una Tabla con datos para la función exponencial e interpolar. Tengo que pensarla
de alguna forma correcta, cosa de que el argumento sea la distancia al cuadrado del vector
y no la distancia, así aprovecho y me ahorro la raíz cuadrada.

Estoy mirando el guidebook de 2012 y estoy notando dos cosas importantes. La primera, es que el
formato es mucho más feo que las versiones anteriores, va a tomar mucho revisar las preguntas.
La segunda es que este guidebook no parece tener separados los datos en códigos como los otros
dos. Eso me preocupa.

De acá para el lunes es importante mandar a correr mi código para 10000 agentes en una dimensión
y el código de Hugo para 10000 agentes en una dimensión. Corrido eso, vamos a tener una buena
idea de la diferencia de tiempos y si los tiempos del código de Hugo es razonable o viable.

------------------------------------------------------------------------------------------

11/05/2024

Mandé a correr el código mío y tardó 7600 segundos. El código de Hugo en cambio tardó 47 segundos.
Hay una diferencia de dos órdenes de magnitud en el tiempo que tarda mi código y el de ellos.
No comprendo por qué. Eze me dice que quizás sea un tema de la cantidad de fors que estoy usando.
No creo que sea eso, pero se puede probar.

Mañana habrá que hacer gráficos con las preguntas que tengo de la ANES, armar una clasificación
clara y después preparar algo para presentar con eso.

------------------------------------------------------------------------------------------

13/05/2024

Soy un reverendo pelotudo, cinco veces pensé en commitear el trabajo de casa y no lo hice.
Ahora voy a tener un bardo entre los archivos y cosas. En la facultad hoy voy a
ponerme a trabajar en los archivos de Python para armar la clasificación de las preguntas
y los gráficos asociados.

El sueño que tengo me está complicando laburar fuerte. Ya no es joda hermano. No sé si
es la ropa que tengo puesta o el cansancio general, simplemente estoy deteriorándome. Y
el invierno no me gusta.

Anoté las preguntas que voy a mirar, armé los gráficos y los estuve repasando un poco,
pero no me parece muy interesante lo que estoy viendo. Pablo me propuso mirar directamente
las distribuciones 1D y con eso ir descartando cuáles son las preguntas que quiero mirar y
cuáles no.

¿Qué criterios usé para remover preguntas? Saqué las que tuvieran una gran cantidad de agentes
en una opinión neutra o que tuvieran distribuciones muy homogéneas.

Hice un primer filtro de cuáles voy a querer y cuáles no. En el drive voy a marcarlas como
descartadas, mientras que en Python las voy a borrar directamente.

Las preguntas que clasifiqué y separé me parece que son un buen filtro, me dejan los gráficos
que inicialmente quería mirar. Anotemos las preguntas descartadas en el drive. Después de eso,
empiezo a ver cómo medir la distancia de jensen-shannon.

Hice las anotaciones que quería en el drive, tengo clasificadas las preguntas que voy a querer
revisar. Mañana veré de armar el conjunto de preguntas y mostrárselo a Pablo, así como mostrarle
de estas preguntas cuáles podrían tener una cierta trazabilidad hacia atrás.

Lo que voy a hacer ahora es descargar los datos del barrido de Zoom Beta-Cosd y a partir de esos
ver cómo comparar esos datos con los datos de las distribuciones. Voy a elegir dos o tres
gráficos para comparar y a partir de esos voy a intentar armar algunas comparaciones.

Descargué los archivos a la carpeta de Comparacion_datos. Lo que necesito es un archivo de Python
que arme la Clasificación de las opiniones finales y compare eso con los datos de la encuesta.
Tengo algo que hace eso creo, que lo preparé para la semana pasada. Así que simplemente tengo
que lograr hacer un for. Y después voy a tener errores porque obviamente tengo huecos en mis
distribuciones T.T.

------------------------------------------------------------------------------------------

14/05/2024

Ayer llegué a casa y tampoco comitee mis datos. Soy un re boludo. Voy a copiar los datos de la
ANES en la carpeta de Comparación_datos y ahí voy a trabajar la parte de las comparaciones de
las distribuciones usando distancias Jensen-Shannon.

Ya tengo los datos del barrido reducido y tengo los datos de la ANES para comparar. Lo siguiente
sería empezar a comparar los datos. Voy a probar contra una distribución que tiene una buena
forma de polarización ideológica, el gráfico que sale de "Govt. Asssitance to Blacks" vs
"Guaranteed Job Income", que son los códigos "V201258" vs "V201255".

Por lo que leí en Wikipedia, debería revisar un poco más el tema, la idea es que al calcular
la distancia Jensen-Shannon, la distribución p, que es la primera que le paso a la función,
es la distribución medida. Es decir que primero le paso la distribución obtenida de la encuesta.
La segunda distribución, la distribución q, debería ser mi aproximación o mi resultado simulado.

Estoy armando el código para calcular la distancia entre dos distribuciones. Tengo una primera gran
duda: ¿Las distribuciones que estoy comparando, elemento a elemento, corresponden entre ellas?
La respuesta es que sí, se corresponden. Eso es genial, no puedo creer que haya funcionado.

Lo siguiente ahora es armar una función que calcule esta distancia y arme gráficos en el espacio
de parámetros. Ahí lo mandé a correr, funcionó. Y da razonable. Charlar eso con Pablo mañana.

------------------------------------------------------------------------------------------

15/05/2024

Pablo mandó un mensaje para posponer la reunión hasta la semana que viene. Así que para
la semana que viene tengo que tener algo más sólido armado. Para eso tengo que trabajar
en las siguientes cosas:

1) Acondicionar el código de Hugo para que trabaje con dos tópicos.
2) Continuar estudiando la distancia Jensen-Shannon en el espacio de parámetros para otras
configuraciones de preguntas. (Esto va a implicar adaptar la función de Clasificación para
los casos con tamaños que no sean 7x7). También debería estudiar un poco más la función
que calcula la distancia Jensen-Shannon.
3) Revisar los resultados analíticos y armar un plan de qué falta hacer. Quizás hacer
análisis de las ecuaciones en papel mezclado con simulaciones.
4) Revisar si quedaron ideas que valga la pena estudiar del tema de las simulaciones.
5) Probar cómo hacer que mi código funcione tan rápido como el de Hugo.

Vuelvo a mirar mi código, no veo nada raro. No comprendo. Pero bueno, empecemos a modificar
el código de Hugo para que funcione como yo quiero. Mientras, pongamos a prueba los tiempos
una vez más. Mandé a correr los dos códigos, sólo para comparar los tiempos.

Mandé mi presentación al curso de Verano ese en Uruguay que Pablo había compartido. Por otro
lado, no terminé de adaptar el código de Hugo. Mañana termino eso. Quedé a mitad de
adaptar la parte donde evoluciona y calcula la variación promedio. Lo que me queda revisar
también es agregar el cálculo de la norma no ortogonal. Creo que hechas esas dos cosas,
debería estar resuelto esto.

De paso, mandé a correr los códigos para comparar los tiempos, sigue ocurriendo que el
código de Hugo es 100 veces más rápido que el mío.

------------------------------------------------------------------------------------------

16/05/2024

Llevo toda la mañana y un poco de la tarde en terminar de adaptar el código de Hugo para que
corra como yo espero. Veamos si realmente funciona. Crucemos los dedos.

Corre y resuelve en poco tiempo. Queda hacer una comparación sobre si mi código genera el
mismo resultado. Suponiendo que el código funciona bien, tengo que reemplazar lo que ya 
está en funcionamiento y mandar a correr este nuevo código. Vayamos preparando eso mientras
se resuelve el código que mandé en la pc de la facultad que compara lo que hace mi código
con lo que hace el de Hugo.

Ya está corriendo el código de Hugo adaptado, el cuál corre mucho más rápido que el mío.
Lo que voy a hacer ahora es probar que el cálculo de la distancia de jensen-shannon sea
razonable, que esa cosa calcula correctamente.

Revisé la función de Jensen Shannon comparando dos distribuciones normales para ver cómo
varía esta distancia. Parece funcionar perfecto, incluso trabajando sin drama ante la idea
de tener 0 en partes de la distribución. Parece que no va a generar ningún problema
esto.

Mañana podría ponerme a modificar la función de Clasificación para poder agrupar las opiniones
en arrays de 6*7.

Ahora lo siguiente que necesito hacer para presentar es armar una función que primero
aisle la región de datos en la cuál quiero armar mi ajuste, y que luego haga ese ajuste.
Como sea que tenga que ser eso. Yo diría que por hoy estoy en horario, guardaría todo,
iría para casa y luego veré cómo construir eso el finde. O el lunes, creo que el lunes
tendría que salir eso.

------------------------------------------------------------------------------------------

20/05/2024

Estoy trabajando desde casa, hoy no me siento en condiciones de ir a la facultad.
Lo que quiero hacer es el ajuste de los parámetros. Para eso recorto una región en
la cuál observe un mínimo. A esa región, le hago un ajuste por cuadrados mínimos a la
Distancia de Jensen Shannon en función de los parámetros Beta y Cos(delta), ajustando
con la función de un paraboloide.

Armé la función que hace el ajuste de cuadrados mínimos. Después tengo que ver cómo obtener
el error del ajuste. Pero lo importante es que con esto podría calcular los coeficientes
de mi paraboloide con el que ajusto este espacio.

Digamos que Beta lo ajusto entre [0.5,0.72] y Cosd entre [0.04,0.15]

------------------------------------------------------------------------------------------

21/05/2024

Ya logré armar el cálculo del mínimo del valor 

Lista de tareas:
1) Chequear dónde se demoran mis simulaciones.
2) Resumen de la parte numérica. Qué está hecho y qué faltaría.
3) Resumen de la parte teórica. Qué está hecho y qué faltaría.
4) Resumen de la selección de datos y comparación del modelo.

Para la charla de mañana, quizás ver de hacer un ranking y también 
mostrar el espacio clasificado según las simulaciones.

Estoy teniendo un problema horrible con el cálculo de los gráficos
de distribución de opiniones de las encuestas. Es ese problema que me ocurre sólo en casa,
y que no logro comprender por qué. ¿Será mi versión de Win Py? Buscaré cómo actualizar eso.

Mandé a correr las simulaciones de la 30 a la 50 en Coimbra. En Algarve y Oporto no terminaron
todavía.

Las dos primeras preguntas que revisé son: 'V201258' vs 'V201255'. Son preguntas dudosas
Las variables óptimas obtenidas fueron: [Cosd = 0.104, Beta = 0.602].
Revisé 'V201420x' vs 'V201231x'. Son preguntas políticas
Revisé 'V202320x' vs 'V202320x'. Son preguntas No políticas

------------------------------------------------------------------------------------------

22/05/2024

Para bien o para mal, hoy es la reunión. Hay que hacer funcionar esto. Logré graficar 
las distribuciones de las encuestas usando matplotlib. Gracias por tanto Hugo.
Lo que tengo que hacer es elegir tres pares de preguntas. Uno ya lo tengo elegido,
es el que le mostré a Pablo, creo que Govt. Assistance to Blacks vs Guaranteed Job
Income.

De las preguntas políticas tengo dos opciones que me parece que podrían resultar
interesantes. La primera es "Birthright Citizenship vs Liberal-Conservative Self placement"
(V201200 vs V201420x). Se parece un poco a polarización descorrelacionada porque no va
tanto a extremos sino que llena un poco más las zonas intermedias. La segunda opción es 
la de "Less or more Government vs Birthright Citizenship" (V201420x vs V202255x).
Esta no me convence tanto porque tiene bastante vacío el medio, eso se parece más a una
polarización descorrelacionada sin anchura. Aunque debería igualmente dar mejor 
cerca de Beta =1.

En el caso de las no políticas, observo que son todas básicamente casos de consenso radicalizado.
Si ploteo lo que observo en la salida del plt.hist2d, lo que obtengo no es algo normalizado, es una
distribución con números más grandes que uno en muchos casos. Pero son todos floats, no es que
es la cantidad de agentes en cada región exactamente.
Me parece que razonablemente puedo proponer como ejemplo del de "Government action about opiod
drug addiction vs Economic Mobility compared to 20 years ago" (V202320x vs V202350x). Todos los
pares de preguntas parecen razonablemente observarse como consensos, ese par me parece preguntas
claramente apolíticas.

El par de preguntas apolíticas que estoy mirando está dando muy mal, por algún motivo me queda la
distribución al revés de lo que esperaría ver. No, ya lo pensé, ahí lo entiendo todo, la forma en
que calculo la distancia claramente está generando problemas. No estoy rotando las distribuciones.

Probemos cómo da el caso de Vaccines in Schools vs Best way to deal with Urban Unrest. 
(V201429 vs V202341x).

.) Considerar que la gente responde nulo cuando no se le da la opinión de no responder.
.) Usar agentes neutros a la fuerza. Es una forma de resolver el tema de la caja de agentes
 con opiniones. La otra es anular el elemento que corresponde a la caja central
.) Normalizar los gráficos de la distribución de la ANES.
.) Salvar los ceros en las regiones que faltan agentes.
.) Considerar que quizás tenemos dos Betas. Pensar en temas que tengan Betas distintos quizás,
 como el del Muro con México y el ..., para ver si tienen dos mínimos.
.) Arrancar con las preguntas que vieron ellos en el paper que sean bimodal o unimodal.
.) Comparar gráficos con igual resolución.

------------------------------------------------------------------------------------------

23/05/2024

Hoy lo primero que quiero hacer es organizar un poco mis archivos, y después resolver alguno
de los elementos que charlamos con la gente de España.

1) Normalizar los gráficos de distribuciones de ANES.
2) Armar reversiones de mis gráficos 
3) Rearmar la función de Clasificación para que tome preguntas de 6 respuestas en vez de 7.
4) Finalizar los ajustes, así como el graficado scatter de las distancias.

Al final solo logré hacer un poco de orden en las cosas que tenía, no avancé en nada del
trabajo por el tema de cómo me está resultando la operación. Roguemos que todo va a mejorar.

------------------------------------------------------------------------------------------

24/05/2024

Hoy estuve con el tema de la inflamación. Recién a la tarde arranqué a laburar. Pablo me va
a proponer usar zealots neutrales en las simulaciones. Mi proposición sería que no porque 
eso es algo a implementar en el código y más fácil sería hacer lo que dijo Hugo, simplemente
retirar el elemento del centro de la distribución.

Creo que normalizar los gráficos de la ANES es la primer prioridad. 
Segunda es modificar la función de Clasificación,
Tercero es graficar los histogramas 2D de mis simulaciones con la misma resolución que mis distribuciones.

Si eso está hecho, podría ver de pasar a ver cómo hacer lo de comparar distribuciones que tengan
betas diferentes para comparar. Para eso necesitaría la info que Hugo me dijo que me iba a compartir.
Si hoy no está, se la pido ya el finde. 

También voy a tener que repasar la parte teórica del modelo y charlar eso como para hacer una
presentación interesante al respecto. ES IMPORTANTE QUE PARA DENTRO DE DOS SEMANAS TENGAMOS
MEJOR PRESENTADO EL AJUSTE HECHO EN LOS DATOS, ASÍ COMO UN RESUMEN DE LA PARTE TEÓRICA Y
LA PARTE DE SIMULACIONES.

Empecemos por la parte de normalizar las distribuciones. Con ponerle un density = True parece
que alcanza. Aunque me genera un poco de duda eso, por cómo funcionan los pesos. La idea
es que el histograma cuenta cuántas son las personas que opinaron X o Y. Pero al pesarlo,
¿Afecta ese valor según un número? ¿No debería ser más bien como que la cantidad de gente
que cuenta se ve afectada? ¿Está el plt.hist2d haciendo el segundo trabajo o el primero?
Yo ya no estoy seguro de qué está haciendo.
 Si esto funciona bien, lo que debe estar haciendo es primero definir donde va cada "evento",
y luego no los cuenta como unidad, sino como su peso. Entonces si el peso es 0.97, no
cuenta como una persona, cuenta como 0.97 persona. Bien, es razonable. Normalizar eso
es una tontería después.
 En particular, al normalizar me queda algo tal que si sumo todos los valores me da 1. Eso
es porque cada cajita mide 1 de lado. 

------------------------------------------------------------------------------------------

26/05/2024

Ahí modifiqué el armado de la función de Clasificación, no lo probé, confío en que está bárbaro.
Acabo de ver que en la función que lee los datos de la ANES ya estaban los nombres de las
preguntas. Debería ver de extraer eso de ahí y listo.

Revisé la función que arma los histogramas 2D, para conseguir mis gráficos de 7x7 como quiere Pablo,
necesito simplemente cambiar el número de bins, ni hace falta que arme una función nueva.
Pero sí aproveché a modificar la función de Clasificación, todos los usos que encontré de eso, y 
por tanto los de Diccionario Metricas y de Calcular Entropia.

------------------------------------------------------------------------------------------

27/05/2024

Llegué no tan temprano, pero con motivos. Organicé cosas, revisé que el armado de gráficos con Seaborn
siga funcionando, aunque pasé a armar los gráficos con matplotlib. Ahora voy a ponerme a hacer
los gráficos de histogramas de opiniones 2D de 7x7.

Mientras está corriendo el armado de los gráficos de Zoom_Beta-Cosd voy a revisar que se estén armando los
gráficos correspondientes en las computadoras del cluster. Eso sigue corriendo todavía. En especial en
Algarve y Oporto creo que están todavía en la primera vuelta, falta la segunda. En cambio en Coimbra
ya casi está terminado. Mañana voy a ver si ya está terminado y mando a correr de nuevo.
Estos gráficos se podrían rearmar de forma de que los cuadrados en los que divido el espacio de opiniones
representen la proba de tener agentes en esa región. Actualmente representan otra cosa porque los cuadrados
miden 2.8...

Bien, ya resolví las cosas que me anoté el viernes. ¿Qué es lo próximo que tengo que hacer?
Hay dos cosas que se me ocurren hacer. Lo primero es revisar el tema del estudio analítico.
Completar el análisis de la polarización ideológica con el análisis de la polarización descorrelacionada.
La idea sería utilizar alguna simulación para ver la estabilidad del modelo en función de Beta
para ver si el estado de polarización descorrelacionada se rompe a medida que Beta crece.

La segunda opción es ver cómo puedo rotar las distribuciones de opiniones para poder comparar eso con las
distribuciones de ANES. Una vez hecho eso, puedo volver a realizar los ajustes que dejé truncados en
la última reunión.

------------------------------------------------------------------------------------------

28/05/2024

En la mañana estuve trabajando un rato en mi cuaderno en armar un código que rote la matriz.
Después me puse a estudiar alemán, fui a cursar y a la vuelta trabajé un poco más antes de
irme a casa.

------------------------------------------------------------------------------------------

29/05/2024

En la mañana me escribí el código para rotar matrices que necesitaba. Ahora que tengo eso,
puedo ponerme a hacer lo segundo que es lo que me dijo Pablo, ver de remover elementos de
las distribuciones. Podríamos removerlos de dos formas. La primera, es remover sólo el elemento
central. La segunda es remover TODO agente que haya respondido con las preguntas centrales
an alguna de las preguntas. Vamos a probar hacer las dos cosas y de ahí vamos a ver qué resulta
mejor.

Pero antes de eso, ¿Tengo resuelto la rotación de mis matrices? Lo que hice funciona bien si mi
matriz es cuadrada. Pero en caso de no serlo, ¿Cómo puedo rotar mi matriz? ¿Tiene sentido rotar la matriz?
Creo que por ahora no me voy a preocupar demasiado por esto. Avancemos con lo otro, y cuando surja
ese problema, lo enfrentaré.

Probaré primero sacando un elemento en el centro. Me parece que va a ser más fácil de implementar.
Al mismo tiempo implementaré una corrección para el hecho de que las distribuciones no tengan ningún
punto nulo.

Para remover el punto central, eso es bastante directo. Si mis preguntas son de 7x7, significa que
tengo que eliminar el punto en la posición [3,3]. O lo que sería lo mismo, de mis 49 elementos de
mi array con la distribución de la encuesta, tengo que eliminar el elemento 24.

Admito que me gustaría además que el gráfico que hago de la encuesta tenga ese elemento bloqueado.
Debería ver de pedirle al pandas que al graficar ese punto esté tapado.

Bien, para remover los agentes del centro o para remover la cruz ya Chat GPT me dió una linea fácil de
cómo hacer eso con Pandas, probé graficarlo y efectivamente lo que se grafica es lo que estoy buscando.
También miré las distribuciones generadas. Tienen la forma correcta. Lo siguiente es entonces
Ya vi que eso funca, lo que me queda es hacer lo de que si la distribución de la simulación tiene ceros,
entonces tengo que agregar agentes en esa distribución. Lo que puedo hacer en ese caso es sumar agentes
de a 1. Luego, según la cantidad que sumé, restar esos agentes del lugar donde haya más agentes.

Si pongo 1 agente en cada lugar vacío, la distancia Jensen Shannon da distinto que si no tengo agentes
ahí. En particular, tomé el ejemplo del par de preguntas políticas y lo comparé con una distribución de
Consenso Radicalizado. Para esta distribución con ceros, la distancia JS da 0.824, en cambio cuando 
relleno los lugares con cero obtengo una distancia de 0.774. Habrá que hacer esto de rellenar los lugares.

Me queda hoy probar lo de remover el punto central. Al remover el punto central, la distancia da
distinto a si dejo un cero en ese punto. Ok, definitivamente removeré ese punto cuando haga las cuentas.
Ya tengo armado el esqueleto para construir el código que quiero hacer, ahora queda nomás pasarlo
al código de funciones que se encarga de armar el mapa de colores de Distancia JS.

------------------------------------------------------------------------------------------

30/05/2024

Hoy el plan es hacer dos cosas importantes. La primera es lograr ver la distancia de JS de pares de
preguntas removiendo el centro y removiendo la cruz central. Tengo más o menos armado el código para
hacer eso, ahora tengo que organizar todo en carpetas razonables. Creo que lo que voy a hacer es
preparar tres carpetas. Una para el caso normal, una para el caso sin el centro y otra para el caso
sin la cruz. El caso normal lo voy a llamar "Base". El caso sin el centro lo voy a llamar "Sin Centro"
y razonablemente el último caso va a ser "Sin Cruz".

Hecho eso, puedo empezar a revisar pares de preguntas, medir las distancias JS y hacer los gráficos
correspondientes.

Lo segundo que voy a querer hacer hoy es mandar las simulaciones con los Zealots. Eso lo tengo
que mandar a correr en las pc's de la facultad. Igual eso lo voy a mandar a correr recién mañana,
hoy no voy a poder porque la pc de la facultad todavía está corriendo el barrido en Beta-Cos(delta).

Probé varias cosas, pero ninguna parece resultar para cerrar esa región de la cruz. Así que por ahora
dejemos eso y sigamos con el resto del laburo. Para lograr esto creo que la idea va a ser en la misma
función de cálculo de la Distancia de JS hacer las modificaciones para que se calcule correctamente la
distancia y desde ahí armar los dos gráficos de una sola vez. Eso va a ser lo mejor.

Hice todas las modificaciones como para poder correctamente armar los gráficos. Fue un bardo, va a
tirar 15 errores, pero bueno, ahora estoy en condiciones de probar a ver qué da. Va a tardar una eternidad
más, porque ahora hace muchas más operaciones. Además está todo mezclado en un sólo paquete para trabajar
sólo con preguntas de 7x7. Va a ser un bardo desarmar eso para que trabaje con preguntas de 6x6 o 6x7.
Voy a tener que ver cómo se automatiza eso para trabajar en esos casos. O, quizás, sólo quizás, cuando
trabaje con esas preguntas mejor simplemente me pongo a armar una función distinta que ya sepa de antemano
la forma de la función que le voy a mandar. Veré, no sé honestamente qué es mejor.

Ahora voy a trabajar con tres pares de preguntas que me resultan las más simples de utilizar:
1) V201255 vs V201258. (Govt. Assistance to Blacks vs Guaranteed Job Income.)
2) V201200 vs V201420x (Birthright Citizenship vs Liberal-Conservative Self placement)
3) V202331x vs V202341x (Background checks for gun purchases vs Vaccines in Schools)

Logré que haga los cálculos, pero no da muy lindo. Mañana armaré algunas preguntas más en la facultad
como para ver qué es lo que da y si ahora el caso de las preguntas no políticas que parecen un consenso
radicalizado dan mejor.

Lo siguiente es ponerme a trabajar en el código actual para introducir el uso de Zealots cuyas
opiniones se mantienen fijas en (0,0). Entiendo que la idea es que una fracción de esos
agentes se mantengan en esa opinión. Supongamos que el plan es que un 10% se mantenga en ese
número.

Ahí hice lo de los Zealots, la verdad fue bastante rápido, buenísimo. Bueno, ya son las 18:30,
creo que puedo dejarlo acá por ahora. Mañana seguiré sacando gráficos de distancia JS
y veré qué tal quedan.

------------------------------------------------------------------------------------------

31/05/2024

Ahora estoy en la facultad. Lo primero que voy a hacer ahora es mandar a armar los gráficos
para los pares de preguntas que tengo ahí considerado, así se ve mejor si esto funca bien
o no.

Armé gráficos de distancia JS en el espacio de parámetros. Dan un poco mejor que antes, pero
tampoco la gran cosa. Habrá que ir viendo qué tal. Se me ocurre que puedo agarrar algunos
pares de preguntas más, revisarlos y después de ahí sacar conclusiones.

Lo que voy a hacer ahora es armar un poco una charla, unas pocas diapositivas para armar
la idea de lo que vamos a charlar para el miércoles que viene. Había malentendido yo, 
esto es para tener un esquema de trabajo nuestro en el cuál tengamos bien claro lo que estamos
queriendo hacer y lo que falta del trabajo. Tengo anotado el armar simulaciones extendiendo la
región de simulación del espacio Beta-Cos(delta). La idea está bien, vamos a tener que considerar
seriamente cuál es el nivel de granularidad de ese barrido cosa de que sea consistente en toda la
región.

Para el miércoles lo ideal sería llegar con más laburo hecho del lado de los ajustes y las
distancias calculadas de JS. Para eso necesito entonces armar un conjunto de seis pares
de preguntas que me interese revisar. Fijemos algunas preguntas como me dijo Pablo y de
ahí vamos viendo cuáles combino y como.

Algo para aclarar de paso, noté hace un rato que el cálculo de la distancia JS con las simulaciones
más similares está mal hecho porque no estoy haciendo un sort según distancia. Así que eso lo tengo
que corregir. Otra cosa que voy a tener que hacer es corregir el cómo se hace el ajuste, porque eso
no tiene la parte de rotar los gráficos. También estaría bueno agregar al mapa de colores de 
distancia JS algo que saque el gráfico que más se parece a la distribución de la encuesta considerada.

Una cosa más a revisar es el tema de cómo está dando la distancia JS. Parece que nos está dando
muy alto. Pero justamente la palabra clave es parece. No tenemos claro si es un número alto o
no, necesitamos más claridad respecto a qué es un gráfico similar o no a lo que estamos viendo.
Así que voy a tener que experimentar un poco con eso para ver cómo sale. Por último, voy a tener
que ver de normalizar los gráficos de histogramas 2D de forma tal que la suma de las fracciones
graficadas de 1.

Bien, tengo bastante claro el laburo a hacer. Y tengo bastante laburo. Arranquemos. Primero
las preguntas. Me armé un conjunto de preguntas. Suficientemente chico como para no matarme
revisando 30 gráficos. La idea es armar seis, siete gráficos de pares de preguntas y con eso
empezar a revisar cosas.

------------------------------------------------------------------------------------------

01/06/2024

Obviamente me olvidé de subir al drive los gráficos de histogramas que había elegido ayer.
Porque obviamente me iba a olvidar de eso. Ahí armé los gráficos, los hice con matplotlib.
Por ahora voy a trabajar sólo con preguntas que tengan seis respuestas.

Bien, ya tengo seleccionadas las preguntas que creo van a resultar útiles. Ahora armo las
distribuciones 2D de esas preguntas para decidir cuáles 6 preguntas quiero mirar.
Los gráficos que esoty viendo no me gustan, no hay nada que se parezca a lo que queremos
ver. Sí, ya sé que tampoco lo que veíamos se parecía tanto, pero igual no me gusta. Por
ahora dejemos eso así, avancemos con las otras cosas, total si lo otro está armado, simplemente tengo
que elegir nuevos pares de preguntas y volver a intentar.

Ya corregí lo de la similaridad. Era tan simple como poner un np.sort. Lo siguiente que se me
ocurre es armar una función que me muestre el gráfico más y menos similar. El tema de
armar una función aparte es que va a tener que volver a calcular todas las distancias JS
y eso tardaría mucho para mostrar un simple gráfico. Creo que lo mejor sería intentar aprovechar
la función del Mapa de colores DJS. Hagamos eso.

Suponiendo que está todo bien, se arman los histogramas 2D de mínima y máxima similaridad
para cada encuesta sin centro y sin cruz. Aunque no estoy haciendo el histograma 2D de la
simulación sin la cruz o sin el centro. Tengo que ver cómo hacer que esos gráficos respeten
eso. Lo cuál no es obvio porque en las simulaciones las opiniones no son valores enteros.

------------------------------------------------------------------------------------------

02/06/2024

Revisé los gráficos de distribución de la ANES, en el centro de opiniones existen como mucho
un 12% de agentes, siendo más bien en general entre un 6% y un 8%. Así que mandar un 10% de agentes
como Zealots parece una buena idea. Lo que tengo que hacer ahora entonces es cargar el archivo
de opinion a todas las pc's, armar la nueva carpeta de los Zealots y ya mandarlo a correr.

Mandé a correr 10 hilos en Coimbra y 10 en Oporto. Iba a mandar en Algarve, pero todavía le
queda un hilo a Algarve, entonces para no hacer macanas corté lo que estaba mandando ahí y volví
a cargar el archivo de opinion que tenía previamente y lo compilé para que ese ejecutable sea el que
esté armado. Con algo de suerte, no arruiné nada.

Bueno, si corrijo el cómo hace el cálculo de JS la función de ajuste, entonces habré hecho todo lo
que me anoté el viernes para hacer. Que era un montonazo. Me parece un gran plan.

------------------------------------------------------------------------------------------

03/06/2024

En la facultad acabo de rehacer los gráficos de distribuciones de ANES. Sostengo que los gráficos
hechos con las preguntas elegidas no me gustan. Voy a tener que elegir algunas preguntas nuevas.

Ahora voy a mandar en Algarve a correr el armado de las simulaciones con Zealots. Ya mandé eso a
correr. Dentro de todo parece correr bien, los primeros agentes tienen opinión nula mientras que el
resto de los agentes está convergiendo a algún lugar.

Lo siguiente es mandar a hacer los gráficos de Distancia JS. Los gráficos se hicieron, parece funcar
bárbaro. Las distancias dan bastante menor, cercano a 0.35 en promedio. Tengo que corregir una cosa
de esto, y eso es cómo se arma el histograma de máxima y mínima similaridad. También tengo que 
cambiar esos títulos, son confusos. Pero cuestión que tengo que cambiarlo para que esos gráficos
tengan efectivamente 0 en los lugares correspondientes, ya sea en el caso en que no tiene el
centro o el caso en que no tiene la cruz.

Creo que en vez de hacer el histograma, es mejor si simplemente hago el gráfico usando la función de
clasificación y un pcolormesh. Bien, ahí hice algo, espero que funcione. No me gusta mucho cómo están
armadas las funciones, después en algún momento tendré que encontrar la oportunidad para rearmarlas y
escribirlas de forma más prolija. Pero mientras funcionen por ahora, estoy hecho.

Lo siguiente es lograr que la función de ajuste funcione claramente. Que creo que lo está haciendo.
Así que si eso funca, tengo que seguir con la función de Ajuste. Aunque ahí trabajé la función de Ajuste,
si todo está bien ya hace lo que debe hacer. Entonces lo que necesito es tomar los gráficos de 
Distancia en el espacio de parámetro que calculé y calcular los rangos en los que voy a hacer los ajustes.
Otra cosa interesante para hacer sería juntar todos los datos de 10000 agentes y empezar a laburar con
eso, mandar a correr este programa en la máquina de Coimbra. O quizás Algarve. Hoy pareciera que Algarve
es una mejor opción, tiene más hilos libres, como para mandar a correr esto ahí. Empecemos a juntar los
archivos de Comparacion_datos ahí.

El armado del histograma de forma tal que se vea bien normalizado me está costando horrores. No puedo creer
que esté perdiendo tanto tiempo en esto. Ahora creo que lo armé de una manera más razonable, Dios quiera
que esto funque mejor así.

Con esto ya tengo armado todo lo que me anoté el viernes. Debería ahora ir preparando la charla. Una vez que el
código corra bien en la pc de la facultad, voy a ver de pasarlo a Algarve así mando a armar los gráficos ahí.
Aparte de eso, debería ver de implementar correctamente el ajuste. Para eso necesito tener más o menos armados
los rangos de Beta y Cdelta para cada par de preguntas. Si estoy con tiempo, hoy reviso algún par de preguntas
más y veo de armar gráficos con eso.

El código funciona hasta el final, arma el gráfico del paraboloide, hace el mapa de colores de Distancia JS y
hace el ajuste para el caso de las distribuciones sin centro y sin cruz. Ya puedo mandarlo a correr en la pc
de Algarve. Voy a tener que hacer algunos ajustes para eso. En estos últimos 20 minutos, armemos el esqueleto
de la idea de lo que quiero mostrar, mañana lo mando a correr esto mientras voy mirando alguna que otra pregunta
que me parezca más valiosa.

------------------------------------------------------------------------------------------

04/06/2024

Estoy armando la presentación de mañana. Estoy viendo que tengo bastante para mostrar como trabajo,
no tanto como resultados positivos. Siento que buena parte del problema es que estamos mirando
combinaciones de preguntas que dan terrible. Igual vamos a charlarlo con Pablo y ver qué opina al respecto.

No lo encontré a Pablo. Intentemos mejorar los resultados. Para eso hagamos lo siguiente:
1) Corregir el tema de los gráficos de histogramas, que la distancia anotada sea un número con
dos cifras significativas.
2) Aumentar un poco más la distancia de los labels en el gráfico de la superficie 3d.
3) Asegurarme que la distancia de JS graficada se grafique con hasta dos cifras significativas, sino se chocan
los números con las palabras.

Esas últimas dos cosas las puedo dejar para después y ahora ponerme con la parte de buscar pares de preguntas
que me resulten más interesantes.

Ok, estoy sinceramente estancado, tengo que hablar con Pablo para ver qué opina. No sé exactamente cómo encarar
esto.

Necesito una discusión conmigo mismo para organizar mis ideas. El plan es contar a la gente de GOTHAM que hicimos
TODO lo que charlamos la última vez. Normalicé los gráficos, armé histogramas 2D, removí el elemento central de las
distribuciones de las encuestas, hice cálculos de las distancias tanto para casos sin el elemento central como sin
la cruz central. De esto puedo concluir que se puede trabajar ambos casos casi indistintamente, no dan muy distinto.

También considero que no es necesario mostrar seis preguntas, es un montón de bardo y gráficos, con tres estamos más
que hechos. Realicé algunos ajustes, y la verdad los resultados para mostrar son un poco feos.
Estoy teniendo un problema por un lado de que me está quedando los mínimos muy cerca del borde de la
región de ajuste, entonces el valor de Cos(delta) que ajusta está dando mal. No sé si convendría simular
un poco para ese lado cosa de que esos datos ubiquen correctamente el mínimo en 0 o si debería más
bien imponer que el mínimo valor de Cos(delta) sea cero.

Estoy pensando, ¿Tengo una buena respuesta sobre cuál es una distancia chica respecto de dos gráficos?
¿Cómo mido eso rápido? Podría tomar una distribución en dos ejes que arranque igual e ir aumentando
su diferencia migrando todos los agentes a un sólo lugar y ver cómo me da eso. Eso lo puedo probar de
hacer ahora y ver de graficarlo como para tener una idea qué tal da la distancia entre gráficos.

Los ajustes dan un poco más lindo si no encierro tanto el ajuste. Démosle un poco de espacio, quizás
esta ajustando mucho sobre una zona plana.

Hablé con Pablo, organizamos bastante la charla. Me dijo que en vez de mostrar los que más se parecen
y los que menos, muestre el que más se parece y el décimo que más se parece.

------------------------------------------------------------------------------------------

07/06/2024

El 05 estuve preparando la charla con la gente de España. A la mañana tuvimos la reunión de grupo.
No estuve en la pc para anotar lo que charlamos en la presentación. Problemas de internet.
Después de la charla me reuní con Pablo y empecé a armar un cálculo de tiempo de simulación que iba
a tomar el armar el barrido en los espacios de parámetros.

El 06 llegué tarde porque tuve problemas para arrancar el auto. Después también tuvimos la charla
de Diego. No llegué a terminar el cálculo del tiempo de simulación, pero casi.

Hoy a la mañana terminé el cálculo del tiempo de simulación de ambos espacios de parámetros. El
barrido no resulta fino, es algo que tendremos que discutir.

Después me puse a estudiar un poco de alemán.
Lo siguiente que voy a hacer es enviarle a Hugo un mail sobre cómo es el cluster que tienen, cuántos
hilos tienen y cuántas cosas podríamos mandar a correr.

------------------------------------------------------------------------------------------

09/06/2024

Hoy lo que quiero hacer es mandar a correr en las pc's de la facultad el nuevo barrido que hablamos con Pablo.
Para eso, ya que también le voy a pedir a la gente de GOTHAM que mande a correr esto, creo que es importante
modificar el formato de los archivos de salida, cosa de que pesen lo menos posible. Para eso, en vez
de devolver el estado final del sistema, voy a hacer que devuelvan la clasificación de opiniones. Voy
a hacer que además no escriban ni las opiniones iniciales ni la variación promedio. Voy a dejar el dato
de la semilla y la matriz de adyacencia, por si acaso.

Estoy mirando la forma en que se construye la distribución de mis distribuciones de opiniones finales, y me
parece que la forma en que se construye con la función de Clasificación NO es igual a cómo se construye
la distribución de la encuesta. Me parece raro, porque los había comparado y había visto que eran iguales.
Bueno, había entendido todo mal, soy un gil. No puedo ser tan pelotudo. Efectivamente las distribuciones
se arman distinto, la que tengo hecha de las simulaciones está traspuesta respecto a la de las encuestas.
Corrijamos eso ahora. Y estemos atentos a cuál es la forma correcta de hacer esto.
Lo corregí en Python, ahí lo corrijo en el clasificador de C también.

Bien, ya lo armé y funca bien por lo visto. Ahora lo voy a poner a correr en las 3 pc's. Voy a asegurarme
de mandar a correr el espacio que charlamos con Pablo.

Estoy mandando a correr en cada pc 20 simulaciones, por lo que tendré en total 60 simulaciones. Lo que estoy
barriendo son las regiones que etiqueté como B+C+D+F+G+H. La región E la dejo para barrerla al final.

Lo mandé a correr en Algarve y Coimbra, en Oporto no porque faltan 3 simulaciones de lo de los Zealots para
terminar. Faltan dos para el peso siempre boludo. Bueno, si tengo suerte, antes de irme a dormir puedo mandar
a correr en Oporto eso que falta.

------------------------------------------------------------------------------------------

10/06/2024

Lo primero que hice en la mañana es mandar a correr desde Oporto las 20 simulaciones que
faltaban para completar 60. Las últimas 40 voy a ver si se las puedo pedir a Hugo.

¿Qué debería hacer hoy? De lo que tengo anotado como primordial, ya mandé a correr simulaciones
en la pc de la facultad y modifiqué la salida de los datos para que los archivos sean lo más
livianos posibles.

Como prioritario me queda hacer:
1) Realizar ajustes con los conjuntos de simulaciones más similares, armando un ranking agrandando
el conjunto de a poco.
2) Armar un archivo con el análisis teórico hecho para pasárselo a Hugo.
3) Charlar con Capuzzi sobre el cluster de Dirac.

El trabajo interno quizás lo iré revisando ya el miércoles o jueves. El martes podría hacer
lo del análisis teórico. Hoy me pongo con el punto 1 totalmente. Antes que exactamente eso,
lo primero que voy a hacer es organizar el código, hacer que se vea más prolijo, agregar las
funciones al archivo de funciones generales y si todo queda más lindo, ahí hago lo que dijo
David que se arma en dos o tres líneas.

Lo que tengo que hacer es borrar la parte de laburar borrando el centro, sino que tengo que
acomodar para que la función trabaje con preguntas de seis respuestas.
 En la función hice que la distribución de la encuesta siempre salga como una matriz de 6x6.
Independientemente de si lo que recibe son preguntas de 7 respuestas o preguntas de 6 respuestas
o mezclado.

No terminé esto, pero vamos bastante bien. Mañana veré de terminar esto.

------------------------------------------------------------------------------------------

11/06/2024

Estuve trabajando sobre la función que realiza los mapas de colores de forma tal que trabaje
sobre preguntas que tengan seis o siete respuestas y para que además arme los gráficos que hablamos
ayer con Pablo.

Voy a probar que funque bien, que pueda trabajar con un par de preguntas de 7x7, 6x7 y 6x6.
Por lo pronto está corriendo, así que eso es bueno. Ahora me voy a poner a hacer lo que sigue,
que es mandarle un mail a Hugo con los archivos para correr las simulaciones.
Estoy corrigiendo muchos pequeños errores con esto, y eso me distrae del laburo. Es sólo eso,
nada más lo que me distrae.

Armé un mail lo más prolijo que pude y le envié a Hugo con los archivos para simular, así
como una explicación de qué hacen y lo que espero que haga. Veremos lo que me contesta mañana
y eso.

------------------------------------------------------------------------------------------

13/06/2024

El 12 no anoté nada porque estuve trabajando en el google drive para armar la presentación
de el análisis teórico realizado. La idea era terminar eso el 12 para mandárselo a Hugo.
Logré terminarlo y programé el mail para enviárselo a Hugo temprano.

Hoy en la mañana me puse a estudiar un poco de Alemán. Ale nos contó que nació su beba.
Eso significa que el Lunes no vamos a jugar la partida.

¿Qué voy a hacer hoy? Primero, debería mandar a correr lo que calcula la Distancia Jensen-Shannon
y arma gráficos con promedios de conjuntos cada vez más grande. Pongámosle un nombre. Ranking
de promedios de distancias de Jensen-Shannon.

Hasta ahora no hablé con Capuzzi por el tema de los clusters de Dirac. Tengo que hacer eso hoy si
me lo cruzo en el aula Federman.

¿Qué resultados tengo para mostrar? Hice los gráficos de ranking de promedios de distancias
Jensen-Shannon. Lo que tendría que hacer ahora es lo que me decía Pablo, de intentar ver
cómo se componen los estados del ranking. La pregunta es, ¿cómo lo hago?

La idea es que yo tengo mi matriz de Distancias JS, que su número de filas es la cantidad de Cos(delta),
su número de columnas es la cantidad de Betas, y su tercer coordenada es la cantidad de iteraciones.
Para cada simulación, que se identifica con una combinación de estas tres variables, ubico su
distancia JS en un lugar de esta matriz. Yo quiero agarrar un conjunto de estas simulaciones, ordenados
en distancias de menor a mayor, a ese conjunto quiero identificar qué estados son y obtener algún gráfico
que visualmente me indique qué estoy viendo.
 Ponele que estoy mirando las primeras 10 simulaciones, y quiero que arme dos gráficos de frecuencias de
estados. Uno con lo que es el estado más probable, y otro con el segundo más probable. Se entiende por
más probable el que aparece más veces en TODO el espacio.
 Tengo una idea de cómo hacerlo, vuelvo a recorrer todo el espacio de parámetros, uso la matriz que tiene
las distancias JS y en cada vector asignado a una combinación de parámetros Beta, Cos(delta), busco el
décimo elemento ordenado de menor a mayor y me quedo con las iteraciones ubicadas en las posiciones
de los elementos cuya distancia sea menor o igual a la del décimo elemento. Luego, construyo mi matriz
con las frecuencias de esos estados. Una vez hecho eso, voy contando cuántos estados tengo y listo.
También veo de armar un gráfico de frecuencias de estados y palo y a la bolsa. Planazo.

La siguiente pregunta es: ¿Meto esto también en la función de cálculo de distancias JS? ¿Debería separar
esa función en nuevas funciones? Lo meto en la función, siento que separarlo sería un problema en
sí mismo porque cada una de esas funciones nuevas necesitaría que les pase un montón de cosas, sería
un bardo en sí mismo.

#################################################################################################
#################################################################################################

Lo pensé de nuevo, puedo hacerlo en partes separadas. Pero creo que mejor lo dejo para la próxima eso.
Lo voy a hacer después de la próxima reunión. O en el finde quizás.
.) La idea es que la primer función returnee la matriz ZZ de distancias Jesnsen-Shannon.
.) Armo una segunda función que arme los gráficos de ranking de promedios de distancia JS.
.) Armo una tercera que grafique la simulación más similar y la menos similar. Para eso voy
a tener que agregar de forma externa el cálculo del Dic_total que surge de la función de 
Diccionario_metricas. La idea es que eso lo hago una sóla vez, por fuera del for de cada par
de preguntas.

TODO esto, después de la próxima charla.

#################################################################################################
#################################################################################################

Tengo que guardarme la matriz ZZ así como viene originalmente, así que voy a tener que agregar
una nueva matriz que sea la ZZ_sorted.

Arranqué con esto, mañana lo resuelvo y empiezo a armar la presentación.

------------------------------------------------------------------------------------------

14/06/2024

Primero hice lo de armar los gráficos de Frecuencias de estados para los dos estados más dominantes
en el espacio de parámetros. Ahora estoy intentando lograr que funcione, porque estoy teniendo unos
problemas de tamaños en el archivo, no entiendo bien por qué.

Hecho eso, ya me puedo poner a armar la presentación. ¿Qué voy a mostrar en la presentación?

.) Se me ocurre que puedo arrancar mostrando las preguntas a considerar. Ya lo vimos antes, 
pero para recordar, en especial ahora que estamos fijándonos en las preguntas sin la cruz
del centro.

Termino esto mañana.
##############################################################################################

Por algún motivo raro, el código que hace el mapa de colores de FEF para los dos estados predominantes
está teniendo un problema en un caso particular. Por alguna razón para los valores de Beta=0.4 y
Cos(delta) = 0.1 pareciera que al calcular la Distancia Jensen-Shannon, todas las distancias dan lo
mismo. RARO. Voy a intentar printear esa "fila" del vector ZZ y ver qué pasa ahí.

------------------------------------------------------------------------------------------

15/06/2024

Estoy en casa intentando hacer funcionar el código que arma los gráficos de Frecuencia de Estados
Finales rankeados de las dos distribuciones más dominantes. Estoy teniendo problemas con las matrices
construidas, pero no sé por qué y tarda mucho el código para poder mostrarme cuál es el problema.

Puedo seguir hardcodeando mis problemas, pero hay muchas chances de mandarme cagadas. Mejor me pongo
a revisar las cosas de a poco. Voy a desarmar el código de mapa de colores de Distancia Jensen-Shannon
de forma de correrlo una vez y empezar a trabajar con la matriz ya construida de forma más fácil.

La idea es que la función devuelva la matriz de Jensen-Shannon, después otra función con eso grafica
el mapa de colores, otra arma los ranking y una tercera hace la parte de las simulaciones predominantes.
Haré eso entre mañana y el lunes.

------------------------------------------------------------------------------------------

16/06/2024

Armé la función que construye la matriz de Distancia Jensen-Shannon y la returnea.
Algo que estoy notando es que quizás convenga definir cuál es el código x y el código
y por fuera de estas funciones. Mejor hacerlo en el código de Graficar.

------------------------------------------------------------------------------------------

17/06/2024

Logré separar el código en tres partes. Lo cuál es un golazo. Lo siguiente es ver si puedo
descubrir el error que tiene para abrir la matriz. Si puedo hacer eso, puedo revisar entonces
qué es lo que está pasando que falla en el armado de los gráficos de FEF.

Luego de bastante revisar, al final el error que tenía era una boludez, simplemente pasa que
estaba pasando un float para ubicar filas de un array. La cosa está funcionando ahora. Lo que voy
a hacer ahora es volver a mandar a correr las cosas las pc's de la facultad. Y también voy a mandar
a correr las funciones de Graficación en Algarve, para tener los gráficos hechos a partir de las
simulaciones de 10000 agentes.

.) En Algarve voy a mandar a correr todo a partir de Beta=0.9. Así que después tengo que completar
la segunda simulación de Beta=0 a 0.8.
.) En Coimbra, la primer simulación se terminó y estaban en la segunda. Así que ahora mando todo
a partir de Beta=0.3.
.) En Oporto voy a mandar a correr todo a partir de Beta=1.1. Así que después tengo que completar
la segunda simulación de Beta=0 a 1.

------------------------------------------------------------------------------------------

18/06/2024

Estoy armando la presentación para mañana, ya tengo varios de los gráficos. Tengo que ver
de mandar a hacer gráficos de histogramas con los 10000 agentes. En especial porque necesito
un gráfico de un estado de transición para mostrar.

Como de costumbre, Pablo me tiró una idea de qué hacer ahora, que es un bardo de rearmar. Veamos
qué podemos hacer de acá para mañana. Si tengo esto resuelto para una o dos preguntas, estoy hecho.
La idea es mirar el estado promedio. Juraría que cuando hicimos esto, lo que se veía era una cagada.
Debí haber recordado eso cuando charlaba con Pablo.

Tengo que considerar adaptar el armado de los histogramas 2D de opiniones para que acepte el caso de
que las preguntas tengan 6 respuestas en vez de 7.

------------------------------------------------------------------------------------------

19/06/2024

Notas de la reunión:
-------------------

.) El gran dilema es si deberíamos tomar pocas cantidad de simulaciones o no al hacer
los análisis. David propone que deberíamos complementar el análisis de pocas simulaciones
con un segundo análisis indicando la composición de estados en el espacio de parámetros.
.) Método cuantitativo, tomar las distancias, ver la dispersión de distancias. Podría dar una
idea de la comunidad de distancias.
.) Armar un histograma de distancias de Jensen-Shannon. La idea es ver si se pueden conseguir
histogramas que indiquen comunidades.
.) Gráfico de probabilidad de encontrar una configuración en función de su distancia. Esto sería
el primer paso para algo mejor, que es un segundo gráfico que tenga para cada combinación de
parámetros, la probabilidad de encontrar comunidades de distancias similares.
.) Nos están comentando sobre el trabajo con la persona esta, Pablo Etchenique. Es un trabajo
en que analizan las ideologías 

Luego de la charla me puse a cocinar y mi intención era estudiar Alemán. No estudié un carajo.
Cuatro horas se me fueron entre cocinar, limpiar la cocina, comer y cosas. Definitivamente fue
mucho tiempo. No sé qué pasó.

------------------------------------------------------------------------------------------

22/06/2024

Revisé las pc's, las simulaciones casi terminaron hoy, mañana podría mandarlas a las regiones que
faltan. Oporto podría mandarla hoy. Mañana lo que puedo hacer es revisar un poco
el código y ver de armar algo que construya los histogramas de distancias de Jensen-Shannon.

Tener algún argumento para charlar con Pablo sobre si tomar más o menos simulaciones. Revisar
las otras preguntas para tener más info qué conversar. Podría también considerar actualizar
las documentaciones.

------------------------------------------------------------------------------------------

23/06/2024

Algarve todavía no terminó, mañana mando a correr cosas ahí. Esto es lo que tengo que mandar
a correr nuevamente. Ignorando la región 

.) En Algarve voy a mandar a correr todo a partir de Beta=0.9. Así que después tengo que completar
la segunda simulación de Beta=0 a 0.8.
.) En Coimbra, la primer simulación se terminó y estaban en la segunda. Así que ahora mando todo
a partir de Beta=0.3.
.) En Oporto voy a mandar a correr todo a partir de Beta=1.1. Así que después tengo que completar
la segunda simulación de Beta=0 a 1.

En Coimbra se terminó todo, así que ahora tengo que mandar en la región chiquita que faltaba.
En Oporto falta una buena parte de la segunda simulación, ahí la mando a correr.
Ya mandé a correr todo. Ahora me voy a poner a estudiar un poco de Alemán.

Arranqué a construir una función que arme los histogramas en el punto de distancia mínima. El
problema con eso es que ese punto medio depende de la cantidad de simulaciones que tome. Y hacer
un histograma con 10 simulaciones no tiene mucho sentido. Necesito definir bien qué critero voy a tomar.
Eso lo haré mañana charlando con Pablo. Y también debería tener un buen argumento sobre si tomar
muchos o pocas simulaciones. Igual posiblemente lo mejor sea hacer lo que dijo David,
hacer los dos análisis en simultáneo al mostrar los resultados.

------------------------------------------------------------------------------------------

24/06/2024

Algarve todavía no terminó, así que habrá que ver de mandar a correr cosas el miércoles
o algo así.

Volviendo al tema de los histogramas de distancias, me parece que lo mejor es arrancar con
histogramas de distancias en los puntos de mínima distancia promedio, utilizando 100 distribuciones
para el histograma.
 Ahí tengo armados estos histogramas. ¿Expando la región que observo? Me parece que hacer un histograma
de cada punto en el espacio de parámetros es un montón. Una gran pregunta es después cómo encontrar
máximos o cosas así. Pero para saber qué quiero buscar, voy a necesitar revisar un poco qué forma
tienen los histogramas obtenidos. Quizás quiera revisar ciertos percentiles o cosas así.

Si hoy no llego a reunirme con Pablo, siento que podría ponerme a revisar un rato el tema de
por qué mi código va tanto más lento que el de Hugo y la gente de Gotham. En cuanto logre armar
los histogramas hago eso.
 Viendo los histogramas, tengo un gran pico con distancias grandes, y un pequeño conjunto
de estados con distancias pequeñas. Voy a tener que ver cómo reconocer esos conjuntos de
datos. También considerando que por ejemplo en el caso del par de preguntas no-políticas,
la distribución de distancias es simplemente un único pico.

Ya revisé el código que tengo en el src. Corregí la función de Clasificación para que funcione
correctamente. Ahora puedo empezar a jugar con esto para intentar ver qué es lo que está funcionando
mal. Hice una corrida de 10000 agentes con 500 pasos, tardó 11 minutos y medio. Probemos con 1000
agentes. Esto tarda 139 segundos. Puedo intentar trabajar con esto para intentar reducir los tiempos
de simulación. Veré de trabajar en esto mañana. O quizás hoy lo mire un poco en casa, ya veré.

------------------------------------------------------------------------------------------

25/06/2024

Hoy a la mañana estuve estudiando Alemán. Después fui a cursar, volví de eso y me encontré con Nacho.
Terminado eso, intenté ponerme un poco con el código que hice yo, pero no tuve mucho tiempo. Revisé
de nuevo de a poco las cosas iniciales, es todo igual. Así que debería empezar a retocar el RK4 para
ver qué pasa ahí.

------------------------------------------------------------------------------------------

26/06/2024

En Coimbra tengo todas las simulaciones que quería resueltas. También tengo lo que me pasó Hugo,
puedo empezar a revisar de compilar todos los datos y simulaciones juntos.

En Algarve mandé a correr las segundas iteraciones, barriendo Cos(delta) [0.16, 0.5] y Beta [0,0.8].
Cuando eso termine, voy a tener que mandar el pedazo de región que falta, la región E. Que va
con Beta [1.1,1.5] y Cos(delta) [0,0.14].

En Oporto se están terminando las segundas iteraciones, barriendo Cos(delta) [0.16, 0.5] y Beta [0,1].
Acá también voy a tener que mandar el pedazo de región que falta, la región E.

Veamos de ir armando el conjunto de datos para revisar en Coimbra.

En la carpeta de Barrido_final puse los datos que tenía reformateados, para que coincidan con todos los
datos que vengo construyendo. Hay algo que podría ser un leve problema para el futuro, y eso es que
estos archivos no tienen un espacio final en los datos que sea una tabulación. Mis códigos están armados
contemplando eso. Pero creo que lo puedo solucionar fácil, tengo que considerar simplemente que lo
que levanto son los valores de las distribuciones, las cuales tienen tamaño 42x42. Entonces simplemente
puedo pedir que cuando construya la distribución, esta tome valores del array de 0:42*42 y listo.

Más problemas creo que me va a traer TODO lo demás, como el Diccionario_metricas o el graficado de los
histogramas 2D, los cuales ahora tendría que readaptarlos a las nuevas distribuciones. O, mejor idea,
puedo armar una función que a partir de las distribuciones que estoy observando, reconstruya las opiniones
de los 10000 agentes, de esa manera tengo ese array de opiniones y ya de ahí no modifico nada de todo
lo demás. Soy un genio. Suena como lo más sensato, en vez de cambiar todo el código, cambiar simplemente
eso.

Voy a mandarle un mensaje a Pablo para juntarnos, mientras termino de subir todos mis archivos a Coimbra.
Ya tengo armados los archivos reformateados de la región inicial. Ahora voy a subir lo que ya tengo
a Coimbra. Lo subo a Coimbra porque es ahí donde se terminó el barrido del espacio de parámetros que
queríamos hacer. Faltará combinar las cosas de Algarve y Oporto, cuando esas terminen de correr.

Hablando con Pablo, lo que charlamos es primero arrancar estudiando cuál es la composición de estados
en el primer cluster de distancias. También querríamos ver si el mínimo de las distancias promedio
se encuentra en el mismo lugar al tomar ese pequeño conjunto de distancias.

Arranco analizando la pregunta de Impeachment vs Wall with Mexico. Para esta pregunta considero las
distancias menores a 0.4. Eso es un pequeño conjunto de distancias. Lo primero que quiero hacer
es entonces estudiar la composición de esos estados.

Ahí armé en casa una buena idea del programa para mostrarle a Pablo, así que ya lo puedo dejar
y mañana lo concreto con los detalles finos, voy a tener que modificar los xticks y eso.

------------------------------------------------------------------------------------------

27/06/2024

Mirando todos los histogramas, por lo que observo, con pedir que las distancias de Jensen-Shannon
sean menores a 0.5, puedo revisar eso como criterio para poder revisar todos los pares de preguntas.
Siguen sin estar terminados los barridos en Algarve y Oporto.

Emprolijé los archivos de histogramas de estados en el conjunto recortado de simulaciones. Lo hice para
que se entienda qué corno está graficado. Además, agregué el armado de Mapas de colores de Distancia JS
con el conjunto de simulaciones elegido. Lo hice para poder observar si con ese conjunto, el mínimo de
distancia promediado se encuentra en el mismo lugar que el observado en los ranking de distancias.

Lo siguiente que tengo que hacer es aumentar los puntos en los cuáles miro los histogramas de distancias.

------------------------------------------------------------------------------------------

28/06/2024

Las corridas en Algarve y Oporto todavía no terminaron. Tengo que mandar a correr la parte que falta
en ambas pc's. Sigamos ahora con la parte de armar histogramas de distancias en puntos cercanos 
al punto del mínimo de distancia promedio. Para eso tomo una región de puntos cerca del punto
de tupla XX e YY.

Ya logré armar los histogramas de la región circundante del punto en el que está el mínimo. Lo siguiente
para hacer entonces es organizar esto un poco, porque tengo gráficos pero no es muy claro entonces
las conclusiones de eso. Con esto entonces lo que tenemos es la primer parte de lo que indicaba
Hugo, la idea de tener histogramas con la proba de obtener ciertas distancias. La segunda parte,
lo que nos decía Hugo que queríamos construir a partir de estos gráficos, no tengo idea de cómo
deberíamos armarlo. Me parece que habrá que charlarlo con Pablo para ver qué tal. Así que hoy
podría reventarme la cabeza por eso, podría retomar lo de ver el tiempo de simulación o
podría ir armando la presentación con estos gráficos. Yo diría de armar esa presentación el finde.

Estoy un poco confundido con los archivos que estoy construyendo. Más que nada mi confusión es si
estoy mirando correctamente el entorno del punto que quiero mirar al construir los gráficos
de composición de estados. Y esta confusión surge porque el array YY está como al revés. Eso
me está confundiendo un toque. Hagamos unas pruebas, después mando a correr cosas en Coimbra y
en Oporto, y después me iré para casa una vez definido todo. Luego el finde trabajaré un poco
en esto y en cosas de Alemán.

Mandé en Oporto las simulaciones de la región que faltaba. Lo de Algarve lo tengo que mandar
mañana. Mandé en Coimbra a correr el barrido en Beta-Kappa de la región de Beta [0,1.5] y
Kappa [0.5,10].

Miré lo que me confundía, ahora mismo estoy en la sensación de que me dejé confundir al pedo.
Si quiero mirar el Y que está adelante y el que está atrás, tengo que usar los puntos
tupla-1:tupla+2. Esto recorre los puntos (tupla-1,tupla,tupla+1). Entonces esto va a funcionar
bien así. Bien, creo que ya tengo lo que quiero, después mando eso a correr en Algarve. También
queda probar si mi idea de cómo armar los títulos va a funcionar bien. Veamos qué pasa con eso
después.

------------------------------------------------------------------------------------------

29/06/2024

Revisé, está corriendo todo. Lo de Beta-Kappa parece correr más rápido, quizás es una sensación.
Lo de Oporto está corriendo tranca, lo de Algarve todavía no terminó. Así que lo siguiente sería
mandar en Algarve a armar los gráficos que había planteado antes.

Ya mandé a correr el armado de gráficos en Algarve, mañana veo de armar alguna presentación
con eso.

------------------------------------------------------------------------------------------

01/07/2024

Estamos un poco contra las cuerdas. En estos casos de alta presión, lo mejor es descomprimir.
Después voy a tener que considerar si continuo el curso de Alemán 2 o no. La duda tiene que ver
con si voy a tener tiempo para rendir el final de la materia de Flujos de Mininni. Y es importante
rendir eso para pedir los puntos. Charlarlo con Pablo, aunque siento que la respuesta de
Pablo va a ser "rendilo y fue".

Hoy armemos una presentación rápida con lo que tengo para charlar con Pablo lo que vine
haciendo estos días.

Antes que nada, como en Oporto se terminaron las simulaciones de la región E, ya mandé el barrido
de Beta-Kappa de las simulaciones entre 20 y 39. Después en Algarve más tarde mandaré las simulaciones
entre 40 y 59.
 En cambio, en Algarve mandé las simulaciones en la región E. Cuando se termine eso, ya puedo empezar
a juntar cosas, más lo nuevo que volvió a mandarme Hugo. Y faltará lo último del código.

Los gráficos se ven interesantes, creo que hay cosas copadas para mostrar y a partir de ahí podemos
terminar de armar algo para el jueves. Me están faltando gráficos de Comp. de estados. Y hay algunos
de Promedios de estados que se ven raros. Revisemos el código y corrijamos eso.

Mandé a rearmar los gráficos de los cuatro pares de preguntas. Con eso voy a armar mi presentación
para mostrarle a Pablo lo que tengo armado. Digo yo que tengo algo razonable revisado. Después
tengo que revisar detalles del armado de los gráficos.
 Los gráficos parecen estar bien, sólo me queda raro que no se armaron algunos gráficos de comp. de
estados de otros pares de preguntas. Raro.

Hablando con Pablo, le parece que el trabajo está bien y lo que estoy haciendo sirve, pero es
poco. Revisando la semana, no me parece que realmente sea poco, pero no puedo evitar
la mala fama.

Mientras se arman los gráficos que necesito para mostrarle a Pablo el laburo hecho, me voy a poner
a reorganizar el código, mientras intento descubrir el problema del código. No lo entiendo. NO hace
los gráficos. No hay razón de por qué, pero no los hace. Tengo miedo de sacar el archivo actual que
grafica y hacer cagadas. Pablo me dijo que arme la presentación con esos gráficos y mañana charlamos
de nuevo.

Yo podría mandar a correr esto ahora, voy para casa y ya en casa me pongo a resolver lo que falta.
Lo otro que puedo hacer es mandar a correrlo, quedarme acá mientras eso corre y mientras eso se resuelve
estudiar alemán. Por último podría irme a casa más temprano y continuar el laburo desde ahí. Creo que voy
a hacer eso, así tengo en general más tiempo para armar esa presentación y mientras voy pensando qué
otra cosa hacer para el jueves que viene.

------------------------------------------------------------------------------------------

02/07/2024

Hoy a la mañana bajé los gráficos de comp. de estados que había armado y los puse en la charla
que le quiero mostrar a Pablo. Luego estuve estudiando Alemán, fui a cursar, creo que el examen
me fue bien y volví para agregar el par de preguntas de "Transgender Policy vs Refuse Same sex Service".

Hecho esto, se me ocurren tres cosas para hacer para agregar a la charla, algunas propuestas de Pablo,
otra propuesta mía.
1) Armar histogramas de los estados más y menos similares del conjunto de estados con distancias
menor a 0.45. Eso estaría bueno para comprobar que los estados tienen las formas que estamos considerando.
2) Hacer un nuevo binneado en el histograma de distancias. Esto me justificaría a tomar algún valor
intermedio de distancias y además podría servir para reconfigurar un poco más los histogramas. No suena
como un gran resultado, me gusta cómo se ven.
3) Revisar los histogramas de las regiones cercanas al mínimo de distancia Jensen Shannon. Eso podría servir
para ver cómo se comportan esas regiones, que darán posiblemente similar.
4) Armar un gráfico en el cuál se vea la fracción de los histogramas de distancia Jensen Shannon que tienen
una cierta cantidad de estados por debajo del criterio de corte de distancia. 

Hablando con Pablo, lo que me dijo es que dilucide un poco mejor lo que ocurre en ese histograma que construí.
Estas ideas que tengo de hacer, las dejos para después y mañana las charlo con Pablo. Me dijo que para mañana
tenga resuelta el histograma, complicado. Vamos igual a intentar resolverlo lo mejor posible.

Mandé a correr esos histogramas en la pc de la facultad. Si funca bien, lo mando a correr en Algarve.
Listo eso, voy a casa y quizás rankeo o mierdas. Después veo mañana de revisar alguna otra cosa que dijimos
con Pablo.

------------------------------------------------------------------------------------------

03/07/2024

A la mañana miré los gráficos de composición de estados. No sé qué se graficó, pero claramente no es
lo que quería ver. No entiendo cómo se graficó así o por qué. Mi sensación es que los arrays en el
zip son tales que uno de ellos tiene dos elementos nomás. No sé por qué.

Después fuimos a la recibida de Sofi. Muy lindo todo. Hay que preparar una reunión para la semana
que viene, alguna reunión de grupo, cosas.

Luego de revisar un rato el código, y charlando con Ale, encontré el problema de por qué los gráficos
se estaban armando mal. Ahora sí, la cosa va a funcionar. Mientras se resuelve el programa, me pondré
a revisar si tengo algo que hacer en la presentación, como para ir adelantando trabajo. Lo siguiente
será responder el mail de la gente de Uruguay. Y sino, ponerme con el armado del gráfico que se me ocurrió
a partir de los gráficos de histogramas.

Hice un cambio en el armado de los gráficos de histogramas para que se ajuste a la región graficada y que
la región que no tiene nada no se muestre.
 Lo que debería hacer es que se construyan histogramas en la región circundante al mínimo observado.
Eso creo que ahí lo armé, no resulta tan complicado por lo visto. Lo siguiente entonces sería intentar
armar ese gráfico que consideré antes, de fracción de histogramas que tienen X simulaciones con distancias
menor a 0.45. Aprovecho para agregarle una línea vertical.

Hablando con Pablo, va a ser importante revisar los puntos mínimos secundarios. Una paja armar eso, pero
podemos intentar. Luego de pelearme mucho con la idea, al final voy a armar los mínimos por mi cuenta, y
luego mandarle eso a la función para que revise esos mínimos. El primer número define la posición del y,
la cuál crece de arriba para abajo. El segundo número define el x. Ahí mandé a armar los gráficos de histogramas

Si todo funciona bien, debería armar histogramas de distancias en las regiones cercanas a los mínimos
y los gráficos de comp. de estados sólo sobre los mínimos designados. Con eso tengo los gráficos para construir
los histogramas en esas regiones que queremos mirar. Lo que quedaría quizás es armar el gráfico que estaba
considerando. Veamos si podría construirlo.

Lo mandé a correr en la pc de la facultad, ahora debería funcionar bárbaro esto. Tuve que poner un max en
una parte para que no se salteara algunos gráficos el armado de gráficos de los histogramas de distancias.
También agregué el armado del gráfico de fracción de histogramas en función de cantidad de simulaciones con
distancias menores a la distancia de corte.

------------------------------------------------------------------------------------------

04/07/2024

Cosas charladas:
----------------
1) Armar histogramas con binneados más chicos.
2) Hay que definir si es mejor elegir un conjunto chico de simulaciones
o si tomamos un corte de distancia y nos quedamos con las simulaciones que haya. (o no).
3) Lo que Hugo proponía es hacer un gráfico que en el eje Y tenga el número de estados 
y en el eje X el promedio de las distancias de los estados que haya (o no) debajo del
criterio de corte de distancia.
4) David propone armar dos mapas de calor. Uno con el promedio de distancias de lo que haya
(o no) por debajo del criterio de corte y otro con la fracción de simulaciones que hay
en cada uno de esos puntos.

Sobrevivimos a la charla, la idea es armar estos gráficos que charlamos pero con más
preguntas. Pablo dijo 20, veamos si podemos hacer con 10 y de ahí vamos construyendo la presentación.

Lo primero que quiero hacer ahora es ponerme a ordenar un poco los archivos. Tengo algunos cambios
que hice en la pc de Algarve que quiero corregir los archivos locales. Después puedo mandar a armar
los gráficos enteros, todo de nuevo. Por último, tengo que leer el paper de Sebas para juntarme a
charlar con Lucio mañana.

En Hist2D se construye el Dic_total. Podría ver de construirlo por fuera de las funciones. En especial
porque es indistinto de cada pregunta considerada.

------------------------------------------------------------------------------------------

05/07/2024

A la mañana llegué y me puse a trabajar con Lucio. Repasamos el paper de Seba, revisamos
ideas y fijamos como objetivo preparar para la semana que viene un google Colab en el cuál
simulemos el modelo de Granoveter con agentes y de ahí ver de quizás agregar el término de
pérdida de memoria de los agentes.

Ahora que estoy en la pc, debería empezar a revisar de construir los gráficos que hablamos con Hugo
y David. Si esto funca bien, lo siguiente que puedo hacer el lunes es ya mandarlo para múltiples preguntas.

Primero voy a armar el google Colab que hablamos con Lucio. Hecho eso, lo que sigue es revisar cómo vienen
las simulaciones. Está todo corriendo. Como Ale mandó a correr cosas, ahora todo va a tardar más. Ponele
que dentro de una semana reviso de nuevo cómo está esto.

Ahora sí, a armar el gráfico que quiero hacer, el que me propuso Hugo y David. La idea es tomar los histogramas,
fijar un valor que sea el criterio de distancia y tomar todas las simulaciones que sean menores a eso para calcular
su valor medio de distancia y además calcular la fracción de simulaciones que estoy mirando en
cada punto. Haré varios de estos gráficos variando el criterio de corte.
 De paso, antes que nada, voy a probar duplicar la cantidad de bines en el histograma de distancias. Creo
que duplicar es la cantidad adecuada. Más bines que eso sería una cantidad cercana a la cantidad de simulaciones.

Ahí armé un código, que si funciona bien, construye efectivamente esos gráficos que David me dijo que arme.
Veremos qué tal, si tira errores o qué. Igual, creo que por hoy ya estoy listo.

------------------------------------------------------------------------------------------

06/07/2024

Mirando lo que está corriendo en las pc's, en Coimbra se terminó el barrido de simulaciones entre
0 y 19. En Oporto se están haciendo las simulaciones entre 20 y 39. Así que voy a mandar
las simulaciones de 40 a 69 en Coimbra, y después en Oporto mando las que van desde 70 a 99.

Mandé a correr las cosas en Coimbra del barrido Beta-Kappa. Mientras estoy descargando los datos 
de Beta-Cosd para hacer simulaciones en la pc con eso.

Parece que el código que arme funca bien, veré de mandarlo en cuanto se hayan descargado todos los
archivos y pueda probarlo. Mientras voy a ir mandando los mails y cosas que venía charlando ayer con
mi vieja.

Bien, logré armar los gráficos que decía David. ¿Qué es lo siguiente para hacer? Bueno, de lo que
charlamos tengo armado lo que me dijeron. Se me ocurren dos cosas:

1) Modificar el armado de los histogramas de distancias, hacerlos en el lugar del mínimo de los
promedios nomás, lo de ver componentes en otros lados, ahora, no me sirve.
2) Tengo que revisar pares de preguntas. Juntemos tántas preguntas como se pueda. Pensemos que si
llego a juntar unos 10 o 15 pares de preguntas, correr esto va a tardar posiblemente 6 o 7 horas.

Hice estas dos últimas cosas y mandé a correr esto en la pc de Algarve. No creo que sean todos buenos
pares de preguntas, pero hay como 40 pares de preguntas. Pablo va a estar feliz. Hasta que vea
que las preguntas son una paja, entonces ya no va a estar tan feliz. Veremos qué sale.

------------------------------------------------------------------------------------------

10/07/2024

Estoy en la facultad, bajé los archivos de los gráficos que hice. Son MUCHOS gráficos, MUCHAS
preguntas. No sé si siquiera son preguntas interesantes o que valga la pena revisar. Visto que esto
funca, podría intentar armar primero una presentación con las tres preguntas principales y de ahí
agregar el resto, una vez que tengo una buena idea de lo que quiero hacer.

Revisé lo que está corriendo en las pc's del cluster, está funcando todo. Quizás el viernes da para mover
cosas. También me anoté en el congreso que nos dijo Pablo. Del Hostel no me respondieron, así que tengo que ver
de volver a preguntar ahí o preguntar en el de Casa Copada. Tengo que ver de comprar los pasajes del Buquebus.

Hoy a la tarde me gustaría ponerme con lo que charlamos con Lucio. Después debería ver de dedicar un momento
para armar funciones que levanten las distribuciones y no las opiniones. Así como dedicarme a ver lo de por qué
el código de Hugo va más rápido que el mío. Eso lo veré después seguramente. Ahora a comer.

Traspasé la mitad del código. No fui tan efeiciente como me hubiera gustado.

------------------------------------------------------------------------------------------

11/07/2024

Descargué en la pc de casa las imágenes que hice en Algarve. Ahora voy a ver de armar una presentación
con esa info lo mejor ordenada posible.

Ya armé la presentación para cinco preguntas. Mañana la idea es juntarme con Lucio y arrancar charlando
del paper de Lorenz-Spreen. O ver cómo está el collab. Quizás la reunión de mañana no sea tan larga.

------------------------------------------------------------------------------------------

12/07/2024

A la mañana me junté un momento con Pablo, charlamos ideas de cosas para modificar y corregir en los
gráficos que estoy armando. Las ideas para modificar son:

1) Sacar las líneas rojas verticales de los histogramas. (Ya corregí eso en el armado de los histogramas
de distancias)
2) Tengo la cruz que marca el mínimo en las distancias de JS. ¿Necesito sacarlo? Creo que no, no parece
que sea un problema
3) Ver los histogramas de mínimos de distancia en los puntos de mínimos.
4) Modificar en el promedio de distancias la barra de colores, para que no se sature lo graficado.
5) Mostrar la composición de los estados en los diversos histogramas de distancias.
6) En los gráficos de similitud, quitar la clasificación de estados. Va a achicar el tamaño
de los títulos y además justamente es algo que no venimos prestándole mucha atención.
7) Utilicemos el mismo código de colores para los gráficos de promedios de distancias según 
criterio de corte que para los promedios de distancias total.

Voy a poner los cambios en el código. Terminado eso, completaré el formulario de la SICSS.
De paso, ya se terminó el barrido en el espacio Beta-Cos(delta) que estaba haciendo en Algarve.
Ya puedo mandar un barrido en el espacio Beta-Kappa, o alguna otra cosa ahí.

Siento que van a ser muchos los gráficos de composición de estados. Por ahora no los voy a armar.
Ahí mandé a correr todo en Algarve. De ahí veré qué tengo y qué construyo. Voy a mandar a hacer
los gráficos de composición de estados. Después los separaré en otra carpeta manualmente.

Dejé corriendo los gráficos, tendré que ver qué hago en la carpeta de Algarve.
El lunes armo la presentación con los nuevos gráficos.

------------------------------------------------------------------------------------------

15/07/2024

Hugo me pasó hoy temprano los archivos que simuló. Ahí los pude descargar. Le tengo que responder
que descargué los archivos sin problemas. Después los intentaré mirar un poco a ver si encuentro
algún problema.

Estoy revisando los archivos para ver dónde los estoy juntando. Por lo que me estoy dando cuenta,
no junté archivos en ninguna pc. Yo diría de juntar todos los archivos en la pc de Coimbra. Después
los archivos de Beta-Kappa los voy a juntar en Oporto. Bien, parece que todo está correctamente
juntado en Algarve. Hermoso. Veré si mañana puedo mandar a correr algo como para empezar a armar
mapas en esa zona.

Armé una buena parte de la presentación, preparé cuatro preguntas para eso, corregí los gráficos
que se veían feos. Creo que fue un día razonable. No sé si bueno, razonable.

------------------------------------------------------------------------------------------

16/07/2024

Me levanté y no pospuse la alarma, pero costó salir de la cama. Llegué a la facultad, hablé con
Pablo y me puse a revisar la presentación. Hoy quiero resolver cuatro cosas:

1) Completar la sección de la última pregunta
2) Armar el gráfico de cómo se agrupan las preguntas en el espacio de parámetros que
observamos antes. Podría hacer eso superponiéndolo al gráfico que tengo del espacio de
parámetros que caracterizamos para 1000 agentes.
3) Armar un gráfico parecido a ese pero con un criterio de corte según los clusters de
distancias. Eso requeriría que lo mire un poco más a ojo, pero es algo que podría armar
a partir de los gráficos que tengo. Repito que tendría que aclarar que no está hecho
de forma automatizada, sino que es un poco a ojo.
4) El inicio de la charla, agregarle dos diapositivas para definir bien las preguntas que uso
y cómo las ordeno.

Ahora me voy a poner a estudiar un cachito de Alemán y después me iré a la clase de Alemán más
tarde.

Volví a la tarde. Ya completé la sección de la última pregunta. Queda quizás completar el desglose
de las distribuciones de la cuarta pregunta, pero no creo que valga tanto la pena.

Ahora voy a seguir con el punto 2, el gráfico de cómo se agrupan las preguntas en la región del espacio
de parámetros. Ponele 3 o 4 preguntas por cluster. Si llegas a cinco preguntas por cluster, sos un
genio.

------------------------------------------------------------------------------------------

17/07/2024

Soy tan boludo que no comitee el laburo que hice ayer en la facultad. Por suerte igual no
fue la gran cosa, no va a ser muy problemático el merge.

Ideas de la charla:
-------------------

1) La distancia JS tiene problemas para detectar los estados de Consenso Radicalizado.
2) El modelo no está logrando replicar estados con tres picos.
3) Otra opción es la distancia de Kolmogorov-Smirnoff. Puede servir para identificar mejor
los estados de Consenso Radicalizado.
4) Probar rehacer el último gráfico mirando sólo un 10% o 20% de estados más similares.
5) Permitir que el modelo clasifique por sí mismo las preguntas y no seamos nosotros los
que definimos cuáles son políticas y cuáles no.
6) Ver algunas preguntas de encuestas viejas para ver si se van moviendo en el espacio de parámetros.

Para facilitar los gráficos, Pablo me propone que:
-------------------------------------------------

1) Agregue sobre los márgenes de los histogramas 2D de las encuestas, debería agregar los histogramas
1D de los cuáles surgen las distribuciones de encuestas.
2) Cambiar los colores de graficado para que se observe mejor los contrastes. Me propuso usar una escala
que arranque con blanco en el cero y crezca hasta el negro en 1.

¿Qué hago ahora? Lo primero que se me ocurre es intentar armar un texto para la encuesta de lo del 
instituto de verano de Uruguay. Así ya mañana llego, veo de sacarme unas fotos después de comer y ya
cargo eso.

Después veo el tema de habilitar la tarjeta de crédito de la VISA y veo el tema de poder hacer el
espermograma en un laboratorio más cercano que el de Avellaneda. Por último, me pondré con el laburo
que estamos haciendo con Lucio, primero continuando el traspaso del código de Sebas. Mañana quizás pueda
ver de hacer el barrido que hablábamos con Lucio.

------------------------------------------------------------------------------------------

18/07/2024

Llegué a la facultad, no muy temprano. Mergee los archivos. Me puse a mirar lo que hizo Lucio con el
código de Granovetter. Tengo algunas dudas del código, pero en principio funciona y la idea está.
Me confundió un poco lo de que los agentes deben interactuar o con otros agentes o con el campo externo.
Pero la idea es razonable. En la ecuación se obtiene el punto fijo a partir de la suma de las contribuciones
del término de la probabilidad acumulada y de la cobertura. Pero en la evolución lo que se representa
es que los agentes se pueden enterar de las noticias por sus vecinos o por leer del tema en los medios.
O pueden al no enterarse por ningún camino, decidir desactivarse.

Hoy estoy trabajando poco eficiente. Tengo muchas cosas por hacer pero no estoy metido en ninguna.
Lucio me dió una mano, me sacó una foto y cargué los datos en la encuesta de la SICSS.

¿Qué trabajos tengo para hacer?

1) El trabajo con Lucio sobre el modelo de Granovetter. Estaría bueno caer con una idea más clara
sobre cómo meter la competencia de tópicos en el modelo. Yo pensaba en hacer algún barrido o
cosas, pero creo que no es principal eso ahora, puede esperar a la próxima reunión.
2) El trabajo con la gente de GOTHAM. Venimos bien, la idea es rearmar el gráfico de distribución
de preguntas en el espacio de parámetros. También debería ver lo de probar usar la distancia de Kolmogorov-
Smirnoff para ver si eso registra mejor los estados que son más bien consensos radicalizados.
3) Tengo que ponerme a ver los videos sobre programación en R y leer el libro que proponen en la página
del SICSS.

Voy por un café, me voy a poner a leer un poco el paper para lo de mañana y así llego más preparado
para la charla. Bien, me anoté cosas, creo que estoy en buena idea para mañana.

Voy a hacer dos cosas más y después me voy a casa. Primero voy a imprimir el boleto de viaje a Uruguay.
Después voy a ver el tema de laboratorios más cerca de casa como para hacer el estudio del espermograma.

------------------------------------------------------------------------------------------

19/07/2024

Llegué maso temprano, organicé algunos mensajes. Ahora me voy a poner a ver cosas sobre codear en R.
Nos juntamos con Lucio para seguir trabajando en el proyecto del modelo de Granovetter. Armamos
un código que contempla dos tópicos, que corre dentro de todo bien. Consideramos que lo que está
haciendo el código no refleja quizás lo que queremos, pero estamos encaminando. Eso va bastante
bien.

Hoy voy a intentar resolver dos cosas. Lo primero es lograr que el código levante los datos de las
distribuciones y desde ahí corra todo los mismo que viene laburando. Lo segundo es seguir viendo 
algunos videos de codear en R.

La idea es que tengo 42x42 puntos. Cada uno de esos puntos tiene la fracción de agentes. Esos
cuadrados tienen por lado 2/42. Entonces la idea es reconstruir un vector de opiniones a partir
de esta distribución. En el punto [0,0], la idea es que están las opiniones que se encuentran entre
[-1,-1+1/21] para X y [-1,-1+1/21] para Y. Ok, se me ocurre que lo que podría hacer es armar un array
con los valores medios de cada caja. Luego en función de la posición en la distribución, me construyo
mi array final.

Ahí armé la función. Estoy viendo de agregar eso a la parte de Barrido_final. Aunque creo que va a ser
más higiénico si simplemente copio los archivos de funciones y graficar que tengo en Comparación datos
y ya arranco desde ahí. Va a ser un bardo y mucho tiempo perdido al pedo sino.
 Bien, ahí parece que está todo. Confío en que ahora esto funca correctamente. Hace falta probarlo.
Yo diría de intentar construir algunos gráficos de histogramas 2D, como para ver que tenga sentido.
Claramente, no está teniendo sentido. Esto es un bajón. Veré si puedo hacer que tenga sentido antes de
irme el martes. No sé cuándo lo haré igual. Un re bajón.

------------------------------------------------------------------------------------------

22/07/2024

El finde estudiamos con Lucio sobre las materias de los finales que queremos rendir. Hoy terminé de
ver el bootcamp de R y ya me puse con la función que reconstruye opiniones a partir de las
distribuciones finales.

Ahí corregí los errores de la función. Voy a incorporar eso a la función general para ver que se hacen
bien las distribuciones y ya mando a correr esto. Ya lo incorporé, funca bárbaro. Bueno, lo siguiente entonces
es definir qué gráficos necesito del espacio.

Gráficos importantes:
---------------------

1) Entropía en el espacio de parámetros
2) Covarianza en el espacio de parámetros.
3) FEF en el espacio de parámetros
4) Gráfico manual de regiones
5) Distancia JS en el espacio de parámetros
6) Hist2D similares en mínimos de promedios de Distancia JS
7) Histogramas de las distancias JS en los puntos mínimos
8) Composición de bines de los histogramas
9) Mapas de colores de promedios de distancia y fracción de estados promediados
según una distancia de criterio de corte.

Ya incorporé todo esto en el armado de gráficos, e incluso me encargué de reducir ciertas partes para que
no tarde tanto, específicamente reduje el calculado del diccionario de métricas y el cálculo de la entropía
reiterado.
 Funciona bien esto, ya puedo mandarlo a correr en Coimbra con los datos que tengo ahí.

Mientras, mandé a correr las últimas 10 simulaciones del barrido del espacio Beta-Kappa en Coimbra.
Ya con eso, no quedará nada más por correr. A menos que querramos ser más finos en nuestro barrido,
que eso es algo discutible.

Imprimí algunos documentos que necesitaba. Mandé a correr el armado de archivos en Coimbra y eso presenta
un problema. Los archivos que armé en la región fuera de la región pequeña: Beta [0,1] y Cosd [0,0.15],
tienen un tab extra al final de la distribución, que los archivos que construí yo no tienen. Tengo que solucionar
eso de forma de que o todos los archivos tengan el tab o ninguno lo tenga.

Por otro lado, hablando con Pablo, coincidimos en que la idea sería armar el gráfico que ubica las preguntas en
el espacio de parámetros según dónde se encuentren los mínimos para el total de las simulaciones y para un
conjunto de 20 o 30 simulaciones. Esto se puede hacer sencillo, total es pasarle el conjunto de preguntas a la
función, calcular los mapas de distancias JS y luego que vaya graficando. Va a ser una función que tarde mucho en correr
porque tiene que calcular todos los mapas de distancias. Pero supongo que se puede hacer.

------------------------------------------------------------------------------------------

02/08/2024

Ya volví de la SICSS. Estuvo muy bueno. Ahora tengo que ocuparme de dos cosas claves. La primera es
que tengo que anotarme en lo de CAPES. Lo segundo es seguir laburando en el laburo del modelo de agentes.
Lo tercero que tengo que hacer ahora es repasar lo que investigué como para ver qué mencionarle a Pablo.

Me parece que lo clave de mencionarle a Pablo del SICSS es que conocí gente, que vi una info interesante
sobre la ética de manipular datos que refieren a personas, que descubrí data sets interesantes del
Latinobarómetro, CSES o Gdelt, y también que vi algo interesante sobre cómo armar encuestas.

Hablé con Pablo, le pareció interesante lo que mostré, ya seguiremos hablando más en la próxima semana.
Lo que quedamos es en posponer la charla de la semana que viene. Primero le mando un mail a Hugo sobre
eso y después me pongo con lo de anotarme al CAPES, a ver qué puedo hacer hoy.

------------------------------------------------------------------------------------------

04/08/2024

Ya identifiqué los archivos que tengo que corregir. Se encuentran en una carpeta que dice Beta-Cosd en el inicio
de la pc de Coimbra. Esos mismos los tengo descargados en mi pc de casa. Lo que voy a hacer ahora, con la ayuda de
Chat GPT, es colocar un tab al fondo de esos números.

Bien, parece estar funcionando ahora. Lo veré más tarde a ver si quedó bien.

------------------------------------------------------------------------------------------

06/08/2024

El 05/08 fue el DDF. Hoy vamos a ponernos con el trabajo de la gente de España, intentemos organizar
un esqueleto de presentación. Pero antes de eso, ¿Qué es lo que tengo que hacer de trabajo?

1) Preparar presentación para la reunión de la próxima semana con la gente de GOTHAM.
Tengo que implementar las cosas que me dijeron en la última charla.
2) Continuar con el trabajo de Granovetter que estábamos haciendo con Lucio. Revisar
las notas en el Drive para ver cómo continuar eso.
3) Preparar presentación para la próxima reunión de grupo sobre las cosas que aprendí o
vale la pena contar en el grupo de mi viaje a Uruguay.
4) Completar presentación para la presentación de Brasil de Mova La America.

Hoy voy a continuar con la implementación de la presentación de GOTHAM, a la tarde continuo
un poco con la presentación de Brasil. Bien, me descargué un conjunto de los archivos con 
el espacio de tab al final de las distribuciones. Lo que debería hacer ahora es por un lado
armar los mismos gráficos que armé en el espacio Beta-Cosd, para el espacio Beta-Kappa.
Luego de eso, lo que haré será analizar los gráficos armados para ver qué pongo en la presentación.
Mirado eso, lo tercero que haré hoy será continuar con la presentación de cosas para la
beca de Mova La America de Brasil.

------------------------------------------------------------------------------------------

08/08/2024

El 07 estuve todo el día trabajando en completar los documentos que necesitaba para la inscripción
del programa de Mova la América de Brasil. Lo bueno es que ya terminé con eso, así que eso es un
laburo hecho. Tengo que empezar a despertarme más temprano, hoy llegué re tarde. No puedo seguir
así.

Lo que voy a hacer ahora es primero descargar los gráficos que armé de los dos espacios de parámetros.
Lo segundo que quiero hacer es armar una carpeta en la cuál guardar los archivos de composición de estados,
así no me ocupan tanto lugar en mis carpetas.
Lo tercero es armar una función que grafique los mínimos de cada par de preguntas en el espacio de parámetros.
Lo cuarto sería agregar lo que me dijo Pablo de poner los histogramas de las preguntas en los bordes de los
histogramas 2D.

Bajé los gráficos. Como cosas rápidas, observé que en el espacio de Beta-Cosd y Beta-Kappa algunos gráficos
de distancias JS recortados se construyeron vacíos, no entiendo por qué. Lo otro que noto es que en el
espacio Beta-Kappa algunos gráficos del histograma 2D más similar me dan nulo. No comprendo por qué, tendré
que revisarlo. Una tercer observación es que las regiones que había delimitado antes para las simulaciones
con 1000 agentes parecen haberse movido un poco. No pareciera ser un problema eso, tendré que ver
de redefinirlas para la próxima reunión.

Lo primero que yo haría ahora es revisar por qué se generaron ciertos gráficos vacíos. Hecho eso, lo siguiente
sería armar la función que grafica los mínimos en el espacio de parámetros como charlamos la última vez.

------------------------------------------------------------------------------------------

09/08/2024

Hoy llegué más temprano. Viste que las amenazas sí funcionan.

Cuestión, ayer me volví temprano a casa y aún así tardé horrores en llegar, no pude hacer nada.
Hoy tengo que ponerme a descular qué corno estoy viendo y a armar el gráfico este de los mínimos
de los pares de preguntas en el espacio de parámetros. Eso va a requerir que catalogue el tipo de
preguntas que estoy viendo. No, cierto que el plan era que nosotros revisemos cómo se agrupan
y de ahí determinar si son preguntas políticas o no. Voy a necesitar construirme una tabla
con la info de las preguntas y guardarme eso, sino no se me ocurre cómo retener esa info en un
gráfico.

Vamos anotando las cosas a revisar. Empecemos por el mapa en el espacio Beta-Cosd:
1) La entropía está mal. (Modifiqué la función que calculaba la entropía)
2) La covarianza se ve rara. Pero le creo, se parece bastante a lo de antes.
3) Los gráficos de Fracción de estados finales parecen estar muy bien.

Necesito revisar la forma de los gráficos en diversas regiones. Y ver qué pasa con la entropía.
Ya ví qué está mal, estaba ploteando la varianza de la entropía y no la entropía. La varianza
tiene la forma que tiene que tener. Pasemos a lo siguiente, armar algunos gráficos para revisar que
efectivamente lo que veo es razonable. Los gráficos de histogramas los voy a guardar en carpetas
aparte.

Ya tengo esos archivos, están en la carpeta de distribuciones. Genial.
Lo siguiente que me genera dudas es:
1) ¿Por qué algunos gráficos de mapas de colores recortados me quedan los gráficos en blanco?
2) En el caso Beta-Kappa, tengo problemas con los gráficos de Histograma 2D de los estados
más similares. Por algún motivo, me quedan vacíos.

Ya revisé por qué algunos de los gráficos de distancia JS recortados están vacío, el problema
es que la dist_lim que elegí es 0.45, pero algunos gráficos tienen distancias por encima
de eso, así que cuando quiero hacer el corte de cantidad de simulaciones en el punto de
distancia promedio mínima, resulta que en ese punto ninguna simulación tiene distancia menor
a dist_lim, por lo que intenta plotear con una matriz vacía.
 Igual me doy cuenta que por lo que charlamos, no es ese el gráfico que quiero hacer ahora,
sino armar gráficos con una pequeña fracción de agentes. Así que voy a comentar este tipo
de gráfico y depués descomentar los gráficos de ranking de distancias JS.

Estoy revisando los gráficos de Hist_2D de las simulaciones similares a las distribuciones de
las encuestas. Todos los gráficos que tienen problema son los gráficos con K = 0.5. Quizás
hay un problema en los datos ahí. Aunque la fracción de estados finales parece estar en
cooncordancia con lo que esperaba ver.
 Ahora entiendo por qué están mal los gráficos de histogramas similares. De nuevo, el código funciona
bien, el problema es que remueve a los agentes que se encuentran en la cruz central. Y justamente
cuando K = 0.5 resulta que TODOS los agentes están ahí. Se me ocurre que eso se puede solucinar
cambiando el código para el caso Beta-Kappa de forma que si el PARAM_X <= 1, entonces omite esa
parte. Ahora igual eso me deja dudas, ¿Cómo corno arma el mapa de distancias Jensen-Shannon si esa
parte la saca?
 Hablé con Pablo. No hace falta que me preocupe por esto, al final no voy a hacer nada de comparación
con datos en el espacio Beta-Kappa. Y debería mandar a correr datos en las pc's, total están bastante
al dope actualmente. Después voy a tener que revisar bien qué quiero mandar y donde. La cosa es tener
cuidado de cómo expando la región.

Hagamos las correcciones al código de Beta-Kappa, subamos los dos códigos, mandemos a correr y después
intentemos armar el gráfico de las preguntas ubicadas en el espacio de parámetros.

Modifiqué las funciones de Histogramas 2D y de gráficos de Comp_estados, para que esos gráficos vayan
a carpetas aparte. Esas cosas me construyen MUCHOS gráficos.

El código para la región Beta-Cosdelta está, preparemos el código de Beta-Kappa.

Ya están los dos códigos cargados y todo corriendo. Esperemos que no se corte. Posiblemente sea buena
idea la semana que viene revisar un poco la documentación.

¿Qué cosas tengo para hacer ahora?
----------------------------------
1) Esa función que vengo prometiendo que asigna las preguntas en el espacio de parámetros según dónde
están los mínimos de la distancia JS.
2) Agregar los histogramas 1D en los histogramas 2D. Va a ser un tema eso, no muy simple en el sentido
de que voy a tener que revisar cómo incorporar esa parte del código en varios códigos. Bah, en el que
construye los gráficos de histogramas de las encuestas, en los otros no.
3) Revisar el tema de la distancia de Kolmogorov-Smirnoff. Estaría bueno tener aunque sea leído eso,
si no pude hacer mucho al respecto.
4) Revisar alguna pregunta y graficarla para ver cómo varía en el tiempo. Quizás esto lo podamos dejar
para la otra reunión.

Construyamos la función que ubica las preguntas en el espacio de parámetros. El problema de esta función
es que va a tardar mucho, porque tiene que calcular la matriz de DJS para cada par de preguntas de nuevo.
Bueno, hagamos una cosa. Arranquemos con hacerlo funcionar. Después lo que puedo ver de
hacer es guardarme esa info en su momento cuando armo por primera vez la matriz de DJS
y así no la recalculo cada vez.

Está básicamente armada la función. Hay que probarla para ver que realmente funciona.
Por hoy vamos a casa, comitteemos todo y listo.

------------------------------------------------------------------------------------------

12/08/2024

Hoy me levanté tarde, no entiendo por qué. La mañana básicamente se me arruinó. Vamos a intentar
armar todo lo que tengo que armar lo mejor posible. Estoy corriendo el pedazo de código que quiero
ver si construye el gráfico que quiero de las preguntas en el espacio de parámetros.
Efectivamente está tardando un buen rato la simulación. Debí haber probado con cinco preguntas
más o menos, como para arrancar. Mientras esto corre, tengo dos cosas que puedo hacer. Una es
mandar a correr en Coimbra, Oporto y Algarve las simulaciones que me faltan. Eso podría venir
bien total voy a estar esperando este resultado.

Lo segundo es ya agrandar este código para que se vea bien con las simulaciones con un porcentaje de
las preguntas. Me conviene hacer ya simulaciones con hasta 40 simulaciones.
 ¿Tengo una forma de guardar los datos de las matrices? Porque sino estoy corriendo esto montones
de veces y me tarda mucho en hacer el gráfico. Veamos cuánto tarda en hacerse eso, que tengo miedo
que tarde una eternidad. Además tengo que agregar el cruce de preguntas y por último tengo que
además lograr extraer qué preguntas caen donde. Bah, eso lo puedo hacer a ojo con los mapas de colores
de distancias JS.

Lo mandé a correr a las 11, son las 15 y todavía no termina esto corriendo en casa. Voy a necesitar
ser listo en cómo mando esto a correr. Primero, me parece que lo principal entonces es hacer lo que
charlamos, armar este gráfico con todas las simulaciones y con hasta 20 simulaciones. Algo que estaba
pensando, voy a tener que agregar ruido en el eje X y en el Y para que los puntos se vean diferenciados,
sino no voy a ver cuántas preguntas hay en cada lugar. Sólo habrá una pregunta si no meto el ruido. Lo que
voy a hacer es obtener una distribución centrada en cero con un sigma que sea un cuarto de la distancia
entre puntos. Eso me parece importante porque el 95% de los números obtenidos de la muestra van a estar
en 2 sigmas, entonces el 95% del ruido se va a encontrar a la mitad de la distancia entre puntos. Eso
me ayuda a que no se me corran preguntas en un punto con preguntas en otro punto.

Lo otro que pensé es que tendría que armar csv con las matrices de distancias JS. De esa manera, voy a
poder correr esto mucho más rápido. Sino la verdad que el tiempo que tarda en correr esto está escalando
demasiado y cada pequeño error puede costar horrores.

Bien, agreguemos el ruido y el tema del armado del gráfico para menor cantidad de simulaciones.
El gráfico terminó en mi pc. Se hizo, tardó casi 5 horas. Habrá que ver si tarda más o menos en
la pc de Coimbra.

Se me ocurrió cómo hacer esto de forma más rápida para tener en el mismo tiempo de corrida los gráficos para
una cantidad reducida de simulaciones. Voy a construir los vectores X e Y para todas las simulaciones en
el mismo for, así esto no tarda 24 horas, tardará 10 más o menos. Y eso es una victoria.

Ya está corriendo y está agregado el tema del ruido y de que se armen los gráficos con un subconjunto
de simulaciones. Ahora puedo mandarlo a correr en Coimbra.

Lo siguiente que quiero hacer entonces es mandar a correr datos para el espacio Beta-Cosd en las tres pc's.
Aunque Ale está usando mucho Coimbra, un poco Algarve y nada Oporto. Tendré que ver cómo reparto código en
las tres pc's. Pero para hacer esto tengo que asegurarme que tengo el código correcto Y que voy a mandar
las simulaciones a la carpeta correcta. Eso es importante porque si mezclo las nuevas simulaciones
con el armado de datos, va a ser un bardo. Un importante bardo.

Los archivos que tengo que agregar al final los voy a ir guardando en la carpeta Extras_Beta_CD.
Considerando que Ale está laburando bastantes cosas, yo diría de mandar a correr símplemente unos 5
hilos, para resolver 20 iteraciones en esta pc.

Lo que estoy haciendo es armar un barrido más fino en Beta, por lo que la idea es que Beta corra
entre [0,1.5] de a 0.05.

¿Qué iteraciones corro en cada pc?
----------------------------------
1) En Coimbra tengo 5 hilos que van a correr cada uno 4 iteraciones, por un total de 20 iteraciones entre
0 y 19.
2) En Algarve tengo 10 hilos que van a correr cada uno 4 iteraciones, por un total de 40 iteraciones entre
20 y 59.
3) En Oporto tengo 10 hilos que van a correr cada uno 4 iteraciones, por un total de 40 iteraciones entre
60 y 99.

Bien, ya mandé a correr cosas en las tres pc's. Mañana me pongo con lo de agregar los histogramas a los bordes
de los histogramas 2D. Y si veo que es necesario, me haré el armado de los csv con la info de las matrices de DJS.
No creo que para esta semana llegue con lo de revisar una pregunta que vaya evolucionando en el tiempo, lo dejaré
eso para la otra reunión.

Me parece bien cortar acá, ya tenemos las tres pc's laburando a full. Dentro de un mes posiblemente esté terminado
el barrido que les mandé. Lo bueno es que todas tienen que hacer 4 iteraciones, vamos a ver cuál termina más rápido.

------------------------------------------------------------------------------------------

13/08/2024

Llegué a la facultad. Ahora sí tengo miedo. Los gráficos importantes que quería mostrar, no están.
No salieron. Y parece que van a tardar un poco más. Estoy medio jugado. Va a estar para mañana.
Pero no me gusta llegar tan justo. En lo que eso se resuelve, aprovechemos el tiempo, resolvamos las dos
cosas que ayer me quedaron en el tintero. Primero, agregar los gráficos 1D en los histogramas 2D.

Bien, logré armar los gráficos como yo quiero. Éxito. Costó un poco, tuve que aprender a usar el Gridspec.
Aún así, logré en 30 minutos lo que me podría haber tardado 6 horas fácil. Ya cargué esos gráficos al
drive. Por si de boludo resulta que en casa esos gráficos nos los puedo armar.

Ahora voy a construir los csv con las matrices de distancia Jensen-Shannon. La idea es armar un csv que en cada
fila tenga cada uno de los arrays de la tercer dimensión de la matriz. Bien, el csv se armar correctamente.
¿Me encargo de ver cómo levantarlos? Bah, ahora no hace falta. Me encargaré de mandarlo a correr ahora en
Coimbra, y después veo qué hago mientras. Bien, ya está corriendo. Ahora yo tengo que ponerme a armar la
presentación con lo que tengo. Después, veré qué tengo para mañana y qué puedo hacer con eso.
Dios, necesito ayuda.

Empecemos con la presentación. Estaría bueno tener el gráfico con las regiones marcadas que hice a mano.
Lo primero que me parece que estaría bueno es contar cómo queda configurado el espacio de parámetros
para 10000 agentes. Eso lo puedo observar de los gráficos de Entropía, Covarianza y Varianzas.

El código del gráfico de preguntas distribuidas en el espacio de parámetros está tardando mucho más
de lo esperado. Esto me está volviendo loco. Debería haber tardado como mucho 15 o 20 horas, no 25.
Sólo me queda rogar que cuando llegue a casa esto esté terminado.

Mientras estoy armando la presentación. En principio me parece que tengo para mostrar algo, pero
no es mucho avance. Sobre lo que charlamos la última reunión básicamente no avancé. Lo que planeo
mostrar suena interesante en mi cabeza, no sé qué tan interesante resultará. Espero que funque todo
bien. Me queda leer un poco sobre distancia de Kolmogorov-Smirnoff. Veré si saco algo de eso,
como para no caer muerto a la charla y tener algo más de dónde tirar.

Mañana tengo que conseguir alguna simulación de Polarización descorrelacionada en el espacio
Beta-Cosd. Para eso tengo que pedir Beta = 1.1.

------------------------------------------------------------------------------------------

14/08/2024

Notas de la charla:
-------------------
.) Revisar si el problema de la clasificación es que los picos están poblados
de forma no uniforme.
.) La forma de la polarización puede ser importante de revisar. ¿Ha cambiado la distribución
de opiniones respecto al caso 1D? Es importante para destacar la importancia del análisis
2D.
.) Revisar el tema del test de Kolmogorov-Smirnoff.
.) Podría hacer un gráfico de distancia vs simulación para  ver que no tengo simulaciones
outliers al considerar las 20 simulaciones más similares.
.) Prob. de polarización vs Beta-Kappa. Si hay tiempo con ganas. Esto estaría bueno
para que el paper no esté en el vacío, sino vinculado con el primer paper.
.) Secciones del numerical recipes 14.3 y 14.7, creo. Es sobre el test de Kolmogorov-Smirnoff.

Numerical Recipes in C.

Algo que noté es que algunos de los gráficos de las distribuciones están armados al revés. Revisar
por qué carajos pasó eso.

Bien, ya terminó la reunión y baje tres cambios. Vamos a continuar con el laburo y organizar lo que sigue.
¿Qué cosas hacer? Podría descargar el libro que me pasó Hugo. mañana me pongo
a trabajar en la cosa que estamos haciendo con Lucio. Ya tengo las tres pc's laburando en realizar
más simulaciones, no necesito solucionar eso ahora. Lo que se me ocurre es que debería
hoy armar la función que levanta las matrices de DJS de los archivos csv y ver de modificar los
códigos para que tenga eso introducido. De esa manera, nunca más va a tardar tanto ese gráfico.
 Trabajando en esta función noto que esto me genera un cambio en la estructuración del trabajo.
A partir de ahora, en vez de armarme una lista de preguntas a considerar y tener esa lista en 
el código de Graficar, voy a relegar esa lista al código de Profunc. Una vez ahí, construiré la
lista de preguntas a considerar. Con esa lista de preguntas es la que trabajaré siempre. Y cada
vez que quiera revisar nuevas preguntas, agrego esas preguntas al conjunto de matrices que tengo.

Otra cosa que puedo hacer hoy es empezar a documentar cosas, porque debe haber varias cosas
perdidas en el laburo.

Estoy pensando que debería rearmar las matrices de DJS de forma tal que los datos guardados
tengan seis decimales guardados. Cuatro me parecen poco.

Bien, tengo el código que quería. Ahora a armar una función y reorganizar todas las cosas que
hacen uso de las matrices de DJS. Al final no reorganicé el resto de cosas. Queda para
después.

------------------------------------------------------------------------------------------

15/08/2024

A la mañana fui a hacer el espermograma. Y sin embargo, fue todo tiempo perdido, porque al
final no pude entregar las muestras. El día pasó, poco y nada hice todavía.

Lo que sí hice fue inscribirme en el concurso de ayudante de primera de física. Por suerte
es bastante simple el proceso ahora.

Lo siguiente que voy a hacer es reemplazar la parte de la función que usa los csv y reconstruye
las matrices de DJS. Después quedará para hacer mañana, o el finde, revisar las preguntas con
lo que estábamos charlando con Pablo. La forma en que las preguntas se distribuyen en el
espacio Beta-Cos(delta) para 100 simulaciones es radicalmente distinto que para 20 simulaciones.
Incluso parece realmente que está teniendo errores en cómo los clasifica. Lo que Pablo me propone
es ir mirando de a clusters y con eso ir armando un análisis robusto de lo que estamos viendo.

Ahí hice los cambios, creo que están bien. Terminé sacando el Dict_Anes que usaba antes. No probé
el código, habrá que probarlo pronto y ver si todo funca bien. Yo confío que sí.

Miré el código de lo de Granovetter. No avancé nada, pero por lo menos ya lo tengo leído y estoy
en tema.

------------------------------------------------------------------------------------------

16/08/2024

Hoy a la mañana fui a estudiar Alemán. A la tarde me junté con Lucio y charlamos del trabajo
de Granovetter. Estuvimos discutiendo bastante sobre cómo avanzar el trabajo, pero fue bastante
interesante el ir viendo las formas de encarar el laburo. Veremos cómo sigue. Estaría bueno
de mi parte resolver algunas cosas y llegar con algo ya estudiado para el próximo viernes.

No hice nada del laburo con la gente de España todavía. Antes de irme, voy a corregir la función
que hace el gráfico de la distribución de preguntas en el espacio de parámetros. Que justamente
es la función que no corregí. Y voy a probar que funque bien.
 Veremos si funca bien, en principio parece que sí.

------------------------------------------------------------------------------------------

18/08/2024

Tiró un error de una boludez que me mandé. Dejémoslo corriendo un poco y veamos si se corrige eso.
Hoy creo que no voy a hacer nada avanzar el código, pero vamos a pensar qué sigue. Lo que hablamos
con Pablo es revisar la distribución del espacio de preguntas por clusters. Entonces lo que tengo
que hacer es lograr ir trabajando esos clusters de a uno.

¿Armo una etapa nueva para revisar eso?
Nah, trabajemos dentro de la etapa de Barrido Final, no creo que valga la pena una etapa nueva sólo
por eso

¿Cómo diferencio las preguntas según cluster?
Podría armarme un Pandas y a partir de eso guardar esos datos en un csv. Tendría que guardar los códigos
de las preguntas, las preguntas y sus lugares de distancia mínima. Me gusta esta idea

Una vez que tengo las preguntas separadas, ¿Cómo las analizo?
Estaría bueno revisar que la clasificación esté teniendo sentido. Primero, podría revisar las distribuciones
de opiniones de cada pregunta, como para ver si son similares a ojo.
 Segundo podría ver cómo es el mapa de colores de distancia JS de cada pregunta.
 Tercero podría analizar cómo son los histogramas más similares en el punto de mínima distancia
 Cuarto podría mirar en los casos en que parecieran surgir dos Betas posibles los histogramas
de distancias JS. Con eso tendría una noción de si esas preguntas son posibles de clasificarse en dos
lugares distintos
 Quinto tengo que revisar qué corno pasa que para 10 y 20 agentes la cosa da tan distinto a lo esperado
en lo otro, no tiene sentido. Podría empezar revisando los mapas a ojo, ver que las distancias JS
graficadas sean coherentes con lo que tenía armado de antes. Daría la sensación que los está ordenando
para el culo, pero me resulta raro eso, está claramente el comando para ordenarlos.

Bueno, en principio estas cinco cosas diría para hacer mañana. Me parece que hecho esto estaría bien.
Hablar con Pablo sobre que tengo varias cosas juntas, que me tenga un poco de paciencia.

------------------------------------------------------------------------------------------

19/08/2024

No comitee lo que hice ayer. Soy un gil. Bueno, arranquemos con el laburo que me organicé ayer.
Primero veamos de armar los dataframes de los pares de preguntas.

Armé la función que arma el dataframe y lo pasa a un csv. Mi idea es bajarlo, revisar esos datos
y luego armar los histogramas de esos pares de preguntas. Perfecto, ya tengo separados los pares
de preguntas. Lo siguiente es armar una carpeta dentro de la carpeta de Barrido_final para el
primer cluster y analizarlo en detalle. Ver cómo son las distribuciones 2D de las preguntas del
primer cluster, los mapas de distancias JS de esas distribuciones, histogramas similares y 
histograma de distancias.

Bueno, estoy lentamente resolviendo este laburo. Mañana quiero tener vistos dos clusters. Sino
estoy yendo a un ritmo tortuga y Pablo me va a cagar a trompadas. Se suma además que tengo
que estudiar Alemán, armar la presentación del DDays y continuar el laburo del trabajo de Granovetter.

------------------------------------------------------------------------------------------

20/08/2024

Bien, ya tengo la tabla y tengo el cómo levantarla. Ahora tengo que armar gráficos y cosas
y separarlos según los clusters. Arranquemos con el primer cluster.

Estoy armando los gráficos y guardándolos en carpetas que tienen los valores de beta y cosdelta
para diferenciar los clusters. Lo primero que quiero revisar entonces es:
¿Está bien hecha la clasificación cuando miro pocas simulaciones ordenadas de menor distancia
a mayor distancia?

Algo que estaría bueno en ese caso es mirar los histogramas de distancias en esos lugares. Con algo
de suerte, si miro los gráficos de distancias de los pares de preguntas ubicados en un cluster,
puedo observar que comparten ciertos puntos de distancias mínimas. Luego reviso el histograma de
distancias en esos puntos.

Cluster de Beta=0.4 y Cosd=0
----------------------------

Mirando los mapas de colores de Distancia JS para 100 simulaciones, para 20 y 40 pareciera que
en prácticamente todas las simulaciones, está bien clasificado esto. Todos los pares de preguntas
oscilan entre (Beta=0.6,Cosd=0) y (Beta=0.4,Cosd=0).
 Se me ocurre que puedo armar histogramas de distancias en los lugares de mínimos usuales, que son
los dos de antes y en (Beta=0.5,Cosd=0.02).
 Lo otro que puedo hacer es agregar histogramas de las simulaciones en esos puntos en específico.
 Hay un par de preguntas que para 10 simulaciones su mínimo se encuentra en (Beta=0.6,Cosd=0.04).
Veré si puedo revisar otras cosas similares y de ahí decidiré si necesito más info.

Necesito entonces conseguir la info que me estoy planteando. Eso me va a ayudar a decidir si estas
distribuciones de pares de preguntas están bien clasificadas.

Primero, corrijo los histogramas 2D en esos puntos. LISTO
Segundo, corrijo los histogramas de distancias, que tienen que recibir varios puntos donde prepararse.
¿Debería considerar de armar esos gráficos en los mínimos de 20, 40 y 100 simulaciones? No, porque
hay gráficos que en todos los casos están en un sólo punto, entonces no me daría la info de todos
los lugares.

------------------------------------------------------------------------------------------

21/08/2024

Continuo con el tema de los histogramas de distancias. Me estoy frenando en lo que es armar la
lista para revisar los histogramas de distancias. Se me ocurrió usar los arr_param_x/y para identificar
el índice, y no ser yo el que tenga que ubicar dónde corno se supone que se encuentran esos valores.
Me parece lo mejor. Ya mandé a armar esos nuevos gráficos, vamos a ver qué pasa.

Hoy armé lo de los histogramas de distancias en esos tres puntos mínimos interesantes. Ahora con
eso voy a hacer un análisis de lo que estoy observando, y luego voy a ir al siguiente punto.

Cluster de Beta=0.4 y Cosd=0
----------------------------
Estoy mirando los gráficos. Puedo concluir las siguientes cosas.
1) Los gráficos de distribución de las encuestas muestran que los estados clasificados considerando
100 simulaciones son estados que son intermedios entre consenso radicalizado y Polarización 1D
con anchura. (No existen estados de consenso radicalizado puros en las encuestas)
2) Hay 33 preguntas en este conjunto. De esas 33, en TODOS los pares hay por lo menos una pregunta
del siguiente conjunto: [Benefits of Vaccination, Background Check for Gun Purchases, Vaccines in Schools,
Govt. Action About Opioids]. (No sé si son todas las posibles preguntas de esas 4 preguntas. No lo creo)
3) 33 preguntas acá significa un cuarto de preguntas sólo en este punto.
4) Las preguntas no parecen estar mal clasificadas, para todo subconjunto de simulaciones consideradas
estos pares de preguntas se encuentran ubicados en una región con Beta entre 0.4 y 0.6 y para Cosd
entre 0 y 0.02. Por lo que están todos en básicamente la misma región.
5) Mirando los histogramas de las simulaciones, se ve que los gráficos son similares a lo que me
indicaba los gráficos de FEF. Aparecen algunos gráficos de polarización descorrelacionada raros.
No sabría cómo explicarlos.
6) Los gráficos de histogramas más similares son todos gráficos de Polarización 1D, ninguno me aparece
de consenso radicalizado.

¿Debería armar un gráficos de distribución de preguntas en el espacio de parámetros para el cluster?
Sí, debería.


IMPORTANTE: Hay sólo 120 pares de preguntas en la carpeta de Matrices de DJS. Raro eso. Deberían ser
177. Veré hoy de mandarlo a correr de nuevo

Ya son las 19. ¿Cómo me organizo para estos días? ¿Con qué le caigo a Pablo? Creo que me va a mirar
y me va a cagar a trompadas fiero. No puedo irme a dormir con esto así, necesito revisar qué carajos
pasa en un cluster más por lo menos. Armemos la carpeta y arranquemos con eso. Primero mando el mail
para lo de los viáticos, después veo de seguir laburando un poco más.

¿Qué tengo que hacer en estos días? Pasó el martes y miércoles, laburé re poco. O mejor dicho, siento
que avancé re poco. Carajo, estuve mirando un montón de gráficos e intentando armar una forma de analizar
esto, no me parece poco. Mierda, mierda con todo.

Quiero ver lo que estábamos hablando con Lucio del laburo de Granovetter, no quiero caer con las manos vacías.
Después está lo de Alemán, quiero por lo menos tomar unas notas. Por último está preparar la presentación
para el Ddays. Digo yo que eso lo puedo ir charlando mañana con Pablo luego de por lo menos haber entrado
a la página.

Mañana a la mañana arranco con lo de Granovetter, después clusters y por último un poco de Alemán.
El viernes mando a correr la cosa para que los archivos de Matrices sean los indicados. No lo hago ahora
para no tener que revisar si se agregan nuevos gráficos que arruinen mi análisis del primer cluster.

------------------------------------------------------------------------------------------

22/08/2024

Descargué los archivos de los gráficos del cluster en Beta=0.4 y Cosd=0. Tengo que revisar eso después
y agregar análisis en otros clusters. Ahora me voy a poner con el estudio de Granovetter, más a la tarde
veré algo de Alemán.

Pablo pasó un rato a charlar, le conté qué onda. Quizás no contempla si venimos bien o mal, así que no
me cagó a pedos. Es IMPORTANTE que para el lunes que viene tenga bien revisado gran parte de los clusters.
Pablo me recomendó que ponga las regiones del espacio de parámetros en los gráficos, cosa que debería
efectivamente hacer, después agrego eso al código.

Estuve mirando el tema del laburo de Granovetter y también fui al coloquio, pero no pude prestar nada de atención.
Con lo de Granovetter, hice algunas notas, repasé algunas cosas. Creo que tengo para charlar cosas
con Lucio mañana y ya diría yo de ver de cerrar esta etapa y avanzar a algo más concreto. Pablo insistiría
con eso.

Me voy ahora a casa, veré si puedo estudiar algo de Alemán cuando llegue.

------------------------------------------------------------------------------------------

23/08/2024

Hoy a la mañana llegué a la facultad, me encontré con Pablo y ya nos pidió resultados de lo
que venimos haciendo con Lucio. También me propuso que la semana que viene armemos una propuesta
de las figuras con las que arrancar a escribir el paper. Así que es importante tener revisados
los clusters de acá al lunes. O por lo menos la mayor parte.

No me queda claro con Pablo cuándo se supone que armemos la presentación al Ddays. El martes voy
a empezar con esto, aunque sea voy a abrir la página y dejarme de joder.

A la mañana fui a cursar Alemán, fue bastante bien la clase. Me gustó. Ich Deutsch lernen gern.
Anoté bastante tarea, veamos cómo me distribuyo eso.

Después de comer me junté a laburar con Lucio. Avanzamos bastante y charlamos sobre el trabajo
de Granovetter y competencia de tópicos.

Ahora lo que voy a hacer es continuar con el análisis de los clusters de preguntas. Lo primero que tengo
que hacer es lo que Pablo me sugirió, de agregar las regiones en el gráfico de distribución
de preguntas. 

Veamos el tema de las preguntas, me tiene un poco loco eso. ¿Por qué son muchas menos de los esperado?
No es que son mucho menos que lo esperado, simplemente soy un gil y estaba calculando mal las combinatorias.
Efectivamente 120 son los posibles pares de preguntas que se pueden formar.

Mientras se resuelve el armado del gráfico para el cluster de Beta=0.4, Cosd=0, voy a ver de armar 
el gráfico con las preguntas completas pero mejor encuadrado y con las regiones separadas.

Algo que antes estaba pensando de las preguntas en el cluster Beta=0.4 y Cosd=0, es si estoy viendo
TODAS las posibles preguntas que se pueden formar con las 4 preguntas que aparecen repetidas en
todos los pares. En principio, tengo 9 preguntas "políticas" y 7 "no políticas". Entonces la pregunta
es cuántos pares puedo armar que tengan a esas 4 preguntas. De cada una, puedo armar entonces 
9+7-1=15 preguntas. Entonces el total de pares que puedo armar con esas 4 preguntas es 60-6,
es decir 54 preguntas. Ya que observé 33, la respuesta es que NO son todas las posibles de esas
4. Pero son bastantes. Esta clase de análisis es más complicado de hacer, me pregunto si hay
una forma fácil de hacerlo. Podría tomar la matriz y construir algún gráfico que indique cuáles son
las 5 o 10 preguntas más repetidas. Suena bastante razonable e incluso fácil de hacer eso. Lo puedo
incluso hacer en la pc remota, no necesito pasar a Coimbra esto, aunque no vendría mal.

El trabajo se puede realizar bastante bien de acá al lunes, para tener algo presentable e interesante.
Lo complejo va a ser condensar la info y tener algo bien claro que transmitir. Y leer lo de
distancia Kolmogorov-Smirnoff. Y armar la presentación resumen. Y armar la presentación de Ddays.
Y estudiar Alemán. Y llegar frescos para el viernes.

------------------------------------------------------------------------------------------

25/08/2024

Voy a revisar un poco algunos clusters de preguntas, a ver qué pasa.

Cluster de Beta=0.6 y Cosd=0
----------------------------
1) Mirando la distribución de las preguntas, las preguntas en este cluster para las 100 simulaciones,
se mantienen en la misma región y con opiniones similares para 20 o 40 simulaciones, así que parece
estar bastante bien.
2) Todos los histogramas más similares son de polarización descorrelacionada, por lo que eso explicaría
que identifique a estos estados como algo distinto de los anteriores.
3) Los mapas de colores de distancias JS están dando que en los puntos donde ubica el mínimo es similar
para cualquier subconjunto de simulaciones. En algunos casos ocurre que para todas las simulaciones hay otros
lugares que parecerían ser importantes, pero creeme, no lo son. En los gráficos de subconjuntos se
nota que esos lugares no pasan a ser comparativamente importantes hasta que no promedias muchos
puntos.
 

¿Se están armando bien los histogramas de distancias? Se ven raros. Están claramente mal. Vamos a mandar
a rehacer estos gráficos y ver qué pasa.

Hagamos eso y el lunes resuelvo lo otro. No quiero estar en esto el resto de la noche.

Los siguientes clusters que quiero mirar son los que tienen Beta alto, es decir 1.1 .
Hay tres clusters de estos, en Cosd=0.02, en Cosd=0.08 y en Cosd=0.14. Debería tener bien anotado
cuántas preguntas tengo en cada cluster. Lo puedo ver rápido levantando la tabla de datos, no es tanto
drama.

Voy a armar las carpetas y los gráficos ahora. Ya lo mandé eso, mañana reviso a ver qué corno pasó con todo.

------------------------------------------------------------------------------------------

26/08/2024

Estoy mirando el armado de los histogramas de Distancias de JS. Están mal armados, y creo que ya sé por qué,
y es porque estoy mandando mal los valores de la tupla. El motivo creo que es que estoy armando mal
la tupla que busca el dónde se encuentran los datos a graficar. Resulta que me estoy confundiendo el eje X
con el Y en el armado de la matriz. Siempre me dan paja estos problemas.
 Bien, ya parece que le encontré la vuelta a esto. Ahora vamos a graficar las cosas.

Hecho eso, lo siguiente es revisar los gráficos, agregar el análisis del cluster que falta y ya de ahí empezar
a ver cómo mostrar estos datos a Pablo. Yo arrancaría mostrando 

Me faltan armar los gráficos del último cluster, los voy a mandar a hacer mientras tanto. Ya tengo eso y también
tengo los gráficos de distrib. de preguntas. Hay un gráfico que sale mal. No sé por qué, creo que no vale la
pena preocuparse tanto por eso. Más me parece interesante revisar que están bien armadas las preguntas.

Las preguntas parecen bien armadas. No se me ocurre cómo cambiar los títulos para que sean más claros, pero están
bien. Listo, a seguir revisando esto y terminar el tema de las preguntas.

Cluster Beta=1.1, Cdelta=0.02:
-------------------------------
1) Mirando las distribuciones, puedo ver rápido cuál es el problema. Las distribuciones de las encuestas,
se intentan asemejar a estados de transición, pero en el fondo las opiniones están re dispersas. Entonces
cuando considera menos simulaciones, la distancia JS lo empareja mucho más a los estados de polarización
descorrelacionada con anchura, los cuales se asemejan a muchas de las distribuciones en definitiva.
2) Fijate que para bajas cantidad de simulaciones, las distancias mínimas están cerca de 0.2. Eso es
mucho menor que lo que observo con todas las simulaciones, que está más cerca de 0.5.
3) Podría armar los histogramas de distancias en los puntos: (0.02,1.1), (0.48,0.4) y (0,0.6)
4) También armemos histogramas 2D en esos puntos

Cluster Beta=1.1, Cdelta=0.08:
-------------------------------
1) Las distribuciones de estas preguntas a la vista no parecen muy distintas de las anteriores, pero
se nota una diferencia de que no tienen una "zona de mínimo" en la región de bajo Beta y alto Cosd.
Lo cuál me parece raro, porque si en realidad se ubican en un mayor Cosd debería entonces tener más
resonancia con esa región. Pero de nuevo, las polarizaciones descorrelacionadas con anchura son las
que se llevan todo porque al final es a lo que se parecen todas las encuestas.
2) Podría armar los histogramas de distancias en los puntos: (0.08,1.1) y (0,0.6)
3) También armemos histogramas 2D en esos puntos

Cluster Beta=1.1, Cdelta=0.14:
-------------------------------
1) En estas distribuciones se ve que tienen más agentes sobre la diagonal que por fuera. El hecho
de que empiecen a verse un poco distintas se nota en que la región de Beta bajo y Cosdelta alto
tengo una zona de mínimo clara para algunas preguntas cuando considero las 40 simulaciones más similares.
2) Para 40 simulaciones el gráfico de distribución de pares de preguntas muestra que se esparcen
mucho estas preguntas.
3) Podría armar los histogramas de distancias en los puntos: (0.14,1.1), (0.04,0.6), (0.48, 0.4)
4) También armemos histogramas 2D en esos puntos

Cluster Beta=0.4, Cdelta=0.48:
-------------------------------
1) A diferencia de la máquina, yo no veo por qué estas distribuciones son distintas a las otras. Eso puede
ser el por qué para pocas simulaciones esto VUELVE a caer en la región de Beta=0.6 y Cosd=0.
 Incluso en 40 simulaciones, están básicamente todos concentrados en la zona esa.
2) Podría armar los histogramas de distancias en los puntos: (0.02,0.6) y (0.48, 0.4)
3) También armemos histogramas 2D en esos puntos

Hagamos estos gráficos planteados, después arranquemos con una presentación y de ahí vemos qué sale con esto.

Puse a armar todos los gráficos importantes, eso en diez debería estar. Yo en un rato voy a estar yendo.
Me está frustrando esto. Llevo más de una semana con este tema. Quizás mi problema fue creer tan ingenuamente
que en quince minutos lo resolvía. ¿Qué me hizo tardar tanto al principio? Creo que separar los
datos y las preguntas, ver cómo tomar los conjuntos de clusters. Eso fue el problema al principio. Y
elegir los gráficos con info que pensé que iba a necesitar. Eso también.
 Estoy frustrado. Pasó una semana, apenas avancé, tengo que hacer la presentación del Ddays, estudiar
alemán, continuar con el armado de un resumen de los temas y otras cosas. Bueno, iré a casa, pensaré 
un poco en esto hasta subir al tren, y ahí me pondré con el libro y dejaré las cosas.

La conclusión que yo saco es que el problema es que la clasificación no es tan directa u obvia
como planteamos en un inicio. Los estados de polarización descorrelacionada parecen tener la dispersión
suficiente para parecerse a los estados de las distribuciones, las cuales no se parecen realmente a algo
en particular de forma tan clara. Eso está generando el problema. Mañana intentaré presentar esto a Pablo
y ya de ahí reorganizaré esto, le contaré lo que creo que pasa y veremos cómo sigue.

------------------------------------------------------------------------------------------

27/08/2024

Armé una presentación para mostrarle a Pablo en lo que va el tema de la distribución de preguntas. Fue
un bardo, muchos gráficos y bastante frustración. ¿Pero qué sacamos en claro?
 Creo que la conclusión a la que podemos llegar es que teníamos la esperanza que considerando todas las
simulaciones, los gráficos de distancia JS media dieran mínimos en distintas regiones del espacio de
parámetros. Eso sí ocurrió. Pero en los gráficos y preguntas que miramos también nos comimos un amague.
Y es que si miramos los subconjuntos de simulaciones más similares, resulta que las distancias más pequeñas
NO se encuentran donde se encuentran los mínimos cuando considero el conjunto entero de simulaciones,
sino más bien que se encuentran siempre en la región donde están las polarizaciones descorrelacionadas.
Al parecer todas las distribuciones de las encuestas más o menos se parecen a eso. Podría revisar que
efectivamente sea eso a lo que están pareciéndose más, si tomo las distancias mínimas rankeadas.
Sumemos eso a los gráficos, sólo para terminar de confirmar mis sospechas. Porque los histogramas
de mínima distancia dan todos gráficos distintos, pero es porque es lo que observan en el punto de mínima
distancia promedio considerando TODAS las simulaciones.

Hablé con Pablo para juntarme, no sé si hoy va a poder. Mañana tendré que charlar esto con él, después
pasar a siguiente tema, plantearle la urgencia sobre lo del Ddays, aunque lo único que se necesita
ahí es un abstract, armar un resumen de lo que venimos trabajando, ir pensando un planteo para el
paper y estudiar las cosas que Hugo me pasó para que estudie.

Armé ese pedazo de código, cuando llego a casa lo mando. Mejor rajo porque quizás no llego a entrenar.

------------------------------------------------------------------------------------------

28/08/2024

Charlé con Pablo. Me gané una cagada a pedo, pero no fue terrible. Le parece razonable mi propuesta.
Pablo me dijo que haga esfuerzos para que lo que voy a presentar se entienda mejor.
1) Mostrar las distribuciones de los estados en las regiones. Eso tiene que estar al lado de todo
lo que muestro
2) Agregar las distribuciones en los bordes de los histogramas de las simulaciones.

Ya salió la prueba de oposición para ayudante de primera. Tuve suerte, los temas propuestos de la prueba de
oposición son iguales a los de una prueba que ya tengo. Así que puedo mandar eso rápido y fácil. Más tarde
lo mando hoy. La verdad, el ejercicio está re bien planteado. Queda quizás agregarle info de 
Bibliografía recomendada.

A la tarde estuve estudiando alemán.

------------------------------------------------------------------------------------------

29/08/2024

Llegué temprano, vengo despertándome bien estos días. Magia. Me encanta. No sé de dónde salen
las ganas de vivir.

Lo primero para resolver es lo de agregar las distribuciones a los bordes de los histogramas en las
simulaciones. Bien, ya descubrí cómo resolverlo. Qué grande chatGPT. Bueno, creo que ahí está,
mandemos a correr todo de nuevo.

Hecho eso, hoy me gustaría tener hecho todo ese análisis sobre la clasificación de los pares de preguntas.
Debería también arrancar con la idea de definir cuáles son los gráficos que tengo y que vamos a mostrar.
Veré qué puedo resolver cosa de tener algo preparado para Pablo el lunes.

Estoy rearmando la presentación, creo que está quedando bastante bien y que mañana puedo tener eso terminado
y el resumen de lo que vengo laburado ya planteado. También podría sino mañana ponerme a leer lo de 
Kolmogorov-Smirnoff.

------------------------------------------------------------------------------------------

30/08/2024

A la mañana fui a la clase de Alemán. Después me junté con Lucio para ver un poco el tema del
laburo de Granovetter y preparar una charla con Pablo. Terminada la charla, me puse con la
presentación sobre la clasificación de preguntas. Lo terminé.

------------------------------------------------------------------------------------------

01/09/2024

Hoy mandé la prueba de oposición y me puse a leer un poco del test de Kolmogorov-Smirnoff.
No llegué a leer mucho.

------------------------------------------------------------------------------------------

02/09/2024

Hoy a la mañana costó levantarse. Cuando llegué, la puerta al pasillo estaba cerrada. Después
haciéndome un café se me rompió la taza. Ahora voy a intentar ponerme a leer cosas del
Kolmogorov-Smirnoff, a la tarde me pongo a preparar la presentación sobre lo que ya
tengo.

Leyendo lo que me pasó Hugo sobre el test de Kolmogorov-Smirnoff, mi primera duda es que
el libro propone que se necesita que la distribución a considerar no tenga más de un dato en
un mismo valor. ¿Esto es así? ¿O se puede armar distinto?

La idea en dos dimensiones es que te parás en un punto y partis tu distribución 2D en cuatro
cuadrantes. Calculás entonces la fracción de datos de tu primer distribución (las encuestas)
y de tu segunda distribución (las simulaciones) en cada cuadrante, y con eso calculás la diferencia
en cada cuadrante de esas dos medidas. Luego, hacés eso para todos los puntos. La máxima
diferencia que encuentres es una medida similar a lo que calculás en el caso 1D, que es la diferencia
de las distribuciones acumuladas.

Le mostré el laburo a Pablo, me dijo que le copó lo que vengo haciendo. Bueno, me alegro que
haya valido la pena. Me dijo que haga los siguientes cambios, que debería tener
para mañana terminados:

1) El gráfico de preguntas clasificadas en el espacio de parámetros hacerla por colores según
cluster. Tengo que ver cómo resuelvo eso.
2) Reducir el texto en los títulos de los gráficos. Empezando por los gráficos de preguntas
en el espacio de parámetros. Y poner en negrita el texto adecuado. Ver si puedo hacer
eso en el texto de plt.
3) Revisar que sea más claro cuando menciono los estados en las regiones, que se vea cuál
región es cuál. Podría agregar un grafiquito abajo como para recordar las regiones.
4) Reordenar las diapositivas para mostrar los dos casos extremos de pares de preguntas que
se mueven de una región a la otra. El resto tenerlo ahí por si preguntan.
5) Si tengo tiempo, podría intentar implementar lo de lograr que las distribuciones se muestren
rotadas. Al final no coincidí en consultarle a Pablo si mejor rotar o no las distribuciones.
Imagino que lo mejor es NO presentar un gráfico que se contradice consigo mismo a nivel fundamental.

------------------------------------------------------------------------------------------

03/09/2024

Llegué un poco sobre la hora, pero venimos bien. Lo siguiente es resolver las cosas que anoté
ayer. Empecemos por cambiar los colores del gráfico de preguntas clasificadas.

Arranquemos con algo simple, pasemos primero un diccionario cuyas keys sean las tuplas de
beta-cosd de los clusters y los valores sean los nombres de los archivos de ese cluster.
Ahí modifiqué la función que arma los gráficos de preguntas en el espacio de parámetros para
que reciba un dict de los clusters y de las preguntas en cada uno de esos clusters. Esto
es con el objetivo de que cada cluster se pinte de un color distinto.

Debería revisar que esto no me genere conflictos para después. El punto 2 también lo resolví
al mismo tiempo. Aunque tengo que revisar los conflictos de textbf.

Ya hice el punto 4. Y agregué unos gráficos de histogramas de distancias. No hice lo de rotar los gráficos
según las distribuciones. Debería ver de corregir eso para la próxima. Me parece que no es
tan terrible. Mañana a la mañana me pondré a repasar la charla para asegurarme de que estoy
preparado. En la semana tengo que estudiar Alemán, preparar la presentación del Ddays y
continuar el laburo de la parte del resumen. Aunque al mismo tiempo, voy a tener que hacer algo
nuevo. Creo que se están organizando las cosas, no es tan terrible. Si llego temprano hoy, voy
a ver si hago algo de estas cosas. Hoy no voy a hacer ejercicio, estoy muerto de sueño.
Y me quiero ir a dormir temprano.

------------------------------------------------------------------------------------------

04/09/2024

Ideas de las charla:
--------------------

.) Quizás podemos quedarnos con los estados clasificados en la región V.
.) Podríamos ver de aproximar los datos e idealizar las distribuciones. Reemplazarlas
por unimodales o bimodales.
.) Aplicar la distancia de Kolmogorov-Smirnoff y ver si eso es una solución.
.) Podríamos hacer limpieza borrando agentes según el tamaño de la caja mayor.
.) Habría que buscar primero una forma de definir que efectivamente tenemos
clusters de preguntas, que las distribuciones son distintas. Sino, estamos queriendo
encontrar cosas que no sé si están en los datos.
.) Hacer un análisis para detectar la región de transición entre la región II y la región
III. Debería salir haciendo el análisis. (Quizás lo hace Hugo)
.) ¿Qué pasa si colapso los datos en un histograma 1D? ¿Puedo mejorar el modelo 1D si 
utilizo los datos 2D?
.) ¿Cómo cambia la probabilidad de encontrar polarización al pasar a más dimensiones?
Estaría bueno hacer la comparación de proyección en 1D del modelo 2D con el modelo originalmente
1D.
.) Es importante hacer un puente de por qué vale la pena pasar a un modelo multidimensional.

Fui a la facultad, di unas vueltas, agregué al código el que los histogramas roten al graficarse,
cosa de tener las cuatro rotaciones y que eso me sirva para armar mejor los gráficos que quiero.

IMPORTANTE:
-------------------------
Mañana le tengo que pasar a Hugo todas las simulaciones que tengo, que me pidió que se lo pase.

------------------------------------------------------------------------------------------

09/09/2024

No sé por qué no anoté nada el jueves y viernes. Sé que no avancé en el tema del trabajo de
GOTHAM. Avancé un poco con el trabajo de Granovetter y con armar el abstract para el laburo
del Ddays.

A la mañana trabajé poco y nada, estuve re muerto. Mandé a correr el código con las rotaciones de
los histogramas similares. Eso funciona bárbaro. Ahora me voy a poner a revisar algunas documentaciones
y después sigo con armar la métrica de Kolmogorov-Smirnoff.

Revisé las documentaciones de imágenes y de archivos de Python. Ahora me voy a poner a armar lo de la
medida de Kolmogorov-Smirnoff. A ver si con eso podemos obtener mejores clasificaciones de los pares
de preguntas. La idea es no toquetear los datos en este proceso.

------------------------------------------------------------------------------------------

10/09/2024

Hoy estuve todo el día laburando en el tema de poder armar la medida de Kolmogorov-Smirnoff. Logré
armarlo en Profunc. Ahora que esto está funcionando, lo próximo que tengo que hacer es
armar primero una función que construya las matrices de distancia KS en el espacio de parámetros
para cada par de preguntas. Luego, con esas matrices, empezar a hacer los gráficos. Es importante
quizás ponerlo a prueba con dos o tres pares de preguntas, eso lo puedo hacer en la pc de
la facultad, mientras mando a correr eso para todos los pares de preguntas en la pc de Coimbra.

Pero lo central, que es construir la matriz, ya lo tengo. Luego, armar las funciones que grafiquen
los mapas de colores es un detalle, total es idéntico a lo que se construye actualmente con las
matrices de distancia JS. Así que razonablemente tendré eso para el jueves. O el viernes, veré de
hacerlo lo más rápido posible, paralelizando la construcción de estas matrices.

Siento que quizás no fue tanto lo que hice hoy, pero yo digo que estuvo bien. Mañana nada de dormir
de más, me pongo directo a laburar en el tema de armar estas funciones temprano, termino antes del
mediodía, y ya a la tarde laburo en lo de Granovetter.

------------------------------------------------------------------------------------------

11/09/2024

Llegué tarde a la facultad, no puedo avanzar con el laburo así, soy un boludo. Tengo que avanzar
en el trabajo ya así le puedo dar unos resultados a Pablo, y también así yo puedo dormir
medio tranquilo.

Una cosa que podría corregir es el hecho de que intento en las distribuciones que no haya lugares
vacíos en el grid del espacio de opiniones. Pero eso era importante para el cálculo de la distancia
JS. Para este caso eso no hace falta, puedo sacármelo.
 Ya resolví esto, bastante simple. De paso, revisando cómo funciona el código con el caso de un estado
de polarización descorrelacionada observé que había un detalle de módulos que casi se me pasa.

Antes de mandarlo a correr, puedo decir que para una misma distribución, que es la distribución
de Impeachment vs Pres. Didn't Worry Congress, observo que la máx distancia de KS es 0.687 comparada
con un estado de polarización 1D con anchura, 0.979 para un estado de consenso radicalizado y 
0.384 para un estado de polarización descorrelacionada. Si tomo la distancia entre la distribución
de la encuesta y la distribución de la simulación y hago 1- esa distancia, entonces ya
puedo tener una distancia mínima con el estado de consenso radicalizado. Igual, si lo miro bien,
siento que lo que va a pasar es que simplemente los estados de consenso radicalizado van a alcanzar
siempre altos valores de distancia KS, por tanto bajos valores de distancia renormalizada.

Si todo está bien, creo que puedo mandar a armar gráficos a partir de esto. Y las matrices.
Elijamos tres gráficos levemente diferentes y veamos qué da en el espacio de parámetros para
20 y 100 simulaciones.

Bien, logré armar la matriz de distancia KS. Así que ahora lo que voy a hacer primero es mandar
a correr esto en Coimbra para todos los pares de preguntas, así ya mañana esto está terminado.
Mientras eso se resuelve, armaré una función que levante los datos de los archivos csv y
otra función que arme los gráficos a partir de eso.

Mandé eso a correr en Coimbra. En principio debería funcar bien esto. Y con eso me refiero a que
el código no debería tirar errores. Pero esta métrica me parece que detecta cuando tenés un único
pico, pero el resto de cosas no las ve.

Hablé con Pablo, tengo varias tareas nuevas que resolver. Vamos a ver cómo corno me organizo para
todo. Lo que dijimos de hacer son tres cosas principalmente.

1) Preparar el gráfico del par de preguntas con distancia de KS para los tres pares de preguntas
considerados.
2) Mandarle un mail a Hugo para reunirnos y consultarle respecto al tema de las distancias KS
y respecto a lo de proyectar lo de dos dimensiones a una dimensión.
3) Probar con un nuevo gráfico usando cuadrados mínimos como una métrica para comparar gráficos.

Para hacer lo primero, lo que voy a hacer es levantar las matrices y de ahí construir los gráficos.
Las funciones de lectura de matriz DJS, mapa colores y preguntas espacio parametros creo que se
pueden totalmente usar para las demás métricas.

Estaba por mandar a correr y armar algún gráfico de distancia de KS, pero resulta que tengo
un archivo csv de los que armé en Coimbra. Eso es un problema porque el archivo de Coimbra está
armado con un barrido más fino y más grande que el que tengo en mi pc. Tengo que rearmar esos
archivos después. Armé los gráficos que quería, soy un crack. Necesito ayuda igual.

------------------------------------------------------------------------------------------

12/09/2024

Ayer hablé con Hugo y logré preparar el armado de las matrices de distancias de KS. Se me ocurre
que lo primero que tengo que hacer es preparar las cosas que necesito para la charla con Hugo
más a la noche. Quiero comentarle dos cosas importantes a Hugo. La primera es cómo estoy
tomando la medida de la distancia KS, la segunda es cómo debería hacer el tema de la proyección
de opiniones en el espacio.

Para lo primero, estaría bueno tener algunas diapositivas mostrando cómo estoy haciendo 
el cálculo de la distancia de KS. Para lo segundo, tengo que ir con una idea de lo que entendí
y con el anotador para dejarme bien claro lo que quiero hacer.

Veamos primero si se construyeron todas las matrices ayer y con eso construyamos las matrices
de distancia de KS. Algunas matrices no se construyeron, no comprendo exáctamente por qué.
Voy a intentar anotar las preguntas y los tamaños de preguntas, como para ver qué pasa ahí.

Hecho eso, veré de armar algunos gráficos extra de distancia KS. Bien, ya eso está corriendo.
De lo que anoté ayer, la idea de cuadrados mínimos puedo ver de hacerla mañana. Yo intentaría
ahora primero de hacer algo del modelo de Granovetter y después un poco de alemán al final del día.
 Aunque si mañana vamos a lo del CCK, no voy a hacer esto el viernes ni a ganchos. Carajo.
Bueno, arranquemos con lo de Granovetter. En el medio de esto, fui al coloquio.

Cuando volví, revisé lo de las matrices de DKS. Los gráficos se realizaron bien, lo que no
salió bien es lo de la generación de matrices polarizadas. Lo que vi es que al parecer el error
está en que me comí el armado de la matriz hist2d y eso llevaba a problemas. Resuelto eso, debería
estar bien. Aunque la forma en que lo resolví me choca un poco, pero va todo bien.

Armé una presentación para plantearle más o menos a Hugo mi idea de lo que quiero contarle. Creo
que tengo todo lo que me parece importante mencionar. Sobre el tema de la proyección, consultarle
cómo debería hacer eso. Lo que habíamos entendido es que debería tomar las opiniones en cada tópico
por separado como si fueran distribuciones independientes para los casos con cos(delta) = 0,
y comparar los niveles de polarización de esos casos con los niveles de polarización de simulaciones
1D. El tema es, ¿tengo simulaciones 1D? La idea es ver cómo afectaba a la polarización el hecho de
que tengo un sistema 2D, aún si los tópicos están desacoplados en el cos(delta).

Mirando el laburo, mi plan sería el sábado hacer el tema de los cuadrados mínimos. Veamos un
segundo si la idea es algo rápido de hacer o no. Seamos inteligentes, me cagaron a pedos y
seriamente lo veo como algo rápido de hacer. Hagámoslo y después el finde estudiaré alemán
sino, no es tanto drama. Lo armé, eran dos patadas. Lo cuál muestra que es muy boludo de mi
parte no hacerlo y hacer otra cosa primero. Como funciona, voy a cargarlo a Coimbra y ya
poner a hacer esto para todos los pares de preguntas.

Para lo de KS Hugo me dijo que tome la máxima distancia de cada rotación y luego minimice entre
rotaciones, o que sino pruebe quedarme con la esquina izquierda de los cuadrantes. Hay una tercer
propuesta que a Hugo no le copa mucho, que es partir los datos de las cajitas a la mitad y repartir
mitad y mitad a cada lado.

La idea es comparar polarización entre el modelo bidimensional y el unidimensional. Los datos
del unidimensional lo tienen en el paper. Los datos del bidimensional lo sacamos del barrido beta-Kappa.
La idea es primero comparar la fracción de estados polarizados en el caso 2D habiendo proyectado 
las opiniones en una dimensión. Mi temilla con esto es cómo defino que un estado es polarizado,
pero siendo que voy a comparar con los datos de ellos, yo diría de usar la definición que usan
ellos.

------------------------------------------------------------------------------------------

13/09/2024

A la mañana fui a estudiar Alemán. Salí temprano, comí unas empanadas y fui a la reunión
de grupo para charlar y ahora volví para ponerme con el trabajo del modelo de opinión.
Tengo dos o tres cosas para hacer. Lo primero es lo que me dijo Hugo, calcular la distancia
de KS tomando primero la máxima distancia en cada rotación entre todos los cuadrantes
y todos los puntos y luego tomando el mínimo entre esas 4 distancias obtenidas.

Bien, ya mandé a correr esto en comparación con el caso anterior. Ahora tengo que ver que
efectivamente funque bien. Quizás pueda aplicar también la otra cosa que propone Hugo sobre
tomar el punto de pivoteo como la esquina inferior izquierda del cuadrante.

Haciendo lo que propuso Hugo da un poco mejor, pero no es un graan avance. Habría que ver qué
pasa si hago lo de modificar los cuadrantes considerando el punto de pivoteo como la esquina
inferior izquierda del cuadrante. Lo que voy a hacer ahora es mandar a correr esta nueva versión
de KS y también armar los gráficos de distancias de CM.
 Armé los gráficos de CM. Mirándolos, no parece que haya sido una solución. Esta medida parece
favorecer que con todas las simulaciones, agrupa a todos los pares de preguntas en la región
I y un poco de la II. En cambio, para 20 simulaciones, agrupa todas las preguntas en la región
V. De nuevo, pareciera que los estados de polarización descorrelacionada se llevan toda la atención.

¿Qué cosas quiero hacer este finde? Yo diría de hacer los gráficos con la métrica de KS que me
propuso Hugo, como una tercer opción. Y después armar las distribuciones de preguntas
en el espacio de parámetros. Así queda claro qué estoy viendo y cuál es el problema.
 Otra cosa que se me ocurre es borrar todos los gráficos que tengo en la carpeta de
Beta-Cosd y rearmarlos. Y aprovechar cuando hago eso de reescribir el código de la
función de Graficar de forma tal que se armen los mapas de distancias de mis tres
métricas distintas. Yo sé que puedo hacer eso. Todo esto el sábado.

------------------------------------------------------------------------------------------

16/09/2024

El finde no pude trabajar lo que quería hacer. Más vale que hoy resuelva todo lo que tengo
que hacer ya. Para el finde tengo que tener gráficos, propuestas y alguna idea de proyecto.

Bien, mandé a correr para armar todos los gráficos. Aproveché y revisé lo que se hizo en los
programas en la pc de Coimbra. Parece que hay algunas simulaciones que no se resolvieron.
NO ENTIENDO POR QUÉ. Revisar de mandar a correr eso. O revisar que estén bien armados
los datos. Eso lo miraré el miércoles quizás.

Miré los gráficos de distribución de preguntas. No está dando nada copado, porque se ve que
las preguntas van al mismo lugar para pocas simulaciones, que es la región V. Aunque podríamos
destacar que cada métrica destaca cosas distintas, eso se ve en cómo se configuran las distribuciones
de los histogramas más similares. Tengo dos cosas que puedo hacer ahora. La primera es modificar el
armado de la distancia KS de forma tal que el punto de pivote sea la esquina izquierda de los cuadrantes.
La segunda es armar lo de la proyección de las distribuciones 2D y ver cómo se da la generación
de estados polarizados y comparar eso con lo que se observa en el modelo 1D. Se me ocurre que puedo
compararlo mirando datos como la varianza de las opiniones y los valores medios. Es la forma en
que se me ocurre que puedo comparar ambas situaciones, la del sistema 1D con la del sistema 2D
proyectado.

Si quiero revisar mejor mis datos necesito construir mi tabla de pares de preguntas para cada métrica.
Por un lado, mandé nuevamente a armar las matrices de distancias de KS. Esta vez con la idea de tomar
el punto de pivote como la esquina de abajo a la izquierda de los cuadrantes. Ahora no me queda nada más
que hacer ahí que esperar a que se terminen esas matrices, que tomará unas 10 o 12 horas.

Mientras eso resuelve, detallemos la parte de construir las tablas de preguntas de cada una de las métricas
y luego de eso me pongo con lo de la proyección de los estados 2D a 1D. Ya hice las tablas, arranquemos
con el tema de proyectar los estados 2D a 1D. Se me ocurre que para construir este gráfico, puedo partir
de la función que construye gráficos de Varianza y con eso ver qué ocurre. Eso sería algo bastante rápido
de construir. De paso, lo tendré que construir en el espacio Beta-Kappa. Así que puedo armar esto en el
archivo de Graficar de Beta-Kappa.

Revisando las distribuciones de preguntas en el espacio de parámetros Beta-Cosd para las distintas métricas,
resulta interesante notar que a métrica que más le llegué a observar consistencia entre las preguntas clasificadas
con 100 simulaciones y las clasificadas con 20 simulaciones es a la métrica KS. Es un poco complicado igual
sacar conclusiones así como está.

1) En los otros gráficos colorear las preguntas según cluster de JS
2) Revisar en los datos empíricos realizando una matriz de similaridad usando JS de 120x120.
Intentar observar clusters propios de los datos con SVD o con Louvain usando una matriz de similaridad.
3) Podría arrancar armando algún gráfico con los datos de las distancias promedio inter cluster e intra
cluster. Veremos cuánto de esto puedo resolver para mañana

Pablo también me dijo que arme diapositivas mostrando cuál es la forma que tienen las simulaciones de los
clusters en particular. Para eso puedo tomar diapositivas de lo que hice la reunión pasada.

Bueno, el gráfico de la proyección de los datos 2D a 1D parece estar corriendo. Eso en principio está avanzando.
Pasemos a armar los gráficos coloreados como me propuso Pablo. Ya corregí para que se armen
los gráficos de preguntas en el espacio de parámetros identificando los clusters de preguntas por colores
como me dijo Pablo. Lo que sigue ahora es ver de construir una matriz de 120x120 de datos contra
datos usando JS.

------------------------------------------------------------------------------------------

17/09/2024

Estoy revisando qué hacer hoy. No quiero confundirme, ayer dejé corriendo dos cosas. Lo primero es
el armado de las matrices de distancias KS usando el punto de pivote como eje izquierdo de los cuadrantes.
Lo segundo, es el armado de gráficos en el espacio Beta-Kappa para ver lo de la polarización del sistema
2D proyectado a 1D. Así que ahora voy a mandar a correr el armado de las preguntas en el espacio de parámetros
Una vez que esté hecho eso, organizo mis datos, lo que tengo y qué voy a poner en la presentación.

Organicemos las cosas que tengo. Ahí armé varios gráficos y necesito plantearme qué tengo y qué voy a mostrar.
Y qué cosas quedan por hacer para el resto del laburo.

1) Tengo los gráficos de promedios y varianzas de opiniones de las opiniones proyectadas a 1D
en el espacio de parámetros Beta-Kappa.
2) Tengo los gráficos de distribución de preguntas por colores en el espacio de parámetros para cada 
métrica.

Con esas dos cosas puedo armar la presentación que charlamos con Pablo. Debería agregar que los gráficos
de distribución de preguntas tienen que ser un poco más grandes en la región porque algunos puntos
no se ven bien.

De los gráficos de opiniones proyectadas a 1D, mejor poner ambos mapas de colores con la misma escala de colores
y forzar que la escala llegue a 1 como máximo. Eso es rápido, lo dejaré para después.

Son las 21. Terminé la presentación. Ahora salgo para casa. Espero que no esté muy fresco afuera.

------------------------------------------------------------------------------------------

18/09/2024

Hoy a la mañana me levanté y tuvimos la reunión con la gente de GOTHAM. En la reunión, al final no tuve
mucho para presentar porque la forma en que entendí que tenía que presentar la distancia de KS estaba
mal. Soy un boludo, no entiendo cómo esto pasó varios filtros y nunca surgió.

Cosas que salieron de la charla:
--------------------------------
.) Para la próxima reunión, tener preparado el análisis de la relación de similaridad entre las distribuciones
de las encuestas
.) La forma de la polarización no está predeterminada en un eje y el otro
.) Se requiere un Beta más grande para generar polarización
.) Lo que mostró Hugo sobre los mínimos de distancia JS en función de Beta está muy interesante.

Cosas en las que trabajar:
--------------------------
1) Armar una matriz de similaridad entre encuestas usando tanto distancia JS y distancia KS.
2) Preparar el resumen de lo que tengo del trabajo. Es importante para arrancar a escribir el paper.
Así ya la próxima reunión vamos con algo planteado para arrancar a escribir.
3) Reescribir el código que hace las simulaciones para que mi código funcione al ritmo del de Hugo
4) Recomponer las simulaciones que fallaron en Coimbra. Anotar cuáles fueron y ver si las puedo
armar rápido de nuevo.

Mandé a correr de nuevo el armado de los gráficos de mapas de colores de KS modificando el tema de las
distancias para que no sea 1 menos la diferencia de las probablidades integradas. En un rato, vuelvo a mandar
a construir todas las matrices de la distancia KS.

Mientras esto se resuelve, me pondré con lo de armar la matriz de similaridad entre distribuciones de encuestas.
No armé la matriz. La verdad un poco Pablo me va a cagar a pedos, pero pensar cómo mierda armar esto es parte
de hacer este laburo. Mañana debería trabajar un poco en esto, un poco en lo de Granovetter y un poco en Alemán.
Carajo.

------------------------------------------------------------------------------------------

19/09/2024

Mandé a rearmar los gráficos de distribución de preguntas en el espacio de parámetros según
distancia KS. No sé si se hizo bien, porque se ven idénticos. En un rato los repaso más en
detalle.

Ya casi tengo armado el archivo que produce la matriz de similaridad JS entre distribuciones.
¿Tengo una duda que no me resuelvo al mirar esto. Debería rotar las matrices para encontrar
cuál es la mejor coincidencia o no? Siento que rotarlo sería un poco como forzar esto. Pero
por otro lado, los estados que defino como estados finales del sistema son invariantes ante
rotaciones. Un estado polarizado en una dimensión y con consenso en el otro, rotado es lo mismo
en cualquier caso. 
 Creo que la justificación se encuentra en lo siguiente. Yo considero que algun estado representa
más o menos la encuesta que estoy observando. Entonces cuando comparo encuestas, lo que quiero
comparar no es si hay un consenso radicalizado de aprobación contra un consenso radicalizado de
rechazo, mi interés es saber si hay consenso o polarización. Entonces rotar las encuestas es válido
porque pierdo la noción de si hay aprobación o rechazo a las preguntas, pero el estado que se
representa no se pierde.

Hablando con Pablo, la idea es que usar una red para ver el tema de la similaridad quizás no es lo
mejor, quizás conviene mirar el tema desde la matriz de Similaridad y listo. Me propuso usar cosas
como tSNE o PCA para reducir dimensionalidad y ver cómo me agrupa las preguntas de las encuestas.
Otra propuesta es ver cómo son las distribuciones de distancia inter cluster e intra cluster.

Mandé a rehacer las matrices de distancia KS en Coimbra, junto con la matriz de Similaridad.
Esta vez estoy armando la matriz de SIMILARIDAD. Tiene sentido que la construya como 1-distancia JS.

Antes de hacer nada nuevo, voy a revisar qué pasó con los archivos que no se terminaron de armar.
Una vez organizado eso, me pondré un ratito con el tema de Granovetter. O quizás vaya para casa si
veo que la cosa está medio calmada.

.) En la iteración 2, hay un salto entre Beta=0.65 y Cosd=0.26 hasta Beta=0.75 y Cosd=0.36.
Ver si esos estados faltan.
.) En la iteración 6 tiró error la sim con Beta=0.65 y Cosd=0.10. Después hay un salto entre
Beta=0.65 y Cosd=0.20 hasta Beta=0.65 y Cosd=0.42.
.) En la iteración 10 tiró error la sim con Beta=0.75 y Cosd=0.14. También la sim con Beta=0.85 y Cosd=0.18.
.) En la iteración 14 tiró error la sim con Beta=0.65 y Cosd=0.08. También la sim con Beta=0.65 y Cosd=0.22.
.) En la iteración 18 tiró error la sim con Beta=0.55 y Cosd=0.38. También la sim con Beta=0.65 y Cosd=0.02.
Además hay un salto entre Beta=0.65 y Cosd=0.18 hasta Beta=0.65 y Cosd=0.38.

Me estoy dando cuenta que en un punto también hubo un barrido de Beta entre 0.05 y 0.35 que falta hacer.
Parece que los saltos no son problemas de verdad. Pero los errores sí. A eso se le suma que la iteración
6 falta una sim en Beta=0.65 y Cosd=0.22. Básicamente parece que en el inicio de los saltos faltan
simulaciones. Bien, esos son todos los archivos que faltan que hay un acuse de que faltan.

Mientras tanto, mandé a correr el armado de datos con Beta menor a 0.35. Mientras eso se resuelve,
veré si mañana o pasado resuelvo lo que falta. Estoy mirando que hay muchos archivos que están vacíos.
Pero hay una diferencia de 4 iteraciones entre cada iteración con múltiples errores. Mejor lo
mando a correr todo de nuevo desde el principio y listo. O quizás desde 0.45 hasta 1.05. Me parece
lo razonable.

------------------------------------------------------------------------------------------

20/09/2024

A la mañana fui a Alemán, comí, mandé a correr los gráficos con el tema de la distancia KS corregido.
Ahora lo que sigue es ponerme a laburar, aunque sea un poco, en el tema de Granovetter.
Me junté con Lucio. También hablamos con Seba por el tema de Granovetter, nos tiró una idea muy
buena sobre usar las distancias para determinar probas de transición de un estado al otro.
Si flexibilizamos la condición de transición para que no sea algo de que gana absolutamente el de
más distancia, sino que sea una probabilidad de transición en función de las distancias.

El tiempo no me da para laburar mucho más, el plan de laburo es el que tengo anotado más arriba.
A eso le tengo que sumar el ponerme a leer papers y también organizar los que tengo descargado en
la carpeta de Bibliografía. Mañana me pongo con estudio de la materia de Mininni.

------------------------------------------------------------------------------------------

22/09/2024

Al final no estudié nada de lo de Mininni. Ahora ya es bastante tarde en el domingo, pero vamos a intentar
ponernos a laburar un poco, cosa de caer con algo hecho mañana.

Se me ocurre que podría tomar cada distribución dentro de un cluster y comparar eso con gráficos de otros
clusters y luego tomar la media y la varianza de esas distancias JS. Me parece mejor eso que graficar
la distribución de distancias. Entonces para un dado cluster, miraría cuáles son las distribuciones de
la media de distancia JS y la varianza de las distancias JS. Puedo hacer eso diferenciado por clusters.

No hice nada, no quería hacer nada hoy. No trabajé. No descansé. No nada. Qué bronca.

------------------------------------------------------------------------------------------

23/09/2024

Estuve avanzando con el tema de hacer la medición de JS entre gráficos de distribuciones.
Ya tengo el cómo levantar los arrays. Ahora tengo un leve problema que es remover la diagonal
del array. Pidámosle eso a Chat GPT.

Bien, ya armé los gráficos que quería. Ahora, tengo dos conclusiones. La primera es que no hay
una gran diferencia en los histogramas inter cluster e intra cluster. La segunda es que no es
algo fácil o directo de comparar, necesito modificar los gráficos para que sea algo más
razonable o fácil de entender. Hecho eso, podría hacer el mismo trabajo pero usando la distancia
de KS como medida de lo que estoy observando.

Se me ocurre que estaría bueno normalizar los gráficos según cantidad de pares de preguntas
en un cluster y también poner varios de esos gráficos juntos. Podría armar gráficos de barras
de colores y transparentes.

Pablo me propuso que directamente pruebe hacer un PCA. Arranquemos por eso, no hagamos lo de la
distancia KS primero.

Antes que esto, viendo que el barrido en valores de Beta menor a 0.35 ya terminó, voy a
mandar a correr entre Beta = 0.45 y Beta = 0.95 el barrido, cosa de que me asegure de que atrapa
todos los problemas de simulaciones vacías.

Hice lo del PCA. Creo que está bien hecho, pero consultar con alguien más. La forma en que los agrupó
es interesante. Por lo que ví, los agrupó en tres, cuatro clusters. Bastante copado eso. Y hay un 60%
de la varianza explicada en los primeros dos componentes. ¿Con un Nearest Neighbors encuentro
los clusters? Revisar eso.

------------------------------------------------------------------------------------------

24/09/2024

Hablando con Pablo, me dijo que lo que tengo que hacer es ver cómo realizar un clustering de
mis datos. Se me ocurrer probar con Kmeans, quizás un clustering jerárquico o KNN. Habrá que
ver ideas de cómo juntar todo.

Hablando con Lucio, me propuso que haga el producto de las matrices que me salen del pca como
para ver que efectivamente lo que obtengo a la salida es similar que lo que tenía originalmente.

Tanto K-means como clustering jerárquico son métodos válidos para esto, yo arrancaría con el
K-means. El tema de esto es no perder quince horas revisando la documentación y validación de noventa
métodos distintos de clusterización. Hagamos primero lo de tSNE y después veo de ir clusterizando
cosas.

Bien, tengo armado algo para la separación según PCA o tSNE. Ahora tengo que ver de armar métodos de
clusterización espacial. Le pregunté a Chat GPT, me recomendó cinco métodos, entre ellos K-means y
hierarchical clustering. También DBSCAN.

Partamos usando K-means. Veamos cómo se usa. Bueno, hice una clusterización con K-means. No sé qué
decir, no me parece que esté tan bien agrupados. Habría que juntarse con Pablo mañana. También
quiero mañana a primera hora ponerme a descargar los papers que viene pasando Pablo, cosa de
organizarlos en la lista de cosas para leer y así.

------------------------------------------------------------------------------------------

25/09/2024

En la mañana quise ir a la facultad para laburar, pero se me pinchó la rueda de atrás.
Mañana llevaré la bici a revisar. Me volví a casa para ponerme a laburar desde ahí.
Resulta que desde casa hay paquetes que no estaban bien instalados. Así que los resolví
Luego de un buen rato, ya actualicé el WinPython y mandé a correr todo de nuevo.
Hagamos ahora sí lo que charlé ayer con Pablo, comparemos clusters.

Bueno, logré armar una matriz que me muestra la superposición entre los clusters hallados 
por el método de K-means y los clusters hallados al separar los gráficos usando distancia
JS. Para arrancar, da bastante mal. Lo segundo, no sé si es la mejor manera de mostrar que
da mal. Lo tercero, quizás tenga que revisar cómo son esos clusters por dentro, para ver si
tienen algún sentido.

Lo que voy a hacer ahora es armar dos o tres gráficos más de esto. Debería hacer este mismo
gráfico pero con la reducción de dimensionalidad de tSNE, y después probar si uso otro método
de Clusterización, aunque no creo que vaya a dar mucho mejor otro método de clusterización.
Digo, los clusters encontrados parecen bastante razonables. Tengo que charlarlo esto con Pablo
mañana sí o sí.

Mañana temprano construyo la matriz de KS, armo los gráficos y ya al mediodía veo de plantearle
a Pablo los resultados. Tengo que levantarme temprano y no joder mañana.

------------------------------------------------------------------------------------------

26/09/2024

Hoy trabajé desde casa, estuve preparando los gráficos de clusterización y cosas para mostrarle a Pablo.
Armé una presentación rápida y charlamos lo que estuve haciendo. Anoté las cosas que Pablo
me propuso hacer.

.) Usar los colores de los clusters al graficar PCA
.) Preguntarle a Sebas por formas de encontrar clusters según la forma de las distribuciones
en un espacio euclídeo
.) Hacer K-means en el espacio de vectores de 36 dimensiones (Creo que al final esto no)
.) Hacer K-Means sobre la matriz de Dist_Enc_JS
.) Agregar las preguntas que no están en los clusters como "Otros"
.) Organizar el gráfico que compara cuánto se parecen los clusters en función de 
cuánto se parecen.

Después de la reunión estuve con cosas, se paso la hora rápido, así que no pude avanzar nada
en esto. Tampoco pude estudiar Alemán. Quizás haga un rato de eso mañana. Veré si mañana
puedo hacer algo de esto que me pasó Pablo o si lo haré el lunes.

------------------------------------------------------------------------------------------

27/09/2024

Hoy fui a la mañana a Alemán, después tuvimos la reunión de grupo en la que Lucas dió charla,
y por último me reuní con Lucio. No pude hacer nada sobre lo que anoté ayer para resolver.
Voy para casa así busco la bici y veo si después me pongo a laburar un poco más.

------------------------------------------------------------------------------------------

28/09/2024

De lo que charlamos el jueves con Pablo, voy a intentar primero hacer el K-means a la matriz de 120x120
y después lo de incorporar los colores al conjunto de datos. Lo de agregar los que sobran lo haré
a lo último. Hagamos primero que nada el estudio sobre la distancia JS, no la distancia KS.

Bien, armado ese gráfico, da interesante porque lo que observo es muy similar de lo que observo 
aplicando K-means al PCA. Armemos los tres gráficos que Pablo decía que debo tener. El que me falta
es el tercero, el que pinta los datos según los clusters formados según la distribución de preguntas
en el espacio de parámetros.

Creo que puedo hacer mejor este trabajo si utilizo las propiedades de Pandas. Puedo agregar una columna
al pandas que tengo de Df_preguntas en el cuál vayan los clusters considerados. Luego, uso esa columna
para identificar los clusters en el gráfico. Ahí revisé, la columna nombres del DataFrame de Df_preguntas
coincide totalmente con los índices del DF Df_dist_JS.

Bien, ya tengo esos tres gráficos. Tengo que organizarlo un poco para que sea más legible o agradable a la
vista. Ponele básicamente la leyenda de clusters al costado, y fijate que más o menos tengan que ver los
clusters entre ellos un poco.

------------------------------------------------------------------------------------------

30/09/2024

Llegué temprano hoy a la facultad, pero tengo un sueño terrible, me está costando laburar. Cuestión,
tengo los tres gráficos que quiero:

1) K-Means aplicado sobre el PCA
2) K-Means aplicado sobre la matriz de distancias JS
3) Pares de preguntas clasificados en espacio de parámetros aplicados sobre PCA.

Estaría bueno que los colores tengan que ver para que sea más fácil comparar. Porque la verdad no sé
qué estoy viendo. Primero que nada, pongámosle a cada gráfico el cuadro de labels.

Costó, pero ahí armé el cuadro de leyenda que indica los clusters. Ahora veré 
de agregar eso a los otros y después veré de organizar correctamente esos clusters.
Bien, ya tengo todos los gráficos con los clusters ubicados. Ahora necesitaría compararlos por un lado
y colorearlos según los que más se parecen. Ya junté las tres clusterizaciones en un dataframe, que es
el de Df_preguntas.

Bueno, armé los gráficos. Acabo de descubrir que perdí un puto día haciendo esto, para que me de todo
para el tuje. La verdad, que se vaya todo a la mierda. Veamos qué tengo y qué voy a hacer con eso.

De lo que anoté de la última reunión, hice tres de las cuatro cosas anotadas. La primera era
lo de la matriz de Similaridad, está armado eso y preparados los gráficos al respecto, tanto para
el K-Means sobre la matriz de distancia como para el K-Means sobre los datos de PCA,
Lo segundo era lo de corregir el análisis de KS, esto está resuelto y da bastante feo también.
Lo tercero era lo de revisar las simulaciones que salieron mal, las cuáles ya mandé a correr
de nuevo. Mañana debería revisar qué les pasó.
Finalmente lo cuarto era lo de continuar preparando un resumen del trabajo hasta ahora,
así como revisar que mi código en C corra tan rápido como el de Hugo. Esto último no lo
veré mañana, pero si logro preparar pronto la charla para el miércoles, muy raro que Pablo
considere que ya con lo que tengo para mostrar estamos terminados, podría ponerme un poco con
el laburo de ir juntando todo lo que ya tengo para ir perfilando el laburo.

------------------------------------------------------------------------------------------

01/10/2024

Armados mis gráficos, ¿Qué voy a presentar? Vistos los gráficos, lo que puedo mencionar es que
la construcción de los clusters usando K-means muestra conjuntos de pares de preguntas muy
distintos. Entonces voy a presentar que hice el análisis de la distancia KS, el análisis
de la similaridad de gráficos y la clusterización usando K-means.

Hablando con Pablo, me propuso usar la MI o el randIndex para revisar un poco más la relación
entre las clusterizaciones. Me dijo de cambiar los textos en los gráficos. Se me ocurre además
agregar en paréntesis el tamaño de los clusters, para que quede marcado también eso como una
referencia. Hagamos esto y después agregemos estos gráficos a la presentación.
 Hice los cambios en los textos, vayamos poniendo todo en la presentación. Para el gráfico de
preguntas en el espacio de parámetro, tengo que agregar las preguntas que sobran y que no son
parte de ningún cluster.

Hacer Jaccard índex, hacer Rand índex, Matriz de Superposición comparando las dos particiones
obtenidas por K-Means. Tengo armado esto, aunque tengo mis dudas. Veré si Pablo quiere discutirlo
un segundo mañana. Mi plan mañana es armar unas conclusiones también, eso lo puedo hacer en un
momentito.

------------------------------------------------------------------------------------------

02/10/2024

Cosas charladas en la reunión:
-------------------------------
.) Revisar más en detalle las configuraciones outliers en KS para ver cómo están compuestas.
.) También mirar mejor si las radicalizadas están clasificadas mejor o si eso queda mal.
.) Hacer K-Means en el espacio de Beta-Cosd sobre la distancia de JS.
.) Definir la cantidad de simulaciones a utilizar en función de cuál ajusta mejor a la cantidad de clusters.
.) Habrá que revisar mejor las métricas para definir qué es una buena clusterización.
.) Quizás revisar si hay mejores formas de clusterizar.
.) Mi criterio de convergencia es más estricto. ¿Por qué lo hice así?
.) Presentación de los resultados generales.

Propuesta de Pablo:
--------------------
1) Hacer el camino inverso con los métodos de clusterización para ver cuál es la cantidad de clusters
razonables y así ver cuál es la mejor cantidad de simulaciones a considerar.
2) Armar una presentación general de los resultados

A la tarde fui a la marcha universitaria.

------------------------------------------------------------------------------------------

03/10/2024

Hoy a la mañana fui a hacer un trámite con mis viejos y ya llegué a la facultad al mediodía.
Ejercité un poco, respondí cosas y ahora me queda ir al coloquio de Andrés. Después de eso,
veamos de laburar en esto.

El armado de datos está tomando bastante tiempo, todavía no terminaron los barridos en Algarve
y en Oporto. Quedarán para cuando vuelva de México.

Estuve empezando a armar algo sobre la charla resumen de lo que tenemos hecho hasta ahora.
Después podría más o menos fácilmente armar algún recorrido sobre los métodos de clusterización
para presentar el miércoles. Veremos cómo se va resolviendo el día de mañana después de Alemán.
No estamos tan en la mierda, aunque tampoco tengo taaanto para mostrarle mañana a Pablo. Habrá que
ver cómo venimos.

------------------------------------------------------------------------------------------

04/10/2024

Una idea es usar Multi-dimensional scaling para hacer una proyección en 2D de los datos de la
matriz de distancia JS. Seba me proponía esto como forma de graficar en un espacio 2D los gráficos
de pares de preguntas. La otra cosa que me proponía es buscar si hay alguna transformación
que lleva mis encuestas que están en un espacio representado por un vector de 36 elementos,
a otro espacio donde ciertas distribuciones que representan estados finales similares se encuentren
juntos.

Más temprano, fui a estudiar Alemán y tuvimos el examen oral del primer bimestre. Lo que sigue
es continuar con el trabajo que teníamos anotado sobre armar una presentación para resumir
el laburo y armar un camino inverso de ver cómo clusterizar los puntos en el espacio de parámetros,
y ver cuáles de estas formas de clusterización dan mejor.

Tengo un montón de código en Profunc, organicemos un poco ahí. Ya borré las cosas que no tenían mucho
que hacer o que eran repetidas. Ahora vamos a ver de intentar tomar mis datos y realizar dos procesos
de clusterización. Uno que funcione usando K-means, el otro usando DBSCAN.

El plan es tomar la posición de las preguntas en el espacio de parámetros, clusterizar eso y después
comparar ese cluster con clusters construidos a partir de la matriz de Datos. Mi plan es sólo comparar
contra eso, no contra la clusterización a partir de los datos reducidos en dimensionalidad.

Siento que son varios los gráficos que quiero armar. Por un lado tengo la matriz de Datos, la cuál
puedo clusterizarla en K clusters. Por otro lado tengo los datos en el espacio de parámetros, los
cuáles puedo clusterizarlos en L clusters. Finalmente los datos en el espacio de parámetros puedo
tomarlos segun una cantidad T de simulaciones más similares. Efectivamente tengo tres cosas que
variar. Se me ocurre que lo razonable es pensar que la cantidad de clusters que armo de la matriz
de distancia tiene que ser igual a la cantidad de clusters que armo en el espacio de parámetros,
sino sería rara la comparación. Yo quiero ver cuál es la cantidad de clusters a tomar y la cantidad
de simulaciones a considerar. Mi anhelo es que eso me dé un máximo al rand_index cuando las clusterizaciones
son similares para un dado número de simulaciones. Si hice 6 clusters en la matriz de distancias y eso
por motivos raros da bien con la clusterización de 3 clusters del espacio de parámetros, no sé qué
puedo extraer ahí. ¿Uso 3 o 6 clusters?

Arranqué con el código, la idea va. Creo que lo voy a graficar como mapas de colores. Claramente tengo
una fascinación con eso.

------------------------------------------------------------------------------------------

06/10/2024

Bien, me senté a laburar. En dos horas puedo hacer algo, creo en mi. Pongamos algo de música para laburar
y no dormirme. Bueno, logré hacer algo. Hice clusterizaciones varias, comparé los clusters usando
Mutual info y Rand Index. La verdad, no se ve que coincidan mucho las clusterizaciones, aunque es en parte
lo que me marcan ambos índices. Mi respuesta a Pablo sería que no es evidente, ni me parece el mejor camino,
hacer un análisis desde este lado. En especial considerando por un lado que al programa le cuesta encontrar más
que siete clusters, y además que está encontrando un máximo en 4, que suena más bien a un máximo resultado de
haber tomado pocos clusters.

Podría intentar hacer un análisis usando DBSCAN, pero en ese caso tengo que ir considerando el tema de cuál
es la distancia para identificar puntos como vecinos.

------------------------------------------------------------------------------------------

07/10/2024

Llegué a la facultad en el horario usual, pero más tarde de lo que debería, porque como boludo me pasé
de parada. Si hoy voy a buscar la bici, quizás pueda empezar a llegar más temprano. Dios, siempre hay
más gastos para hacer.

Hoy a la tarde veré si puedo ponerme a ordenar el tema de los papers. Por otro lado, estoy teniendo mal
internet, voy a ponerme a leer papers y ver si se me arregla pronto.

Por un lado, probé hacer DBSCAN sobre los datos de la matriz y encontré los dos extremos. Para eps=0.3,
no encuentra ningún cluster. Para eps=0.9 todos los puntos forman parte del mismo cluster. Puedo variar
eps entre 0.4 y 0.7 y ver cómo construye los clusters.

Pablo me dijo que pruebe hacer clusterización sobre el espacio 2D y que revise qué tal queda
como para ver si el score de Silhouette me indica una buena clusterización o no.
Hay probé eso, no me queda del todo claro que esté tan bien eso. Habrá que ir probando qué tal.
Vamos yendo a ver si consigo pasar a buscar mi bici.

------------------------------------------------------------------------------------------

08/10/2024

Hoy vine un poco más tarde, pero es porque me voy a quedar hasta bastante tarde. El freno de adelante
de la bici se salió, tengo que reajustarlo. Estuve retocando el plot para que se vea más lindo. Todo
bien con eso, pero ahora queda tomar decisiones sobre qué hacer.

Charlando con Pablo, me propone esforzarme en armar clusterizaciones directamente sobre el espacio de
las distribuciones, el espacio de 120x36. Se me ocurre que una primera forma de hacer esto es 
comparar los gráficos y alinearlos con las rotaciones según la rotación que minimiza cuadrados mínimos.
Para eso tomo un primer gráfico de consenso radicalizado ubicado arriba a la derecha, y luego a partir
de ese ordeno todos los demás gráficos. Vayamos con eso. Primero hagamos los gráficos de todos los
pares de preguntas consideradas en una sola carpeta.

Ya tengo armados todos los gráficos en una sola carpeta. Voy a probar alinear todo con el gráfico de
"Service to same-sex couples vs Pres. didn't worry about congress". V201408xvsV201372x.png.
Logré armar el array con las distribuciones rotadas para encajar todas lo mejor posible.
Ahora sólo tengo que aplicar DBSCAN o Kmeans a esta matriz. Haré eso mañana en un momentito.

------------------------------------------------------------------------------------------

09/10/2024

Llegué en tiempo más o menos, hice lo de clusterizar en el espacio de distribuciones e intenté observar
algo a partir de eso. No estoy viendo nada claro. No sé si este sea el camino. Razonemos un poco
lo que tengo y lo que estoy haciendo. Estoy intentando hallar una clusterización que surja de los
datos de las encuestas. Usando DBSCAN me está costando un poco quizás definir clusters.
Tampoco estoy sabiendo leer bien el silhouette clustering por lo que veo.
 Con el DBSCAN tengo dramas por la distancia entre puntos para considerarlos vecinos, porque si es
muy chica o muy grande me genera un único cluster, y de ahí no puedo ni calcular el score de Silhouette.

Ok, revisar el Silhouette no es algo garantizado. Probé aumentar K-Means una barbaridad y me da
que se plancha el silhouette. Creo que justamente eso marca que aumentar la cantidad de
clusters en ese punto no te cambia el sistema.

Necesito organizar lo que tengo, son muchos gráficos y cosas que me confunden. Se me ocurre que
puedo ir separando yo los gráficos según lo que me parece más razonable. Hasta ahora he realizado
reducciones de dimensionalidad tanto de la matriz de dist. JS como de la matriz de distribuciones
de las encuestas. Realicé PCA y MDS de ambas cosas. Sobre ambas matrices intenté investigar la
cantidad de clusters óptimos usando DBSCAN y K-means y optimizando el coeficiente de Silhouette.
Para ver que esto clusterizaba bien, apliqué DBSCAN sobre los espacios reducidos, optimicé Silhouette
y me fijé cómo quedaba eso clusterizado.

Hecho todo esto, creo que los métodos de reducción de dimensionalidad considerados son razonables,
no sé si tiene sentido probar otros aparte de PCA y MDS. Lo que debería probar es dos métodos extra
para estudiar si la clusterización es correcta y además podría agregar como método de clusterización
el de clustering jerárquico. Hagamos eso ahora, intentemos no perdernos entre tantos gráficos.
 El uso de la inercia para calcular DBSCAN no funca. ChatGPT me recomienda usar el índice de 
Davies-Bouldin. Entonces usaré eso en DBSCAN, pero inertia en K-means.

Hablé con Pablo, planteamos que el siguiente paso es esto:
1) Fijate qué se observa con Kmeans sobre la Mat JS para el "máximo" coef. Silhouette
2) Compará la clusterización de DBSCAN contra la de Kmeans y fijate qué tan parecidas son.
3) Si son similares, entonces comparamos contra clusterizaciones del espacio de parámetros
Si no son similares, haré algo similar seguro. Dios sabe que es un bardo esto.

Mañana resuelvo esto.

------------------------------------------------------------------------------------------

10/10/2024

Al final no fui a la facultad, laburo desde casa. Hagamos rápido lo que charlamos con Pablo y 
mandémosle esto a Pablo. Ya armé el K-means sobre el máximo coef. de Silhouette. Ahora
tengo que comparar clusterizaciones.
 Lo que me está

El rand_index y la info_mutua dan por encima de 0.5, así que hay similitud entre ambas clusterizaciones.

Comparo esto contra clusterizaciones en el espacio de parámetros. La idea es comparar las clusterizaciones
que tengo en la Mat de JS, no las que armo en la proyección. Según coef. de Silhouette, el eps tiene que
ser 0.525, mientras que la cantidad de clusters tiene que ser 5.

Tuvimos charla con Pablo. Dentro de todo la idea resultó bastante razonable, me agrada que estamos cerrando
a algo. Ahora debería ver de armar la presentación, como para tener algo bien terminado para
cuando vuelva. Dios, cómo carajos me pongo a tiro con lo de Lucio, Alemán y cosas.

------------------------------------------------------------------------------------------

21/10/2024

Estaba pensando por qué no tengo nada anotado de lo que hice. Lo del 10/10 yo juraría que lo anoté
y que lo mandé al git. Espero no haberme mandado cagadas en ese caso. Pero bueno, ya me pondré
con eso. Me puse más o menos al día con mails y cosas, lo que sigue es laburar lo que teníamos
preparado con Pablo y de ahí ir terminando de preparar la presentación del miércoles. Primero
leamos lo que mandé, después haré el trabajo de revisar lo que me decía Hugo de ver si
se clasifican mejor los estados de "Consenso Radicalizado" usando la distancia de KS.

Mirando la presentación, está para modificar los gráficos de Varianza o Covarianza para que se
vean mejor y para que las barras de color vayan entre 0 y 1. El gráfico final de Clust. Matriz JS
vs Clust. espacio parámetros, podría modificar el color de la línea punteada de la curva, para
que se diferencia de la línea punteada que marca el punto clave. O podría hacer la otra línea negra
y fue.

Ahora me voy a poner con lo que me dijo Hugo, lo de revisar que los estados de Consenso Radicalizado
se clasifiquen bien usando la métrica de KS. Primero definamos cuáles son esas preguntas. ¿Las
elijo a ojo? Por ahora sí, mañana quizás no. Ahí las revisé, usé las distribuciones unidimensionales
como forma de apalancarme en la idea de si son Consensos radicalizados o no. Encontré 15 pares
de preguntas que forman estos estados.

V202331x_vs_V201372x.csv
V202331x_vs_V202336x.csv
V202336x_vs_V201372x.csv
V202341x_vs_V201372x.csv
V202341x_vs_V202331x.csv
V202341x_vs_V202336x.csv
V202350x_vs_V201372x.csv
V202350x_vs_V202331x.csv
V202350x_vs_V202336x.csv
V202350x_vs_V202341x.csv
V202383x_vs_V201372x.csv
V202383x_vs_V202331x.csv
V202383x_vs_V202336x.csv
V202383x_vs_V202341x.csv
V202383x_vs_V202350x.csv

Mañana lo que voy a hacer es revisar cómo se clasifican estos 15 pares de preguntas en el espacio de 
parámetros para JS y cómo lo hacen para KS. Hecho eso, tendré que ver bien qué cuento el miércoles.

------------------------------------------------------------------------------------------

22/10/2024

En la mañana le mandé el mail a Silvio sobre el plan de Tesis para que pueda armar la documentación para
el viaje.

Más temprano hablé con Pablo. Fijamos tres cosas para presentar mañana.
1) Un armado sobre qué vamos a proponer en el paper. Cómo vamos a hacer eso y qué vamos a contar.
2) Una muestra sobre clusterizaciones de las distribuciones y qué se observa en esos
clusters. Muestras de que hay una cierta cantidad de clusters ideal.
3) Responder a la pregunta que me hacía Hugo sobre el tema de los estados de Consenso Radicalizado
mal o bien clasificados según KS.

Arranco por el tema de la pregunta de Hugo. Estoy armando esos gráficos. Así que eso va a estar listo
pronto. Lo siguiente es armar los gráficos correctos de clusterizaciones que quiero mostrar.

Armé el gráfico para responder a lo que me preguntaba Hugo, ya tengo hecho eso para agregarlo a la presentación.

Cosas para revisar:
1) Los gráficos según lo que escribí ayer
2) Cómo funciona el score de Silhouette
3) Qué es el SSE

Bien, ya mandé a hacer cosas. Ahora me iré para casa, emparcho un poco más la presentación y listo.

------------------------------------------------------------------------------------------

23/10/2024

Cosas que surgieron en la reunión:
-----------------------------------

.) Hugo propone estudiar la polarización ideológica para el caso con coseno delta distinto de cero
.) Hugo hizo simulaciones para estudiar la estabilidad del caso de polarización ideológica.
Da cosas raras.
.) Quizás la transición de polarización descorrelacionada no es una transición propiamente dicha.
.) David menciona que quizás es mejor intentar distinguir los clusters generales, intentar diferenciarlos
minuciosamente es más ambicioso
.) Estaría bueno mirar entonces un subconjunto de preguntas que se separe bien, no intentar separar
TODAS las preguntas.

Hecho eso, hoy y mañana no me pondré directamente con esto. Aunque charlaré con Pablo al respecto mañana.
Ahora me pondré con lo de Lucio que charlamos. Bien, ahí lo miré, estoy en tema. Charlaré con Lucio sobre
que me genera un poco de duda la notación y después modificaré el color blanco de los indecisos. Y luego
me pondré a ver un poco el código.

------------------------------------------------------------------------------------------

24/10/2024

Hoy a la mañana lo primero que hice fue mandarle un mail a Silvia sobre lo que fue mi viaje, con ganas
de armar un texto escrito en Alemán.

Después me junté con Lucio y trabajamos en retocar la presentación y cómo plantearla para mostrarle a 
Pablo dónde estamos. Quedamos en que yo debería retocar el código para que las distribuciones de umbrales
sean únicas para todos los tópicos por cada agente. Voy a cambiar para que los tipitos blancos tengan
otro color porque cuesta verlos. Por último, retocar un poco la presentación en general para que se
vea más linda. Y después ya tendría que ponerme a ver lo que hizo Sebas para entender cómo es el pase
de la ecuación de la dínamica de las probabilidades a la ecuación de la dinámica del k.

Bueno, bastante laburé en la presentación. Ahora pasemos a lo del trabajo con la gente de España.
Primero anotemos las cosas que me dijo Pablo de hacer.

1) La parte numérica está bastante cerrada. Quedaría ver cómo matchear eso con el modelo 1D y elegir
correctamente los mejores gráficos a presentar.
2) En la parte teórica, continuar un poco con el análisis teórico, cosa de tener algo más claro
las curvas de transición. Yo propondría continuar un poco con la ecuación de la estabilidad
del estado de polarización descorrelacionada.
3) En la parte empírica, habría que reducir las preguntas a un conjunto que mejor matchee con el
modelo.

Ahora me voy a poner a hacer lo tercero, buscar un conjunto que me parezca que sea el más identitario
de estados finales del modelo. ¿Lo hago a ojo? ¿O podría buscar una métrica? No, definitivamente
tiene que ser a ojo en principio. Planteemos entre 8 y 12 gráficos como el subconjunto a revisar.

Bien, ahí separé un conjunto de preguntas. Queda después ver cómo trabajar con eso y ver si realmente
se puede clasificar algo de eso.

------------------------------------------------------------------------------------------

25/10/2024

Fui temprano a la clase de Alemán, revisamos cosas sobre formas de decir si algo está prohibido,
si es obligatorio, si se puede hacer o no.

Hecho eso, volvimos, fuimos a comer, di vueltas algunas cosas y ahora sí, a laburar. Ya separé un
conjunto de gráficos para analizar eso en detalle separado. Veámoslo a ver si quedan separados en
el espacio de parámetros.

Los pares de preguntas que estoy mirando en el subconjunto son:
V201411xvsV201408x
V201426xvsV201386x
V202255xvsV201420x
V202255xvsV202328x
V202255xvsV202341x
V202328xvsV201386x
V202331xvsV201386x
V202341xvsV201372x
V202341xvsV201386x
V202341xvsV202331x
V202350xvsV201386x
V202350xvsV202341x

Antes de eso, primero mandemos a realizar las matrices usando los datos que calculé y que completan
el espacio de parámetros. Bien, ya junté todos los datos en una carpeta. Debería probar a ver qué
me da si construyo matrices con eso. Veamos primero el archivo de Python que tengo.

Ya mandé a correr para construir las matrices de DJS de los pares de preguntas en el espacio de
parámetros habiendo aumentado el conjunto de simulaciones. Me mandaría a ver cómo quedan ordenados
los pares de preguntas del subconjunto en el espacio de parámetros, pero ahora necesito esperar
a que se construyan las matrices de DJS.

Lo siguiente que puedo hacer es continuar un poco con el código para que cuando estas cosas estén
hechas ya mandarlas a correr. Ahí preparé eso, así que me voy yendo a casa.

------------------------------------------------------------------------------------------

28/10/2024

Hoy vine más tarde porque a la noche mis viejos llegaron a la 1:30 de la mañana. En la mañana me peleé
un poco con el sistema de CAPES para lograr enviar la carta firmada por Silvio.

En la comida hablamos con Pablo sobre que deberíamos proponerle a Silvio alguna idea de trabajo.
Estaría bueno proponer un modelo multidimensional, algo en la línea del trabajo que hace Pastor Satorras.
Esa es una idea, la otra es proponer algún modelo que busque aplicar ideas de teoría de juegos, 
interacción de personas con alguna interface y quizás propuestas de argumentos que puedan ser
analizados.

Ahora debería ponerme con el tema del trabajo con Hugo. Primero, mandé a correr el armado de las matrices
de DJS y los gráficos del espacio de parámetros habiendo incrementado la cantidad de simulaciones utilizadas.
 Se hicieron bien todas las simulaciones. Ahora debería revisar lo que me anoté sobre los gráficos esos
particulares que planeo revisar en especial, los que pertenecen al subconjunto.

Por motivos que desconozco, no se armaron los gráficos de preguntas en el espacio de parámetros. Voy a tener
que revisarlo de nuevo desde el principio. Por un lado, las matrices de JS no se armaron, la cagué ahí. 
Voy a mandarlo a arrancar de nuevo eso, así que hoy no va a estar. Resuelto esto, sigo teniendo una
pequeña duda de por qué el gráfico en el caso de datos KS no se construyeron. No me cierra eso.
Ya vi el error. Listo, ahora a esperar que se resuelva todo.

Lo siguiente es ponerme con la parte teórica, ya. Por ahora fue simple repaso, pero me vino bien para
recuperar idea de cómo se hace la cuenta. Tengo que seguir.

Por otro lado, mañana leeré lo que me pasó Lucio, se parece a un paper que leí, pero ya no recuerdo.

------------------------------------------------------------------------------------------

29/10/2024

A la mañana mandé mal un mail, como pelotudo. Después leí el paper de "Drivers of online polarization"
que me pasó Lucio. Creo que hay cosas interesantes para mencionar a Pablo, como forma de comparar nuestro
trabajo con alguien que hace un trabajo similar.

Lo siguiente es ver si puedo mandar a correr los gráficos que quise hacer ayer. Por algún motivo, el gráfico
no sale bien, no estoy dándome cuenta de cuál es el problema.

Me junté con Lucio para charlar sobre la presentación del trabajo de Granovetter que estábamos haciendo.
Quedamos en dos o tres ideas de cosas para agregar a la presentación. Tengo que ponerme a trabajar en eso.
Mañana o el jueves.

Tengo que mañana resolver lo que está pasando en el gráfico ese. Y también quiero hacer el test de
Alemán.

------------------------------------------------------------------------------------------

30/10/2024

Hay tres cosas claras que quiero resolver.

1) Armar esos gráficos de preguntas en el espacio de parámetros que por motivos no me están
funcionando.
2) Completar la presentación que estamos armando con Lucio sobre el trabajo de Granovetter.
3) Hacer un test de Alemán.
4) Revisar el tema de la beca de movilidad.
5) Mandar a correr las simulaciones haciendo un barrido más fino en el espacio de Beta-Cosd.

No logro entender por qué funciona mal. No lo entiendo. El código de funciones que está
cargado es uno viejo. No tiene las correcciones nuevas. Tengo que cargar uno nuevo. Decidí directamente
bajar los archivos de csv.
Está dando vacío el subconj de preguntas. No logro entender por qué. Ese es el gran problema. Lo veré
más tarde, porque Pablo quiere que haga algo extra en el medio.

Ya encontré el problema. Dios, era una re pelotudez, la puta madre. Bueno, esos gráficos van
a estar para mañana. Lo que puedo hacer ahora es ponerme con el test de Alemán y después
mañana me pondré con lo de Granovetter.

------------------------------------------------------------------------------------------

31/10/2024

Hablé con Pablo, me dijo que primero vea si puedo separar el subconj de preguntas a partir
de usar las distancias JS. Hecho eso, me pondré con la presentación del trabajo de Granovetter.
Después tengo que mandar a correr nuevas simulaciones en las pc's del cluster. Y por último,
continuar con la parte teórica a ver qué logro construir.

Hice lo que me dijo Pablo, terminé lo de Granovetter. No llegué a hacer nada más, lo otro lo hago
el finde supongo.

------------------------------------------------------------------------------------------

01/11/2024

A la mañana fui a Alemán, a la tarde fue el DF Abierto. No tuve tiempo de avanzar en nada.

------------------------------------------------------------------------------------------

03/11/2024

En casa al final estuve intentando pensar en qué hacer con el trabajo para presentarle a la
gente de GOTHAM. No tengo grandes ideas. Esto no está nada bueno. Me puse a estudiar un
poco para la materia de Mininni. Tengo que avanzar más rápido con esto si quiero 
rendir ese final algún día.

------------------------------------------------------------------------------------------

04/11/2024

Hoy llegué a las 10. Revisé los gráficos que tengo hechos. La verdad, no muestran gran cosa.
Quiero charlarlo con Pablo y plantearle mi situación. Mientras me voy a poner con la parte
teórica.

Hablé con Pablo después de la comida, lo que me dijo es que no sólo haga una clusterización
en cuatro clusters, sino que también lo haga en dos, que identifique cuáles son los pares de
preguntas en cada cluster y de ahí sacar una conclusión sobre si podemos o no diferenciar
estados en este contexto.

A esto sumarle un resumen claro de qué vamos a escribir en el paper.

Ya clusterizé todo en dos clusters y sumé los gráficos para ese análisis. Ahora debería
diferenciar cuáles pares de preguntas están en cada cluster.

#######################################################################################

Si clusterizo en dos clusters, lo que observo son las siguientes separaciones:

.) Cluster 1: 'V202255x_vs_V202341x.csv', 'V202331x_vs_V201386x.csv',
	      'V202341x_vs_V201386x.csv', 'V202350x_vs_V201386x.csv'
	    
.) Cluster 2: 'V201411x_vs_V201408x.csv', 'V201426x_vs_V201386x.csv',
   	      'V202255x_vs_V201420x.csv', 'V202255x_vs_V202328x.csv',
   	      'V202328x_vs_V201386x.csv', 'V202341x_vs_V201372x.csv',
    	      'V202341x_vs_V202331x.csv', 'V202350x_vs_V202341x.csv'
    	      
#######################################################################################

Si clusterizo en 4 clusters, lo que observo son los siguientes conjuntos:

.) Cluster 1: 'V202255x_vs_V202341x.csv', 'V202331x_vs_V201386x.csv',
	      'V202341x_vs_V201386x.csv', 'V202350x_vs_V201386x.csv'
	    
.) Cluster 2: 'V201426x_vs_V201386x.csv', 'V202328x_vs_V201386x.csv'

.) Cluster 3: 'V201411x_vs_V201408x.csv', 'V202255x_vs_V201420x.csv',
	      'V202255x_vs_V202328x.csv'
	    
.) Cluster 4: 'V202341x_vs_V201372x.csv', 'V202341x_vs_V202331x.csv',
	      'V202350x_vs_V202341x.csv'
	      
#######################################################################################

Bueno, la verdad dió bastante lindo lo observado. Habrá que ver cómo plantear el mostrar eso.
Más que nada como para que entren todos los gráficos en una o dos diapositivas.
Podría armar un nuevo subconjunto y ver qué da, pero me parece que es forzar un poco
la maquinaria. Creo que estaría bueno mostrar lo observado y de ahí decidir a dónde
encaramos la cosa.

Por ahora seguiré con el análisis teórico. Ahí anoté una buena parte de la ecuación, tendría
que ver si puedo hacer un análisis de estabilidad de esto.

------------------------------------------------------------------------------------------

05/11/2024

Preparé la presentación para mañana. Es bastante chica. ¿Hay algo más que quiera presentar?
Establecí que mirando un pequeño subconjunto, la clusterización de Kmeans logra diferenciar
4 clusters de gráficos bien diferenciados.

¿Debería agregar gráficos a este subconjunto? Me parece que sería para confundir nomás.
¿Qué debería comentar como idea para el paper? Por ahora por desgracia nos estaría faltando
la capacidad de diferenciar en el espacio de parámetros gráficos de encuestas. Actualmente
tenemos preguntas distribuidas en el espacio de parámetros, pero sin un gran contexto de
cómo se distribuyen. Y si reducimos el conjunto de simulaciones usadas, la cosa da horrible
porque ubica a todos los gráficos en el mismo lugar básicamente.

No estoy seguro de qué cosas hacer de acá para mañana, yo creo que voy a seguir un rato con
el análisis teórico, a pesar de que no voy a poder resolver nada para mañana.

------------------------------------------------------------------------------------------

06/11/2024

Cosas que surgieron en la reunión:
---------------------------------

.) Tomar los datos, aprovechar la separación en 4 clusters 
.) Concentrarnos sólo en polarizaciones en ambos ejes. Tendremos una
distribución de parámetros ideales
.) Empezar a escribir, como para ir destilando lo que tenemos y 
de ahí ir consolidando lo que tenemos
.) Quizás pensar en la Kurtosis
.) Quizás se podrían ir agrupando cajas de opiniones. Pasar de siete
a cinco.

.) Lo que mencioné sobre los estados observados está bien, ¿verdad? Estoy
notando que el de Obamacare vs Impeachment no pareciera bien graficado.
¿Eso pasa con todos?
.) ¿Hay alguna otra forma de comparar los datos con las simulaciones? 

Lo miré, los colores están mal. No entiendo cómo, pero están mal. Voy a revisar esto primero.
Sí, efectivamente están identificados para el orto. Reparemos eso. Claro, además cuando
comparo clusterizaciones, están mal comparadas. Pero en el espacio están bien. Y eso
es compatible. Dios, qué pelotudo.

Encima me da mejor la clusterización para tres clusters. Y quizás justamente eso sea mejor.
Dios, qué bronca. Repitamos la anotación de clusters

#######################################################################################

Si clusterizo en dos clusters, lo que observo son las siguientes separaciones:

.) Cluster 1: 'V201426x_vs_V201386x.csv', 'V201411x_vs_V201408x.csv',
      	      'V202255x_vs_V201420x.csv', 'V202328x_vs_V201386x.csv',
       	      'V202255x_vs_V202328x.csv'
	    
.) Cluster 2: 'V202341x_vs_V201372x.csv', 'V202341x_vs_V202331x.csv',
      	      'V202350x_vs_V202341x.csv', 'V202350x_vs_V201386x.csv',
	      'V202341x_vs_V201386x.csv', 'V202331x_vs_V201386x.csv',
      	      'V202255x_vs_V202341x.csv'
    	      
#######################################################################################

Si clusterizo en 3 clusters, lo que observo son los siguientes conjuntos:

.) Cluster 1: 'V201426x_vs_V201386x.csv', 'V201411x_vs_V201408x.csv',
     	      'V202255x_vs_V201420x.csv', 'V202328x_vs_V201386x.csv',
	      'V202255x_vs_V202328x.csv'
	    
.) Cluster 2: 'V202350x_vs_V201386x.csv', 'V202341x_vs_V201386x.csv',
    	      'V202331x_vs_V201386x.csv', 'V202255x_vs_V202341x.csv'

.) Cluster 3: 'V202341x_vs_V201372x.csv', 'V202341x_vs_V202331x.csv',
	      'V202350x_vs_V202341x.csv'


#######################################################################################

Si clusterizo en 4 clusters, lo que observo son los siguientes conjuntos:

.) Cluster 1: 'V201411x_vs_V201408x.csv', 'V202255x_vs_V201420x.csv',
      	      'V202255x_vs_V202328x.csv'
	    
.) Cluster 2: 'V202350x_vs_V201386x.csv', 'V202341x_vs_V201386x.csv',
              'V202331x_vs_V201386x.csv', 'V202255x_vs_V202341x.csv'

.) Cluster 3: 'V202341x_vs_V201372x.csv', 'V202341x_vs_V202331x.csv',
    	      'V202350x_vs_V202341x.csv'
	    
.) Cluster 4: 'V201426x_vs_V201386x.csv', 'V202328x_vs_V201386x.csv'
	      
#######################################################################################

Bueno, revisé la cosa y la verdad si bien me mandé una cagada en la presentación de resultados,
que honestamente me hace sentir que doy una imagen de alguien que labura tórpemente,
por otro lado por lo menos las cosas dan bien y me parece que tenemos un resultado en puerta.
Estamos completamente en condiciones para escribir el paper y arrancar a presentar lo que
tenemos. Con mes y medio de laburo quizás podemos llegar a presentar algo para fin de año.
O quizás para Enero.

Pablo anotó las siguientes cosas:
---------------------------------

Buscar distribuciones empíricas que se parezcan mas a los estados puros.
Pensar que queremos separar bien en el espacio de parámetros.
(Esto creo que está supeditado a que estaba dando mal. Igual podríamos agrandar el subconjunto
visto que dentro de todo esto está dando mejor)

El modelo esta muy degenerado y puede encontrar mismas configuraciones en muchas regiones del espacio de parámetros.
Hugo: Concentrarse en configuraciones polarizadas
Otra metrica aparte de JS? (Pensar en otra métrica visto los resultados corregidos quizás
no sea necesario) binear en. 3 o 5 cajas (Esto se podría considerar como forma de mejorar las distancias obtenidas)
Nuestro modelo cualitativamente reproduce los resultados, si queremos ser mas precisos en la comparación,
tenemos que hacer un modelo mas sofisticado que incluya variabilidad. (Esta es una propuesta
de reiniciar todo que finalmente quizás no sea necesaria)

Correr una red 1000 fully connected entre cos delta 0.5 y 1, beta 1 y beta 1.2
Hugo: buscar la transición de descorrelacionada a correlaciónada en la región beta > 1

------------------------------------------------------------------------------------------

07/11/2024

En la mañana hice otro de los test en alemán. Hablé con Pablo, me dijo que primero hagamos la
comparación con tres clusters, a ver qué se observa. Eso quiere decir el gráfico de parámetros
coloreado según los clusters, la mutual information entre clusters y por ahora no se me ocurre
algo más.

Ya armé esos gráficos que me propuso Pablo, los subí al drive, corroboré que los gráficos estén
en los lugares correctos.

Pensaba leer un paper, después ir a casa y ya de ahí mañana haré algunas cosas más de Alemán.
O mejor el laburo de la materia de agentes.

------------------------------------------------------------------------------------------

08/11/2024

A la mañana fui a Alemán, después estuvo la charla de Sebas. Para dentro de dos semanas tengo
que preparar una charla. Veré si la armo sobre lo que fueron las clases de ética en la
recolección de datos, o sobre algún paper interesante.

Lo primero que tengo que hacer es mandar a correr cosas. Segundo leer lo que hizo Sebas sobre
el cálculo de la ecuación dinámica en el modelo de Granovetter.

En Coimbra mandé a realizarse las simulaciones de la iteración 0 a la 29. En Algarve
mandé a realizarse las simuaciones de la iteración 30 a la 59. En Oporto mandé
a correr las simulaciones entre 60 y 89. Van a quedar 10 simulaciones faltantes
que después repartiré en las tres pc's. Dentro de un mes o más.

Ecuación de Focker-Planck. Está descargando el libro de Springer mientras miro lo que escribió
Sebas. Tal cuál me dijo Sebas, ese libro justifica el paso de la ecuación de la derivada
de la probabilidad de la fracción de agentes a la ecuación dinámica de la fracción de agentes.
¿Cómo sería entonces la ecuación maestra que tenemos pasada al caso de fracción de agentes?

------------------------------------------------------------------------------------------

11/11/2024

Llegué no tan temprano, hablé con Lucio por temas del modelo de Granovetter y el viaje con
Silvio. Después mandé mail por el tema del trabajo de la materia de modelos basados en
agentes.

Podría seguir laburando en la parte de agregar pares de preguntas al tema del trabajo de la
gente de GOTHAM. Podría seguir con el análisis teórico, que ya casi tengo la ecuación armada
y de ahí lo que sigue sería quizás hacer pruebas con el modelo numérico. No me parece igual
que sea el camino a resultados.

Hablando con Pablo, me dijo de modificar los colores de los gráficos, para que sean más fácilmente
diferenciables. Y que arme también el gráfico para 100 simulaciones en el caso de 4 clusters.
Y que revise uno de los puntos rojos que está mezclado con los puntos rosas.

No me tengo que olvidar que yo tengo que armar una presentación para dentro de dos semanas.
Tengo que leer lo que anoté del viaje a Uruguay y decidir si con eso tengo algo para charlar
al respecto.

Pablo nos recomendó buscar bibliografía sobre el modelo de Schelling para la materia de Inés.
Ahora YA voy a ver lo de la ecuación del modelo de Granovetter, después lo que me dijo Pablo
y por último lo del modelo dinámico para ver si ya consigo una versión final de eso.

Charlamos sobre el modelo de Granovetter con Pablo, anoté unas cosas para hacer en el
cuaderno. Con Lucio estábamos viendo formas de escribir la ecuación maestra de la
probabilidad de tener una fracción de agentes. Estábamos considerando introducir una
integral de la función softmax en función de los umbrales de los agentes. Y como esa
integral se presenta como una cuenta muy compleja de resolver, quizás podríamos ver
formas de aproximar el denominador.

Volviendo al trabajo con la gente de GOTHAM, Pablo me dijo para emprolijar lo que tengo
hasta ahora cosa de mandarles lo que estamos viendo antes de la charla y ya poder llegar
con esto revisado.

Antes de eso, primero voy a revisar las correcciones que hicieron sobre mi laburo Victoria
y Felipe. Bien, ya revisé y respondí eso, sigamos con lo otro.

Resolví lo de los colores. Genial. Pablo me dijo de armar los clusters en el espacio reducido
y en reconstruir los gráficos en el espacio de parámetros, porque no son del todo claros.
Tengo que tener algo que dé una idea de cómo son los estados promedios de los clusters y
cómo son los estados en cada región. También me preguntó para el caso de 4 clusters si el punto
rojo en las 20 simulaciones está mal clasificado. Y cuál es el caso de 100 simulaciones para
los 4 clusters.

------------------------------------------------------------------------------------------

12/11/2024

Hoy tengo tres cosas principales para hacer:
1) Emprolijar la presentación, intentemos sacar algo hecho hoy. Achicar la región graficada
en los gráficos donde se me juntan todos los puntos, esas cosas.
2) Revisar algunos papers sobre trabajos de Schelling, ideas con las que caer hoy a la
clase. También revisar cómo funca el código de Mesa.
3) Preparar presentación para el viernes de la otra semana.

Revisé y encontré un paper sobre cosas de Schelling, después quizás lo charlemos con los pibes.

Voy a ponerme con la presentación. Revisé el punto que me propuso Pablo de mirar,
está bien ese punto. Después me fui a la clase de Modelo de agentes.

------------------------------------------------------------------------------------------

13/11/2024

Hablando con Pablo, el plan primero es armar la presentación para mandarle a la gente
de GOTHAM. Bien, tengo esa presentación armada. Para la semana que viene puedo intentar
tener un análisis más claro de la parte teórica y una presentación un poco más exhaustiva
sobre las clusterizaciones.

Ahora tengo dos cosas que puedo ponerme a hacer. La primera es un test de Alemán, la segunda
es ponerme a preparar la presentación para el viernes de la semana que viene. La tercera
cosa que quiero hacer es si puedo ponerme a estudiar para el final de Mininni.

Pablo me dijo de armar unos gráficos de distancias de JS y ver dónde van los mínimos.
Armé los gráficos que Pablo me pidió, mañana a primera hora le muestro eso. Mañana
trabajaré con Lucio en el tema de Granovetter. Mañana también quiero laburar en la presentación
del otro viernes.

------------------------------------------------------------------------------------------

14/11/2024

Llegué más o menos temprano, vamos mejorando. Me siento joven, con vida.
Pablo me decía que tenga a mano los estados característicos de las regiones como para
mostrar que lo que se ve en las matrices de distancia de JS es correcto. Se me ocurren
dos formas de mostrar eso, una es colocando según como yo ya tengo separadas las regiones.
Siento que eso tiene como un preconcepto de lo que yo creo que es. Me parece mejor si
uso los gráficos de fracción de agentes en el espacio de parámetros. Porque además
justamente sirve para mostrar por qué creo que están donde digo que están.
Lo armé como me parece mejor. Ahora tengo dos opciones, ponerme con Alemán o ponerme
con el armado de la presentación para el viernes que viene. Yo haré lo de la presentación
primero, después alemán, después charlar con Pablo.

¿Hay algo que yo piense que deba hacer para la semana que viene? Proponerle a Pablo lo
de usar la correlación como forma de medir si los gráficos dan bien.

Después de esto me junté con Lucio a laburar en el tema de la notación de Granovetter
y resolver lo de la notación.

Más tarde charlé con Pablo y continué preparando la presentación agregando comparaciones
entre el mapa de colores de distancia JS contra lo que se ve en el mapa de fracción
de agentes en el espacio de parámetros.

------------------------------------------------------------------------------------------

15/11/2024

A la mañana fui a Alemán, llegué un poquitín tarde hoy. Fuimos a comer, volví, y más tarde
voy al casi coloquio. Hoy no voy a laburar mucho.

Después tengo que ponerme a actualizar la documentación. El miércoles quizás.
En la hora que queda, me pondré a revisar el código del laburo de la materia de Modelos
de Agentes. Miré el modelo, la verdad que me quedé bastante dando vueltas con eso y no
resolví nada. Pero por lo menos ya lo entiendo bastante, creo que podría hacerlo correr
con los otros criterios que charlamos. Me confunde un poco que no estoy seguro de qué queremos
ver o graficar. Tengo algunas cosas anotadas, veré de armar algo para el martes quizás.
No sé si el finde, quizás el martes nomás.

------------------------------------------------------------------------------------------

19/11/2024

Llegué a la facultad, estoy en condiciones de laburar en lo de la presentación, hacer algo
para la charla de grupo o trabajar en lo del modelo de Schelling. Primero voy a repasar un
segundo el tema de la presentación para la gente de GOTHAM.

------------------------------------------------------------------------------------------

20/11/2024

Hicimos la reunión con Pablo y la gente de GOTHAM. Estas son las cosas que anoté de la charla.

Cosas que surgen en la reunión:
--------------------------------
1) No apoyarse tanto en los datos. Identificar diferentes parejas de datos en el espacio de parámetros.
2) Hacer comparaciones bien cualitativas sobre si los estados están en regiones de 
alta controversialidad o de alta correlación.
3) Convence más la idea de la comparación de la encuesta con el mapa de JS y la fracción de estados
en el espacio de parámetros.
4) Hugo está mostrando cómo da el análisis de estabilidad. Encuentra dos regiones de transición,
una de Beta 1.1 para abajo, y otra de Cos(delta) 0.75 en adelante.
5) La presentación de la comparación de la polarización 2D vs 1D me parece interesante para mostrar
la importancia de el modelado en varias dimensiones.
6) Estaría bueno mostrar la jerarquía de Betas. Dar una idea de que lo que se vió en el paper de ellos
1D se respeta en la versión 2D.

Luego de bastante mirar los pdfs, creo que básicamente tomaré algunas slides de dos presentaciones
y contaré algunas conclusiones que tengo de lo que fue la parte más de charlas del SICSS.


------------------------------------------------------------------------------------------

21/11/2024

Hoy en la mañana quise laburar en el tema de Modelos de Agentes, no logré hacer correr el programa,
tampoco nos pusimos de acuerdo en quién manda a correr las cosas. Mañana charlaremos sobre esto supongo.
El resto del día estuve laburando en la presentación sobre el viaje de Uruguay. Viene bien, falta
agregar el tema de lo de ética en ciencia. Veré si puedo concretar una buena parte hoy.


------------------------------------------------------------------------------------------

22/11/2024

Llegué temprano, aunque los trenes me están complicando porque están tardando mucho.
Me puse con la presentación del viaje a Uruguay. Armé bastante, aunque no terminé todo
lo que me hubiera gustado. Igual fue una charla grande, creo que bastante bien estuvo.

Me junté con el grupo de MBA, charlamos sobre qué hacer, fue un bardo porque todavía no
tenemos datos. Así que volví y mandé a correr las cosas en el cluster de Coimbra.
Corté mis simulaciones en Coimbra, estaban en la primer vuelta en Beta=1.20. Voy a arrancar
desde la segunda vuelta la próxima. Y ya a lo último vuelvo a arrancar desde 1.20 la primer
vuelta nomás.

------------------------------------------------------------------------------------------

25/11/2024

El domingo me enfermé. Hoy laburé un poco desde casa en la presentación de la materia
de MBA.

------------------------------------------------------------------------------------------

26/11/2024

Hoy vine un poco más tarde, revisé algunas cosas de mail, suscribí a algunas Obligaciones negociables
para ver qué tal. Tengo que resolver cosas en casa y ver qué hacer con Telecentro.

A la tarde terminamos de preparar la presentación de la materia de modelos basados en agentes. Lo mandamos,
preparamos la charla, fuimos a la clase, vimos varias presentaciones copadas, defendimos
el laburo, volvimos para casa.

------------------------------------------------------------------------------------------

27/11/2024

A la mañana vine un poquito tarde, me agarró la lluvia, armé el mail del grupo que me pidió
Pablo y el Overleaf. Me guardé esos datos.

Después de comer revisamos vuelos con Lucio. Hecho eso, me puse a revisar qué hacer en estos días.

Ideas de qué hacer:
-------------------
1) Ir completando el Overleaf, construir una propuesta de paper. Un primer draft razonable
y copado.
2) Continuar el laburo de Granovetter. Lucio había introducido el cálculo de ciertas integrales
en las ecuaciones dinámicas del modelo. Tengo que rever eso y continuar desde ahí.
3) Estudiar Alemán. En principio el plan sería rendir este viernes. Sino el que sigue.
4) Rendir el final de Mininni. Estaría bueno charlar con Pablo, y también con Mauro.
Mañana le mandaré un mensaje a Mauro avisándole que planeo cruzármelo a Pablo en el
pasillo y de ahí ir viendo cómo avanzamos.
5) Preparar el poster de Ddays.
6) Terminar el informe para MBA.

Visto todo, yo hoy estudiaría Alemán, mañana haré cosas de Mininni e iré completando el Overleaf.
Para mi el poster lo puedo armar la semana que viene tranquilo. En esa semana también armaré
el informe de MBA. Quizás un poco de estudiar Alemán. Y también mechar estudiar para el final
de Mininni. Ok, suena razonable. Voy por el café.
¿Y Granovetter? Qué se yo, el lunes que viene.

------------------------------------------------------------------------------------------

28/11/2024

Hoy terminé otro test de Alemán. En parte, tengo que decir que no me siento para nada confiado,
no manejo bien el vocabulario, no tengo bien entendido la forma de armar oraciones o los temas
vistos. Me gustaría poder armarme un mejor resumen de los temas vistos en clase. Quizás no
me puedo armar yo el resumen pero puedo leer lo que está al final de las unidades.

Ahora a la tarde arrancaré con ir preparando el Overleaf. Le iré cargando librerías, pondré
algunos títulos y secciones, veremos cómo lo encaramos. Después, si queda tiempo,
me pondré con el informe de MBA.

Ok, estuve con esto, pero siento que no fue mucho lo que hice en el día de hoy. Los jueves
tienen eso, el corte del coloquio medio que me destroza. Y yo soy un gil. Cuestión, mañana
tengo alemán, tengo que seguir con esto, estaría bueno hacer lo de Mininni y también
está el informe para Inés. Así que hay que ver todo junto. Quizás la semana que viene la
cosa esté más tranca en ese sentido.

------------------------------------------------------------------------------------------

02/12/2024

Hoy llegué más o menos tarde a la facultad, ahora debería ponerme con lo que es el poster del
Dinamic Days. Hay tres cosas claves para hacer esta semana:

1) Poster para el Dinamic Days
2) Presentación en Overleaf del paper
3) Informe de MBA

Pablo quiere que antes del miércoles les podamos mostrar el overleaf a la gente de España. Arranquemos
con eso YA. Después me pongo con el poster, y por último el jueves me pongo con el informe de MBA.
Mininni puede esperar.

Hoy armé el esqueleto grande del paper que vamos a presentar con la gente de España y se lo pasé a Pablo
para que lo mire. Me voy más temprano porque no me estoy sintiendo tan bien, intentaré descansar un poco.

------------------------------------------------------------------------------------------

03/12/2024

Hoy me quedé en casa esperando a que vengan a revisar el tema de la caldera. De paso me sirvió
porque estaba sintiéndome bastante mal por el tema de la gripe/fiebre de ayer.

Estuve laburando en el poster, pero la verdad hice muy poco para eso. Esta semana va a ser
medio nefasta con el laburo que tengo por delante.

------------------------------------------------------------------------------------------

04/12/2024

Pablo me dijo que haga varios cambios en el archivo de Overleaf. Para empezar, me dijo que lo
pase a Inglés. El resto de los cambios los voy a ir tomando de lo que me escribió en el Whatsapp.
Vamos a ver si resuelvo esto ahora a la mañana.

Costó arrancar la máquina, pero por lo menos ahora estoy haciendo algo. Estoy de a poco escribiendo
algunas secciones del poster. Siguiendo lo que dijo Pablo, estoy poniendo las cosas del paper directo
al poster.

Armé el Overleaf como me dijo Pablo, me dijo que le pareció que quedó bien. Eso es una victoria moral.
Lo siguiente es continuar con el Poster. Me voy temprano por partido de River. Cuando llegue a casa,
seguiré laburando.

------------------------------------------------------------------------------------------

05/12/2024

Hoy estuve laburando el poster. Va quedando. Pablo me dijo que lo puedo imprimir el lunes.
No me gusta estar tan sobre la hora, pero bueno, veremos. Intentaré tenerlo mañana. Aunque
mañana hay un montón de coloquios interesantes.

Pablo al mediodía me pidió que le ayude con unos gráficos. Después fui a comer y más tarde
seguí con el poster. La última hora laburé un poco en la presentación, retoqué cosas.
Debería revisarlo un poco más mañana.

------------------------------------------------------------------------------------------

06/12/2024

A la mañana fui a rendir Alemán, estuvo bien, se hizo lo que se pudo. Me gustó el curso.
Después miré un poco el tema del trabajo de MBA. Anoté algunas correcciones. Pero no está
terminado.

Seguí con el poster. Hice todo lo que pude, lo que se me ocurrió. Tiene forma de poster, podría
imprimirse. Hay algunas cosas que después les daré una revisada con una mente un poco más fresca.
Al final nunca entregamos el trabajo de MBA. Tenemos que resolver eso el finde. Después veré
qué haré el finde.

------------------------------------------------------------------------------------------

16/12/2024

Hoy llegué al mediodía, tuve que ir a buscar unas cosas a la mañana. Ahora voy a comer
y ya arranco con el tema del trabajo del modelo de opiniones y a pensar un poco un proyecto
para laburar con Silvio en Brasil.

Lo primero para hacer hoy, YA: Qué pasa con el modelo en el caso de cos(delta)=1.
Avancé, aunque quedaron algunas cosas por resolver todavía. Debería mandar a correr simulaciones
con esto. También debería rearmar las simulaciones que tenía corriendo en Coimbra y Algarve.

Pablo me dijo de hacer tres cosa en particular:
1) Avanzar con el paper con la gente de GOTHAM. Cualquier cosa le pido la hoja con lo que charlamos
con David y Jesús.
2) Preparar una propuesta de laburo para mandarle a Silvio. Hablarle sobre el modelo de opinión,
3) No me acuerdo qué era, la concha de la lora. Creo que era mandar simulaciones para ver qué
pasa con lo del caso de cos(delta)=1. Arrancaremos con las dos cosas que tengo anotadas y después
recalculamos.

Para lo primero, tengo que además hacer simulaciones con 1000 agentes para valores de Beta entre
[0.5, 1.5] y cos(delta)=1. Tengo que ver cómo evoluciona eso. Y tengo que reponer las simulaciones
en Coimbra y Algarve.

------------------------------------------------------------------------------------------

17/12/2024

Hoy voy a arrancar con el tema de las simulaciones. Voy a volver a mandar las cosas de Oporto y las
de Coimbra. En su momento había cortado cosas en Coimbra, recordemos cuáles.

No encuentro lo que anoté de dónde corté en Coimbra, me cago en mi. Voy a tener que revisar eso
de lo que tengo armado en la carpeta directamente.

Algarve:
-------
Se terminó la primer iteración, la segunda arranca en general desde Beta=0.4. Creo que sin drama
puedo arrancarlo todo de una a partir de la segunda iteración. Repetiré algunas simulaciones
pero no vale la pena preocuparse.

Coimbra:
-------
La primera iteración resolvió hasta Beta=1.15. Hay que arrancar en Beta=1.20 la primera iteración.
La segunda iteración resolvió hasta Beta=1.05. Hay que arrancar en Beta=1.10 la segunda iteración.
La tercera iteración la arranco desde Beta=0.

Bien, ya está mandado a correr todo. Ahora hagamos la parte que tiene Cos(delta)=1, con Beta
en el intervalo [0.5, 1.5].

Armé algo para correr estos datos. Mañana correré esto desde la facultad, veré si lo puedo hacer
correr con 5 hilos y con eso resolver esto en tres o cuatro horas. Ahora mismo lo dejo corriendo
un poco en casa como para ver cuánto tarda.

------------------------------------------------------------------------------------------

18/12/2024

Mandé a correr las simulaciones para tener datos en el caso de Cos(delta)=1. Para eso están
corriendo 5 procesos en paralelo. Mientras se hace la parte numérica, voy a seguir con la
parte teórica. Con esos 5 procesos que mandé, estoy armando simulaciones de 0 a 19.

Terminé armando simulaciones hasta la 59. Mañana haré los gráficos que me muestran la polarización
del sistema en función de Beta.
También terminé el análisis teórico, me da que el cambio de la estabilidad de los estados
ideológicamente polarizados se da en beta=1, igual que me daba en los otros casos. Es bastante
razonable en cierto sentido, porque al final el comportamiento 2D se vuelve muy similar al 1D.

------------------------------------------------------------------------------------------

19/12/2024

Hoy llegué medio tarde, me agarraron para llevar sillas al jardín en el que íbamos a hacer
el asado de fin de año, comimos el asado, a la vuelta guardé sillas y por último me quedé
laburando para terminar el gráfico de entropía y varianza en función de Beta. Da lo que esperaba,
un salto en beta=1.

------------------------------------------------------------------------------------------

26/12/2024

Me tomé libre del 20 al 25. Aunque eso fue descanso únicamente de tres días. Llegué a la mañana
y Coimbra estaba caído, al parecer se cayó en estos días. Ahora voy a tener que mandar
a correr nuevamente todas las cosas en Coimbra. Lo que estaba corriendo en Coimbra es la
tercer iteración y parece que se cortó en su mínimo valor en Beta=1.00.

Ya fue, mando las tres iteraciones todas juntas entonces a partir de Beta=1. Listo, ya lo mandé
a correr, veremos cuánto tarda esto en terminarse. Digo yo que unos días más y está, para fin
de año debería estar todo listo.

Bueno, hecho esto, recapitulemos lo que tengo que hacer y lo que voy a hacer. Tengo 4
cosas importantes para resolver:

1) Paper trabajo de modelo de opiniones multidimensional.
2) Propuesta para Silvio
3) Final de Mininni
4) Trabajo de Granovetter con Lucio
5) Avisarle a la gente de GOTHAM del laburo sobre Cos(delta)=1
6) Revisar el tema de la vacunación de la fiebre amarilla

Arranquemos con lo primero que se puede resolver más rápido, lo de Silvio.
Ya mandé un mail a Hugo preguntándole sobre el laburo de comparar el modelo 1D con el 2D.
También le mandé un mail a Silvio por el tema de la visa de viaje. Podría ser necesario
tener una visa de viaje para poder permanecer 6 meses allá y cobrar el estipendio.
Por último tengo que mandarle un mail a la gente de España avisando el laburo de
cos(delta)=1.

Ahora voy a escribir la propuesta de trabajo para laburar con Silvio.

------------------------------------------------------------------------------------------

27/12/2024

Llegué no tan temprano. Vamos a ver de ir corrigiéndolo la semana que viene. Ayer armé una
propuesta que le mostré a Pablo, le mandé mensajes a la gente de GOTHAM y le mandé mensaje a
Hugo sobre el laburo. Así que ahora principalmente queda trabajar en el paper del modelos
de opiniones, Granovetter y el final de Mininni. El lunes que viene me pondré a revisar papers
de physical reviews sobre el tema que elegí.

Arranquemos con el paper. Sigamos el esquema que hablamos con David y Jesús y que Pablo anotó.
La intro puedo patearla para después, es algo que usualmente queda más para el final.

Lo siguiente es arrancar describiendo el modelo. Pablo me dijo que me guie por los papers
de Sebas y de Lucio para ver cómo construir las figuras. Para describir el modelo me voy
a guiar con lo que hicieron la gente de GOTHAM en su paper.

Hasta ahora logré escribir uno o dos párrafos y armar el texto de citas. Se puede cambiar después
pero en principio logré que tenga la forma que busco.

Avancé con escribir cosas, no mucho. Veré qué tal después. Tengo que no distraerme tanto
al hacer esto. Pero todo genera dudas sobre cómo escribirlo o qué escribir.

------------------------------------------------------------------------------------------

30/12/2024

Hoy la alarma no sonó, me levanté más tarde de lo usual. Laburé desde casa. A la mañana miré
a ver si encontraba papers del tema que hablé con Mininni para trabajar. Encontré tres, voy
a intentar leerlos y ver si son relevantes o útiles.

A la tarde estuve con el paper para escribir con la gente de España. La primera parte del modelo
la vengo escribiendo siguiendo los lineamientos del paper de ellos. Ahora llegué a la parte
donde tengo que ir describiendo los puntos estables. Hay algo ahí para mencionar que es que 
a diferencia de lo observado en el modelo 1D, si considero que las opiniones de los agentes
son todas iguales y quiero ver cómo son los puntos fijos en los cuáles los agentes tienden
a consenso neutral o consenso radicalizado, la transición de esos estados se da para 
K = 1/(1+cos(delta)).

Algo para mencionarle a Pablo es que venimos siempre usando la figura de Baumann como figura
ilustrativa del carácter bidimensional del modelo. ¿Deberíamos usar una figura nueva para
eso? ¿Qué querríamos mostrar de distinto con una nueva figura? Se me ocurre una figura
que tenga un agente hablando sobre tópicos y abajo una representación de ese espacio
e indicaciones de los valores del ángulo entre esos dos casos.

También me parece importante recalcarle que en sí vengo avanzando por el orden del paper
en el cuál estoy repasando el mismo orden jerárquico que el de la gente de España.
Estaría bueno un primer vistazo de eso.

------------------------------------------------------------------------------------------

31/12/2024

Laburé un poco. Me cuesta concentrarme en este laburo, y más en casa. Tengo que entrenarme
para esto nuevamente. Cuestión, avancé un poco más, siento que estoy de alguna manera enganchando
el ritmo. Tengo que ponerme después con lo de Mininni. Eso es ordenar qué quiero hacer y cómo.
Siento que lo más confuso en eso es qué quiero hacer. Bueno, lo primero será leer el paper,
diseccionarlo, intentar darle un sentido y ver qué tal.

------------------------------------------------------------------------------------------

02/01/2025

Hoy llegué más o menos a tiempo. No laburé mucho, estuve dormido todo el día, la verdad siento
que no pude aprovechar el día para nada. Avancé un poco del paper, pero a este ritmo
no termino ni en Mayo. Tengo que ponerme las pilas. Y mañana tengo que ponerme a leer
un poco los papers que revisé para lo de Mininni.

------------------------------------------------------------------------------------------

03/01/2025

Hoy me sentí muy cansado y con sueño, a la mañana tuve reunión con Lucio, charlamos sobre el tema
de los pasajes para Brasil, la idea es el lunes mandarle un mail a Silvio mencionándole lo de los
pasajes y las opciones. Después me puse a dormir por lo cansado que me sentía, no podía trabajar.

A lo último, revisé el tema de la visa y le mandé un mail al muchacho José, resulta que sacar la visa
en Brasil es una mala idea, tenemos que hacerlo acá, sin duda. El lunes debería volver a llamar
por el tema de la vacuna amarilla, tengo que dármela ASAP.

------------------------------------------------------------------------------------------

04/01/2025

Hoy quería mirar un poco el tema del paper, pero la verdad me encuentro con cero ganas y encima
no tengo el cuaderno para anotar cosas sobre eso. Seamos serios. El lunes vayamos temprano a laburar,
no jodamos con eso. Ahora lo que voy a hacer es leer un poco el laburo sobre lo que quiero charlarle
a Mininni. También voy a organizar un poco el laburo de la semana.

El lunes debería terminar la parte del modelo, anotando lo de la aproximación que hago para el caso
de Cos(delta) = 1. Quizás dejar una parte para la charla sobre comparación de modelo 1D con el modelo
2D y luego pasar a laburar lo que sigue. Esta sección debería coronarla con armar un gráfico que sirva
de ejemplo para explicar el modelo. Mi deseo es que quien vea ese gráfico se lleve una idea clara de cómo
funca el modelo. Hecho eso, paso a la siguiente sección de datos, tal cuál lo charlamos con Pablo, David
y Jesús. Entonces, esto que anoté es el camino claro para llegar al resultado.

------------------------------------------------------------------------------------------

06/01/2025

Llegué temprano hoy, mandé mails y me puse con el laburo del paper. Después me agarró Lucio
para ver el tema de los pasajes y charlar con Silvio al respecto. Entre cosas pude terminar
más o menos la parte del modelo. O lo que creo que es la parte del modelo, después revisaré
de nuevo eso.

Veré si cuando llego a casa me pongo a armar un esquema de la primer figura.

------------------------------------------------------------------------------------------

07/01/2025

Venimos llegando bien a la facultad. Aunque me robó de nuevo el pasaje a la salida desde
casa en el tren.

A la mañana revisé lo que me mandó Hugo y después estuve revisando todo lo que escribí en
la sección del modelo. Como primer draft me parece bien, tengo comentarios de cosas para corregir.
Ahí me armé una versión cartoon de la primer figura indicando cómo sería el modelo. Subamos eso 
al paper y agreguémoslo.

Armé la figura inicial que representa un poco el modelo a estudiar. Pablo espera que esto esté bien
armado, completo para el jueves. Vengo trabajando, no sé si bien o mal. Tengo que anotarme entonces
lo que voy a mencionar en la parte de comparación con el modelo 1D. Me parece que la parte
más clara es ver cómo la fracción de simulaciones polarizadas se reduce en el espacio Beta-Kappa
al comparar el modelo 1D contra proyecciones del modelo 2D.
Dicho eso, creo que hay algo más para agregar considerando los otros gráficos que pasó Hugo, pero
no logro definir qué querría contar de eso. El tema está también en que quiero seguir el hilo narrativo
y no adelantarme en lo que estoy contando. Y la parte de la estabilidad de los estados finales me
parece que es un resultado que nos sirve a nosotros para charlar sobre dónde se ubica realmente
la región de transición, pero no me parece que sea algo para agregar así como está. Creo que no
es central a lo que queremos contar.

------------------------------------------------------------------------------------------

08/01/2025

A la mañana fui a ver el tema del vacunatorio. Al final necesito simplemente el pasaje a Brasil y mi
DNI para que me den la vacuna de la fiebre amarilla. Ya que me dice Sara, un día deberia ir hasta
Avellaneda para ver el tema de la vasectomía de nuevo. Que igual debe funcionar sin problemas.

Llegué al mediodía para la facultad y me puse con el paper. Armé el gráfico de la figura 2 con las
cosas que me parece que estaría bueno comentar. Hagamos los últimos comentarios y pasemos a la siguiente
sección.

Hablando con Lucio, estos son los documentos para apostillar:

- Antecedentes penales
- Certificado de nacimiento
- Copia del título
- Admisión al doctorado

Al comenzar la siguiente parte, tengo que arrancar describiendo cómo es el modelo y qué parámetros barrí.
Igual, releer de nuevo lo que escribió la gente de GOTHAM, no estoy seguro que sea buena idea hablar
de TODOS los parámetros barridos.

------------------------------------------------------------------------------------------

09/01/2025

Hoy costó salir de la cama, no sé por qué estaba tan muerto. Cuestión, llegué, me puse a laburar
con el tema de Brasil porque Silvio mandó mails, después me puse con el paper, fuimos a comer, y
a la vuelta estuve yendo y viniendo entre Brasil, portugués y el paper.

Estuve pensando que puedo hacer mejor de forma esquemática las figuras que poner. Para empezar, puedo
primero ir armando las figuras en google slides, después las trabajaré un poco más para que se vean más
lindas.

Cambios para hacer:
-------------------

1) La figura 2 puedo hacerla en Google Slides para que se vea como quiero, eso reduciría bastante bardo.
2) La figura 3 (La que tiene todos los estados finales) vuela, lo que podría hacer es ir poniendo los estados
finales asociados con las regiones en las que aparecen.
3) Para el estudio del modelo en los espacios de parámetros, podría armar una imagen que tenga en chiquito
los tres gráficos que rápidamente caracterizan el modelo en ese espacio de parámetros y más en grande
la separación del espacio de parámetros en regiones con los estados finales acompañando eso.

Empecé a anotar sobre cómo describir la región del espacio de parámetros Beta-Kappa. Está escrito medio
bruto, pero me gusta. Lo mismo, me gusta la idea de que maduré un concepto de las figuras finales. Habría
que discutir después qué tan interesante le parece a los demás esas figuras.

------------------------------------------------------------------------------------------

13/01/2025

Hoy vine a la facultad, no tengo mucho para anotar porque medio que no avancé tanto. Igual 
me corta la inspiración cada tanto el tema de la visa. Ahora voy a volverme temprano como para
comprar fruta y después me pondré con la visa y con el paper un rato más. Quizás pueda
ver lo del pasaporte cuando llegue a casa.

------------------------------------------------------------------------------------------

14/01/2025

A la mañana fuimos con Lucio al colegio de Escribanos, intentamos apostillar varios de los documentos,
nos recibieron el certificado de antecedentes penales nomás. De ahí fuimos a la facultad. Estuve
revisando el tema del turno del consulado mientras terminaba el paper del modelo de opiniones.

A la tarde terminé de escribir el paper, le avisé a Pablo y me volví a casa.

------------------------------------------------------------------------------------------

15/01/2025

Llegué a la mañana, repasé el paper y corregí algunos párrafos. Después estuve viendo el tema
del turno en el consulado. Avancé hasta la parte final, me falta cargar los archivos que me
pide el trámite. Para eso necesito apostillar documentos. Para eso necesito tener el documento
de alumno regular. 

Para conseguir el trámite el orden es:
1) Conseguir el documento de alumno regular. Insistirle a Pablo, Constanza o gente al respecto.
2) Ir al colegio de escribanos con eso y la partida de nacimiento a apostillar.
3) En lo que eso se apostilla, preparar los documentos que faltan, que son la carta de Silvio,
la lista de gente aceptada para el programa Move la America, el pago del RER y la foto.
4) Solicitar el turno en el consulado
5) Tramitar la visa.

Mientras Pablo revisa el paper, podría ponerme a modificar la figura 1 y corregir eso. Después,
me pondré con el paper para presentarle a Pablo Mininni.

Hoy me vuelvo temprano para ver lo del regalo de Mica e ir a su casa.

------------------------------------------------------------------------------------------

16/01/2025

Hoy vine tarde porque me quedé durmiendo, llegué re tarde del cumple de Mica.
iré a comer, charlaré con Pablo, le preguntaré por el tema del documento que me falta,
por el texto para presentarle a Silvio y por el paper. Mientras Pablo revisa eso
yo me pondré con el tema del final con Minnini.

Estuve unas dos horas intentando anotarme en el CPF para extranjeros. Por lo que ví, me falta
el tercer paso. Necesito esperar a que me manden el número para subirlo en mi cuenta de CAPES
y actualizar mis datos. Posiblemente la semana que viene esté esto.

Ahora sí, el final con Minnini. Empecé a leer el paper. Cómo cuesta leer papers. Bueno, eso.

------------------------------------------------------------------------------------------

17/01/2025

Hoy leí el paper de Dominant Imprint of Rossby Waves. Para hacer un resumen, en el paper
lo que hacen es estudiar la temperatura a altura de la superficie y con eso intentar
medir correlación entre distintos puntos. La idea es que tomaron el mapa y lo subdividen
en una grilla identificando cada punto como un nodo. Lo que logran observar finalmente
es que encuentran correlación entre nodos que se configura en base a cantidades entera
de media longitud de onda de Rossby. Es decir, las mediciones de correlación y la forma
que entre nodos se afectan está muy influenciada por el fenómeno de las ondas de Rossby.
Esa es la gran conclusión.

Ahora miremos un poco lo que tengo hecho yo en el trabajo que hice para E1. Después de eso,
lo siguiente sería ponerme a ver cómo carajos hacer funcionar el GHOST en mi pc.
Ya leí el trabajo, tiene algunos puntos que tengo que revisar y si quiero hacer las cuentas:

1) La aproximación de la fuerza de Coriolis usando la aproximación del plano Beta
2) El cálculo de las ecuaciones dinámicas que definen el sistema.
3) ¿Qué es la aproximación de aguas poco profundas?
4) El uso del método de Lax-Wendroff y por qué vale la pena
5) ¿Qué es la vorticidad potencial?

Me parece que son cinco preguntas razonables a contestar, yo me pondría con esto el martes
o miércoles que viene. Quizás podría comparar con las cosas de la materia a ver si surge algo
parecido en lo visto en clase.

Al hacer este análisis, Pablo me dijo de considerar por qué pudo haber fallado. Me dijo
de revisar el coeficiente ese que te da la relación entre el tamaño del grillado y el delta
t para ver si te va a reventar la simulación.

Lo siguiente que se me ocurre que vale la pena revisar es cómo hacer correr el GHOST. Juraría
que aunque sea una vez funcó en mi pc. BIEN, lo hice funcionar. Encontré en la página un archivo
indicando cómo hacerlo funcionar y carpetas en las que mandé a correr esto alguna vez.
Corrió, no tarda demasiado. Habrá que ver cómo extraer info de los archivos. Charlar con Mauro
sobre eso.

------------------------------------------------------------------------------------------

20/01/2025

Hoy llegué no tan temprano a la facultad, charlé unas cosas con Lucio y me puse a revisar
papers de Silvio. Descargué 9. Voy a ponerme a leer varios, no sé si leeré todos. Intenté
tomar uno por año de los que hizo Silvio, que tengan bastantes citas o que sean temas más
o menos diversos.

Leí tres papers de Silvio, anoté el resumen de dos. El tercero lo anoto mañana.
Igual mañana debería ponerme a laburar en otra cosa.

------------------------------------------------------------------------------------------

21/01/2025

Estoy revisando las simulaciones realizadas en las pc's. Lo de Coimbra se terminó.
Ya tengo 30 simulaciones completas ahí. En Algarve todavía se están realizando simulaciones.
Oporto no terminó, pero ya mañana o pasado está. Voy a mandar lo que falta a realizarse en
Coimbra, total con lo que falta en Algarve, lo de Coimbra se termina ahí.
 Mandé lo de Coimbra, me puse a leer el paper de Silvio y no logré resolver bien qué corno hacen,
intenté resumir más o menos el concepto y sigamos.

Ya es de tarde, tengo que ponerme a avanzar con algo más, otro día sigo leyendo papers
de Silvio. ¿Qué es clave hacer ahora? ¿Me pongo a revisar las figuras del paper y a
estilizarlas? ¿Preparo el final de Mininni?

Al final estuve toda la tarde intentando anotarme en el CPF, voy a ver si puedo terminar esto
en casa. Estuve mirando unas páginas por un lado, otras por el otro, mandé mail al consulado.
Cuestión que ahora encontré algo que tiene un instructivo de cómo hacerlo en la página
del consulado. Esperemos que esto funque esta vez.

------------------------------------------------------------------------------------------

22/01/2025

Ayer en casa terminé de solicitar el turno para el CPF. Hoy a la mañana charlé con Lucio y
miré unas cosas de mails. Ahora me voy a poner a revisar las figuras del paper y a ver
cómo estilizarlas siguiendo lo que me dijo Pablo.

Antes de las figuras, vi que me enviaron el comprobante de alumno regular, así que intentaré
llevar eso a apostillar. Ya saqué turno para ir a apostillar cosas el viernes. Y por otro lado,
tengo para ir al consulado a conseguir mi CPF el lunes 03 de Febrero. Está intensa la cosa.

Correcciones:
.) Presentación del modelo: Falta un párrafo citando la descipción de la figura 1
   Hacer un análisis de punto fijo antes de análisis de estabilidad
.) Modificar los parencite por cite.
.) El párrafo que marqué como copiado directamente, debería reescribirlo con mis palabras
.) El párrafo donde describo los estados finales, tengo que modificarlo porque la
forma en que está escrito casi que pide el usar una figura para mostrar los estados finales.
.) Sacar la descripción de las métricas de las secciones de espacios de parámetros y ponerla
en la sección de estados finales del modelo. Partir explicando que trabajo con la distribución
de opiniones 2D y 1D, que miro la entropía y varianza de eso y después de aclarar cómo lo calculo
recién ahí decir que hago un promedio sobre el ensamble. Además agregar en esa región una
figura con los estados finales que me parezca importante mencionar.

------------------------------------------------------------------------------------------

23/01/2025

Hoy llegué no muy temprano. Esto de dormir más tiene ese problema. A cambio, estoy
bastante mejor, nada zombie. Hice bastantes de las correcciones que Pablo me dijo que haga,
aunque no terminé. Me falta lo último, repasando la sección del espacio de parámetros.
Haré eso mañana y ya después me pondré con el final de Mininni supongo.

------------------------------------------------------------------------------------------

24/01/2025

A la mañana fui al colegio de escribanos a apostillar documentos. Me tomaron la partida de nacimiento,
no me tomaron el certificado de alumno regular. Tengo que enviar el mail para que me inicien el trámite.

Después a la tarde me puse a terminar de agregar las correcciones que charlamos con Pablo al
paper. No fue mucho para terminar, así que hecho eso, ahora voy a mandar el mail, llamar
para ver de sacar turno por el tema de mi hombro y después me voy a poner a leer el paper
que Nahuel me pasó para comentarle a Mininni. El lunes me pondré con las figuras que debo
corregir del paper y ya el martes continuaré con el tema del final.

Al final saqué turno médico para el lunes a las 14:45, así que no iré a la facultad a laburar.

------------------------------------------------------------------------------------------

27/01/2025

Ayer fue el recital de Los Piojos, hoy me levanté re tarde. Me levanté, comí, fui al médico a recibir
los turnos para hacerme un control médico y volví para casa. Ahora me voy a poner a revisar algunas
de las figuras, cosa de llegar mañana con algo hecho para mostrarle a Pablo.

Pablo me dijo que arranque con emprolijar las figuras de las distribuciones, con algo similar a lo que
hacen Sofi y Sebas en un paper. Básicamente la idea sería hacer que los histogramas tengan forma de
funciones para que se vean más lindos, y que no sean barras.

Estoy peleando con el cómo armar el gráfico de forma horizontal. Hecho eso, tendría también que lograr
sombrear la parte de abajo. Eso va a tomar otro rato de resolver, de nuevo para la parte que va en
vertical. Pero hecho eso, estaríamos esa parte, después habrá que discutir los colores y cosas con Pablo.

No está funcionando bien eso, habrá que seguir revisando qué hace y cómo.